# Validate Tree Detection and Crown Delineation

In this section we'll use the benchmark data made available in the [`NeonTreeEvaluation`](https://github.com/weecology/NeonTreeEvaluation_package) data set ([Weinstein et al. 2021](https://scholar.google.com/scholar?cluster=4986448711981898434&hl=en&as_sdt=0,6)) to evaluate our process for lidar-based tree detection. We'll implement our tree detection process via the [`cloud2trees`]https://github.com/georgewoolsey/cloud2trees) package

First, load the standard libraries

```{r, warning=FALSE, message=FALSE}
# bread-and-butter
library(tidyverse) # the tidyverse
library(viridis) # viridis colors
library(harrypotter) # hp colors
library(RColorBrewer) # brewer colors
library(scales) # work with number and plot scales
library(latex2exp)

# visualization
library(mapview) # interactive html maps
library(kableExtra) # tables
library(patchwork) # combine plots
library(ggnewscale) # ggnewscale
library(rgl) # rgl plotting

# spatial analysis
library(sf) # simple features
library(lidR) # lidar data
library(cloud2trees) # tha cloud2trees
library(NeonTreeEvaluation) # benchmark data
```

```{r, include=F, warning=F, message=F}
# knit options
knitr::opts_chunk$set(
  echo = TRUE
  , warning = FALSE
  , message = FALSE
  # , results = 'hide'
  , fig.width = 10.5
  , fig.height = 7
)
# option to put satellite imagery as base layer of mapview maps
  mapview::mapviewOptions(
    homebutton = FALSE
    # , basemaps = c("Esri.WorldImagery","OpenStreetMap")
    , basemaps = c("OpenStreetMap", "Esri.WorldImagery")
  )
# clean session
remove(list = ls())
gc()
```

## `NeonTreeEvaluation` overview

Weinstein et al. ([2021](https://scholar.google.com/scholar?cluster=4986448711981898434&hl=en&as_sdt=0,6)) developed: 

>a benchmark dataset of individual canopy crowns derived from multi-sensor imagery in the National Ecological Observatory Network (Table 1) that provides: 1) co-registered remote sensing data from multiple sensors (LiDAR, RGB imagery, and hyperspectral imagery) to allow comparisons of methods based on any single sensor (e.g., for LiDAR based methods), or any combination of sensors (e.g., combining RGB and hyperspectral), and 2) three types of evaluation data to allow assessing both 'tree detection', defined as the identifying the location of individual trees using evaluation data with a point at the crown center , and 'crown delineation' defined as identifying the boundary edge of crowns across a broad range of forest types. The benchmark is designed to allow flexibility in both workflow and sensor selection. (p. 2)

**Table 1.** Summary of datasets included in the benchmark dataset. All sensor data has been cropped to the extent of NEON field sampling plots.

```{r, echo=FALSE, out.width="100%", out.height="100%", fig.align='center', fig.show='hold',results='asis'}
# https://journals.plos.org/ploscompbiol/article/figure?id=10.1371/journal.pcbi.1009180.t001
knitr::include_graphics("../data/journal.pcbi.1009180.t001.PNG")
```

Note the three data labeled as "Evaluation data" in the table. If you are asking "why three evaluation datasets?", the authors provide some detail:

>The inclusion of multiple evaluation types is critical because each type of evaluation data has strengths and limitations in evaluating model performance. Field collected stems are the most common evaluation data used in crown detection work due to high confidence that each stem represents a location of a single tree. However, the position of a tree stem can fail to accurately represent the position of the crown as viewed from above due to a combination of spatial errors in alignment with the image data and the tendency for trees to grow at acute angles (tree lean is not measured in the NEON data), such that the center of the crown and position of the stem can be offset by several meters....Image-annotated crowns are relatively easy to scale, allowing the collection of data for a wide range of forest types and for annotation of every visible crown in the image. Using image-annotated crowns supports the evaluation of methods across a broad range of forest types and allows both recall and precision to be calculated. However, since these annotations are not generated by an observer in the field there can be errors due to interpreting the images. This problem is solved using field-annotated crowns in which an observer annotates the remote-sensing imagery on a tablet while in the field [33]. The main limitation to this approach is that it is labor intensive, meaning that only a relatively small amount of validation data can be collected, making it difficult to obtain a large number of crowns across broad scales or assess model precision. Given the tradeoffs in each evaluation type, providing multiple criteria is a useful way of balancing the need for broad scale model verification with rigorous evaluation of field-based measurements. (p. 14-15)

To evaluate the performance of our aerial point cloud-based algorithm for 1) tree detection and 2) crown delineation using `NeonTreeEvaluation` we need to ensure our tree polygon data is formatted properly:

>This package takes a standard submission format of predicted crowns in either bounding box or polygons as input and returns the evaluation scores of the detections for each of the three evaluation datasets. This reproducible workflow will facilitate creating a transparent process for future comparisons among crown detection algorithms. (p. 14)

The authors describe the "standard submission format" on the [package GitHub](https://github.com/weecology/NeonTreeEvaluation_package):

> Each row contains information for one predicted bounding box. The plot_name should be named the same as the files in the dataset without extension (e.g. SJER_021_2018 not SJER_021_2018.tif) and not the full path to the file on disk. Not all evaluation data are available for all plots. Functions like `evaluate_field_crowns` and `evaluate_image_crowns` will look for matching plot name and ignore other plots. Depending on the speed of the algorithm, the simplest thing to do is predict all images in the RGB folder (see list_rgb()) and the package will handle matching images with the correct data to the correct evaluation procedure...Instead of bounding boxes, some methods may return polygons. To submit as polygons, create a single unprojected shapefile with polygons in image coordinates. Polygons must be complete with no holes. Here is an example of the above csv file in polygon format. Here the xmin, xmax, etc. columns are ignored since the information is stored in the geometry data.

``` r
Simple feature collection with 6 features and 7 fields
geometry type:  POLYGON
dimension:      XY
bbox:           xmin: 30.39723 ymin: 122.1164 xmax: 397.5746 ymax: 400
CRS:            NA
       xmin     ymin      xmax     ymax     score label     plot_name
1  41.01716 230.8854 151.08607 342.6985 0.8098674  Tree DSNY_014_2019
2 357.32129 122.1164 397.57458 159.3758 0.6968824  Tree DSNY_014_2019
3  30.39723 136.9157  73.79434 184.9473 0.5713338  Tree DSNY_014_2019
4 260.65921 285.6689 299.68811 326.7933 0.5511004  Tree DSNY_014_2019
5 179.34564 371.6130 232.49385 400.0000 0.4697072  Tree DSNY_014_2019
6 316.27377 378.9802 363.67542 400.0000 0.3259409  Tree DSNY_014_2019
                     st_sfc.lst.
1 POLYGON ((41.01716 230.8854...
2 POLYGON ((357.3213 122.1164...
3 POLYGON ((30.39723 136.9157...
4 POLYGON ((260.6592 285.6689...
5 POLYGON ((179.3456 371.613,...
6 POLYGON ((316.2738 378.9802...
```

So we are going to: run `cloud2trees::cloud2trees()` on all lidar data, combine into a single tree list with a row unique by a detected tree and the `plot_name` column (e.g. "SJER_021_2018"), as an unprojected `sf` data with polygons in image coordinates. We may need to run `cloud2trees::simplify_multipolygon_crowns()` prior to submission.

## lidar data in `NeonTreeEvaluation`

we first have to download evaluation data from the Zenodo archive (1GB), use the download() function to place the data in the correct package location. Download the much larger training data, set `training=TRUE`.

```{r, warning=FALSE, message=F,results=F}
NeonTreeEvaluation::download(training = T, force = F)
```

```{r, include=FALSE, eval=FALSE}
# what is in this thing?
lsf.str("package:NeonTreeEvaluation")
# where is this data 
NeonTreeEvaluation::list_rgb() %>% 
  dirname() %>% 
  unique()
# what's this?
NeonTreeEvaluation::field %>% dplyr::glimpse()
```

let's find what data is available

```{r}
# i did some digging around and the lidar data is here
lidar_dir_temp <- system.file(package = "NeonTreeEvaluation", "extdata", "NeonTreeEvaluation", "evaluation", "LiDAR")
# files
lidar_files_temp <- lidar_dir_temp %>% list.files(recursive = T, pattern = ".*\\.(laz|las)$", full.names = T) %>% unique()
# look at this
lidar_files_temp %>% basename() %>% sample(size = 9)
```

```{r}
# let's pull out all sites with `.laz` data and create a data frame for tracking purposes
lidar_df <- lidar_files_temp %>% 
    dplyr::as_tibble() %>% 
    dplyr::rename(f_path = 1) %>% 
    # create some other variables
    dplyr::mutate(
      plot_name = f_path %>% basename() %>% stringr::str_remove_all("\\.(laz|las)$")
    )
# what?
lidar_df %>% dplyr::glimpse()
```

that's a lot of files...let's only process the sites with evaluation data

```{r}
# there are functions to get a list of all evaluation data
# let's use these to filter our lidar files
plotnames_temp <- c(
    NeonTreeEvaluation::list_annotations()
    , NeonTreeEvaluation::list_field_stems()
    # this one includes file paths, so we have to clean
    , NeonTreeEvaluation::list_field_crowns() %>% 
      stringr::str_match(pattern="(\\w+).tif") %>% 
      .[,2]
    # there are plot_names from the submission data too
    , NeonTreeEvaluation::submission_polygons$plot_name %>% unique()
    , NeonTreeEvaluation::submission$plot_name %>% unique()
  ) %>% 
  unique()
# huh?
plotnames_temp %>% sample(11)
```

filter our lidar data list

```{r}
lidar_df <- lidar_df %>% 
  #filter based on plots in evaluation data
  dplyr::filter(plot_name %in% plotnames_temp) %>% 
  # pull out site 
  dplyr::mutate(
    siteID = stringr::str_extract(plot_name, "[A-Z]+")
  )
# what?
lidar_df %>% dplyr::glimpse()
```

we will want to limit our evaluation to only sites with conifer trees since `cloud2trees` implements methods developed specifically to quantify conifer forest structure that may not be appropriate for other uses.

we'll use the field data in the package to look for NEON sites with conifer trees. We'll use the NEON plant list to identify conifer species: [https://data.neonscience.org/taxonomic-lists?taxonTypeCode=PLANT](https://data.neonscience.org/taxonomic-lists?taxonTypeCode=PLANT) (click "DOWNLOAD TAXONOMIC LIST"). We'll filter for species belonging to Class Pinopsida.

```{r}
conifer_spp <-
  readr::read_csv(
    "../data/OS_TAXON_PLANT-20220330T142149.csv"
    , show_col_types = F
    , progress = F
  ) %>% 
  dplyr::filter(
    tolower(`class`) %in% c("pinopsida")
  ) %>% 
  dplyr::mutate(
    taxonID = toupper(taxonID)
    , vernacularName = tolower(vernacularName)
    , genus = stringr::str_to_title(genus)
  ) %>% 
  dplyr::distinct(taxonID, vernacularName, genus)
```

what are some of these conifers?

```{r}
# huh?
conifer_spp %>% 
  dplyr::slice_sample(n = 10) %>% 
  kableExtra::kbl(caption = "Conifer species taxonID examples") %>% 
  kableExtra::kable_styling()
```

filter for NEON sites that have conifer trees based on field data from all terrestrial NEON sites with qualifying woody vegetation: [https://data.neonscience.org/data-products/DP1.10098.001](https://data.neonscience.org/data-products/DP1.10098.001)

```{r}
conifer_sites <- NeonTreeEvaluation::field %>% 
  dplyr::left_join(
    conifer_spp %>% dplyr::mutate(is_conifer = 1)
    , by = "taxonID"
  ) %>% 
  dplyr::mutate(is_conifer = dplyr::coalesce(is_conifer, 0)) %>% 
  dplyr::group_by(siteID) %>% 
  dplyr::summarise(
    tot = dplyr::n()
    , conifer = sum(is_conifer)
    , latitude = mean(plotLatitude)
    , longitude = mean(plotLongitude)
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(pct_conifer = conifer/tot)
```

what is the breakdown of woody vegetation sampled in NEON sites by the percent conifer?

```{r}
conifer_sites %>% 
  dplyr::select(-c(longitude,latitude)) %>% 
  dplyr::arrange(desc(pct_conifer), desc(tot)) %>% 
  dplyr::slice_head(n = 19) %>% 
  kableExtra::kbl(caption = "Conifers in NEON sites", digits = 2) %>% 
  kableExtra::kable_styling()
```

let's only keep NEON sites with >50% of the woody vegetation sampled as conifer

```{r}
# minimum pct conifer
min_conifer_pct <- .5
# data frame of sites
conifer_sites <- conifer_sites %>%
  dplyr::filter(pct_conifer>min_conifer_pct)
```

finally, we'll filter our lidar processing data for only these conifer sites

```{r}
lidar_df <- lidar_df %>% 
  dplyr::inner_join(conifer_sites, by = "siteID") %>% 
  sf::st_as_sf(coords = c("longitude","latitude"), crs = 4326, remove = F)
```

what NEON sites have conifers and the most lidar plots

```{r}
lidar_df %>% 
  sf::st_drop_geometry() %>% 
  dplyr::count(siteID) %>% 
  dplyr::arrange(desc(n)) %>% 
  dplyr::slice_head(n=11) %>% 
  kableExtra::kbl(caption = "NEON sites with conifers and lidar plots") %>% 
  kableExtra::kable_styling()
```

what is the spatial distribution of these sites?

```{r}
lidar_df %>% 
  dplyr::count(siteID) %>% 
  mapview::mapview(
    zcol = "siteID", legend = F
    , layer.name = "NEON site"
    , col.regions = viridis::turbo(n=nrow(conifer_sites))
  )
```

that's pretty good geographic coverage and in places that we expect to have conifers ;D

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Example validation process

now that we have our lidar data that we can test our point cloud-based tree detection and crown segmentation process against, let's walk through the validation for a single plot

we'll test with a single point cloud in our filtered list from conifer sites with validation data

```{r}
lidar_df_row <- 1
# lidar_df$f_path[47] %>% lidR::readLAS() %>% lidR::st_crs()
```

### Preliminaries

#### View the point cloud

this step isn't necessary for validation, but let's see what this point cloud data looks like

We can plot the point cloud with and color by the point height

```{r, rgl = TRUE}
lidar_df$f_path[lidar_df_row] %>% 
  lidR::readLAS() %>% 
  lidR::plot(
    color = "Z", breaks = "quantile", bg = "white", legend = T
   , pal = harrypotter::hp(n=50, house = "gryffindor")
  )
```

there are trees in there for sure (and conifer trees by the looks of it)

let's look at the co-registered RGB imagery (notice that the `NeonTreeEvaluation` commands rely on the deprecated `raster` package :\)
```{r}
# read rgb
rgb_temp <- lidar_df$plot_name[lidar_df_row] %>%
  NeonTreeEvaluation::get_data(type = "rgb") %>% 
  raster::stack()

# read image annotated crown data and make polygons
polys_temp <-
  lidar_df$plot_name[lidar_df_row] %>%
  NeonTreeEvaluation::get_data(type = "annotations") %>% 
  NeonTreeEvaluation::xml_parse() 
polys_temp <- NeonTreeEvaluation::boxes_to_spatial_polygons(polys_temp,rgb_temp)

# plot
terra::plotRGB(rgb_temp %>% terra::rast())
terra::plot(
  polys_temp %>% terra::vect()
  , col = NA, border = "red"
  , lwd = 2 , add = TRUE
)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

```{r, include=FALSE, eval=FALSE}
###### this terra + sf doesn't work because NeonTreeEvaluation::xml_parse returns data in local coordinates
###### .... would need to add these to the coordinates in the rgb raster :/

# function to convert numbers to bbox polygon
bbox_poly <- function(xmin,ymin,xmax,ymax) {
  # points
  lower_left_pt <- sf::st_point(c(xmin,ymin))
  upper_right_pt <- sf::st_point(c(xmax,ymax))
  # to bbox polygon
  sf::st_sfc(lower_left_pt, upper_right_pt) %>% 
    sf::st_bbox() %>% 
    sf::st_as_sfc() 
}
# read rgb
rgb_temp <- lidar_df$plot_name[lidar_df_row] %>%
  NeonTreeEvaluation::get_data(type = "rgb") %>% 
  terra::rast()

# read image annotated crown data and make polygons
# polys_temp <- 
  lidar_df$plot_name[lidar_df_row] %>%
  NeonTreeEvaluation::get_data(type = "annotations") %>% 
  NeonTreeEvaluation::xml_parse() %>% 
  dplyr::mutate(id = dplyr::row_number()) %>% 
  dplyr::select(id,xmin,ymin,xmax,ymax) %>% 
  dplyr::rowwise(id) %>% 
  dplyr::mutate(geometry = bbox_poly(xmin,ymin,xmax,ymax)) %>% 
  dplyr::ungroup() %>% 
  sf::st_set_geometry("geometry") %>% 
  sf::st_set_crs(xxxxxx)
# plot
terra::plotRGB(rgb_temp, axes = T)
terra::plot(
  polys_temp %>% terra::vect() %>% terra::set.crs(terra::crs(rgb_temp))
  , border = "red"
  , add = TRUE
)
```

#### ITD variable window

We discussed our method for individual tree detection (ITD) in [this prior section](#itd). For our validation, we'll be using the default window size in the `cloud2trees::cloud2trees()` and `cloud2trees::raster2trees()` settings.

Let's see what that looks like

```{r}
ws_temp <- cloud2trees::itd_ws_functions()[["exp_fn"]]
ggplot() +
  geom_function(fun=ws_temp, lwd=1.2, color = "navy") +
  xlim(-5,60) +
  labs(
    x = "heights", y = "ws"
    , subtitle = "`cloud2trees` default ITD variable window function"
  ) +
  theme_light()
```

### Filter for "canopy" trees

First, we'll process the point cloud and get a tree list using our `cloud2trees::cloud2trees()` method with all defaults except we'll raise the minimum height of trees to search to 3 m. The ([Weinstein et al. 2021](https://scholar.google.com/scholar?cluster=4986448711981898434&hl=en&as_sdt=0,6)) benchmark was developed specifically for "canopy" trees and the field-collected stems evaluation data only includes >10 cm DBH trees:

>NEON field crews sample all trees within a plot that are greater than 10cm DBH, regardless of whether the tree crown can be seen in the remote sensing image data. While understory tree detection is an important area of future work, the scope of this benchmark is focused on crowns in the canopy that are visible from above. (p. 10)

In order to set up our point cloud-based algorithm to find "canopy" trees, we'll identify the shortest live tree in the field-collected stems data to set our `min_height` in `cloud2trees::cloud2trees()`

we'll use the filters found in `clean_field_data()` from [`NeonTreeEvaluation`](https://github.com/weecology/NeonTreeEvaluation_package/blob/724bdb0a9a3ea6433450f62c69a8fadce9ccdb66/R/evaluate_field_stems.R) as an internal function

```{r}
# get non-na heights from neon field measured trees
neon_field_heights <- NeonTreeEvaluation::field %>% 
  # filters found in `clean_field_data()`
  dplyr::filter(
    !is.na(itcEasting)
    , !stringr::str_detect(eventID,"2014")
    , growthForm %in% c("single bole tree","multi-bole tree","small tree","sapling")
    , stemDiameter>15
    , (height>3|is.na(height))
  ) %>%
  # getting only non-na
  dplyr::filter(!is.na(height)) %>% 
  dplyr::pull(height)
```

look at the summary of height data

```{r}
summary(neon_field_heights)
```

we'll set our minimum height to detect trees at the 5th percentile value

```{r}
(neon_min_ht <- quantile(neon_field_heights, probs = 0.05) %>% round())
```

what does this look like?

```{r}
dplyr::tibble(ht=neon_field_heights) %>% 
  ggplot(aes(x = ht)) +
    geom_density(color = "gold",fill = "gold", alpha = 0.7, lwd = 1.2) +
    geom_vline(xintercept = neon_min_ht, linetype = "dashed") +
    annotate(
      "text", x = neon_min_ht, y = 0.07
      , label = paste0("5th percentile: ",neon_min_ht,"m")
      , hjust = 0
    ) +
    scale_x_continuous(breaks = scales::breaks_extended(10)) +
    labs(
      x = "height (m)"
      , subtitle = "heights of \"canopy\" trees in NeonTreeEvaluation"
    ) +
    theme_light()
```

### `cloud2trees::cloud2trees()`


```{r}
ans <- cloud2trees::cloud2trees(
  input_las_dir = lidar_df$f_path[lidar_df_row]
  , output_dir = tempdir()
  , min_height = neon_min_ht
)
```

quick check our our heights

```{r}
ans$crowns_sf$tree_height_m %>% summary()
```

### Format extracted tree polygons

we need to format our extracted trees for `NeonTreeEvaluation` evaluation and submission

first, we'll simplify multipolygon crowns

```{r}
ans$crowns_sf <- cloud2trees::simplify_multipolygon_crowns(ans$crowns_sf)
```

check out our extracted trees

```{r}
ggplot2::ggplot() +
  ggplot2::geom_tile(
    data = ans$chm_rast %>%
      terra::as.data.frame(xy=T) %>%
      dplyr::rename(f=3)
    , mapping = ggplot2::aes(x = x, y = y, fill = f)
    , na.rm = T
  ) +
  harrypotter::scale_fill_hp(
    option = "gryffindor"
    , breaks = scales::breaks_extended(n=10)
  ) +
  ggplot2::geom_sf(
    data = ans$crowns_sf
    , fill = NA, color = "gray33", lwd = 1
  ) +
  ggplot2::scale_x_continuous(expand = c(0, 0)) +
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(x = "", y = "", fill = "CHM (m)") +
  ggplot2::theme_light() +
  ggplot2::theme(axis.text = ggplot2::element_blank())
```

we'll reserve judgement and let the data talk

format the data for `NeonTreeEvaluation` submission and evaluation

```{r}
return_sf <-
  ans$crowns_sf %>% 
  sf::st_set_geometry("geometry") %>% 
  dplyr::rowwise("treeID") %>% 
  dplyr::mutate(
    xmin = sf::st_bbox(geometry)[1]
    , ymin = sf::st_bbox(geometry)[2]
    , xmax = sf::st_bbox(geometry)[3]
    , ymax = sf::st_bbox(geometry)[4]
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(
    label = "Tree"
    , plot_name = lidar_df$plot_name[lidar_df_row]
  ) %>% 
  dplyr::select(xmin,xmax,ymin,ymax,label,plot_name) %>% 
  sf::st_set_crs(NA)
# what?
return_sf %>% dplyr::glimpse()
```

does this match the submission polygon data from the `NeonTreeEvaluation` package?

```{r}
NeonTreeEvaluation::submission_polygons %>% dplyr::glimpse()
```

yes, except for the "score" column which I'm pretty sure is an artifact from after evaluation?

### Test evaluation

We compared our tree detection and crown delineation results to the three types of evaluation data (i.e. “ground truth” data) presented by Weinstein et al. (2021): field-collected stems, image-annotated crowns, and field-annotated crowns. Field-collected stems offer precise tree locations but might not align with the position of the tree crown as viewed from above (e.g. due to tree lean), image-annotated crowns outline crown boundaries but are subjective, and field-annotated crowns combine the benefits of both but are highly resource-intensive.

#### Scores for an image-annotated crowns

The main data source are image-annotated crowns, in which a single observer annotated visible trees in 200 40m x 40m images from across the United States. Get the benchmark score image-annotated "ground truth" data.

*in testing, including the `sf` polygon data did not work...switching to the bbox method with `sf::st_drop_geometry()`*

```{r}
rslt_img_annttd_crwns <- NeonTreeEvaluation::evaluate_image_crowns(
  predictions = return_sf %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

in the plot (if there is a plot), "red" boxes are crowns our point cloud-based method extracted and "black" are the image annotated crowns

it looks like the overlay is generally the same but we are still extracting trees that may not be considered "canopy" trees ;\

what is in the return from `NeonTreeEvaluation::evaluate_image_crowns()` ?

```{r}
rslt_img_annttd_crwns %>% names()
```

`overall`: must be across all NEON sites, plots, and trees included for evaluation

```{r}
rslt_img_annttd_crwns$overall
```

`by_site`: must be across plots, and trees included for evaluation in a NEON sites

```{r}
rslt_img_annttd_crwns$by_site
```

`plot_level`: must be across trees included for evaluation in a NEON site, plot combination

```{r}
rslt_img_annttd_crwns$plot_level
```

count_error is the number of predicted trees minus the number of "ground truth" trees but in graphical form so we'll skip it

#### Scores for an field-annotated crowns

The second data source is a small number of field-annotated crowns from two geographic sites. These crowns were drawn on a tablet while physically standing in the field, thereby reducing the uncertainty in crown segmentation.

*not all plots have field-annotated crowns* 

`NeonTreeEvaluation::evaluate_field_crowns()` returns an error if "No plot names matching the field crown data, see list_field_crowns for paths to RGB field crown imagery."... so, we'll have to capture errors in our checks?

```{r}
# safe it
safe_evaluate_field_crowns <- purrr::safely(NeonTreeEvaluation::evaluate_field_crowns)
# test it
rslt_fld_crwns <- safe_evaluate_field_crowns(
  predictions = return_sf %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

did it do it?

```{r}
rslt_fld_crwns$error
```

nope!

#### Scores for an field-collected stems

The third data source is the NEON Woody Vegetation Structure Dataset. Each tree stem is represented by a single point. This data has been filtered to represent overstory trees visible in the remote sensing imagery.

*not all plots have field-collected stems* 

`NeonTreeEvaluation::evaluate_field_stems()` returns an error if "No submitted plot_names with matching field stem data, see list_field_stems()"... so, we'll have to capture errors in our checks?

```{r}
# safe it
safe_evaluate_field_stems <- purrr::safely(NeonTreeEvaluation::evaluate_field_stems)
# test it
rslt_fld_stems <- safe_evaluate_field_stems(
  predictions = return_sf %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

did it do it?

```{r}
rslt_fld_stems$error
```

nope!

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
remove(ans, lidar_df_row, min_conifer_pct)
remove(rslt_img_annttd_crwns,rslt_fld_crwns,rslt_fld_stems)
gc()
```

### Function to extract trees

let's create a function to extract trees and format for evaluation using our `lidar_df` data which includes a data frame of file paths with the appropriate plot name

```{r}
cloud2trees_for_eval <- function(lidar_df_row, lidar_df, min_height) {
  # message
  message(paste0("doing the work for ...... ", lidar_df$plot_name[lidar_df_row]))
  # run c2t
  qc2t <- purrr::safely(cloud2trees::cloud2trees)
  ans <- qc2t(
    input_las_dir = lidar_df$f_path[lidar_df_row]
    , output_dir = tempdir()
    , min_height = neon_min_ht
    , ws = cloud2trees::itd_ws_functions()[["log_fn"]]
  )
  if(!is.null(ans$error)){return(NULL)}
  ans <- ans$result
  # simp
  ans$crowns_sf <- cloud2trees::simplify_multipolygon_crowns(ans$crowns_sf)
  # return
  return_sf <-
    ans$crowns_sf %>% 
    sf::st_set_geometry("geometry") %>% 
    dplyr::rowwise("treeID") %>% 
    dplyr::mutate(
      xmin = sf::st_bbox(geometry)[1]
      , ymin = sf::st_bbox(geometry)[2]
      , xmax = sf::st_bbox(geometry)[3]
      , ymax = sf::st_bbox(geometry)[4]
    ) %>% 
    dplyr::ungroup() %>% 
    dplyr::mutate(
      label = "Tree"
      , plot_name = lidar_df$plot_name[lidar_df_row]
    ) %>% 
    dplyr::select(xmin,xmax,ymin,ymax,label,plot_name) %>% 
    sf::st_set_crs(NA)
  # give the workers a rest
  Sys.sleep(2)
  return(return_sf)
}
```

### Build evaluation data

let's run each point cloud through our lidar-based tree detection implemented via `cloud2trees::cloud2trees()`

```{r, include=FALSE, eval=FALSE}
xxxx <- c("2018_TEAK_3_315000_4107000_image_237" ,"2018_TEAK_3_316000_4097000_image_35",  "2018_TEAK_3_322000_4107000_image_518"
,"NIWO_002_2018"                        ,"OSBS_029_2019"  )
temp_temp <- lidar_df %>% dplyr::filter(plot_name %in% xxxx)
my_submission3 <- 
    1:nrow(temp_temp) %>% # uncomment this when it gets real
    purrr::map(\(x) 
      cloud2trees_for_eval(
        lidar_df_row = x
        , lidar_df = temp_temp
        , min_height = neon_min_ht
      )
    ) %>% 
    dplyr::bind_rows()
```


```{r, results=FALSE, warning=FALSE, message=FALSE}
# where should we save the file?
submission_fn <- "../data/NeonTreeEvaluation_submission.gpkg"
# if we don't already have the data, run it
if(!file.exists(submission_fn)){
  my_submission <- 
    # 1:nrow(lidar_df) %>% # uncomment this when it gets real
    sample(1:nrow(lidar_df), size = 22) %>% 
    purrr::map(\(x) 
      cloud2trees_for_eval(
        lidar_df_row = x
        , lidar_df = lidar_df
        , min_height = neon_min_ht
      )
    ) %>% 
    dplyr::bind_rows()
  # save it 
  sf::st_write(my_submission, submission_fn)
}else{
  my_submission <- sf::st_read(submission_fn)
}
```

what did we get?

```{r}
my_submission %>% dplyr::glimpse()
```

trees detected by plot

```{r}
my_submission %>% 
  sf::st_drop_geometry() %>% 
  dplyr::count(plot_name)
```

### Evaluation

#### Scores for an image-annotated crowns

The main data source are image-annotated crowns, in which a single observer annotated visible trees in 200 40m x 40m images from across the United States. Get the benchmark score image-annotated "ground truth" data.

*in testing, including the `sf` polygon data did not work...switching to the bbox method with `sf::st_drop_geometry()`*

```{r}
rslt_img_annttd_crwns3 <- NeonTreeEvaluation::evaluate_image_crowns(
  predictions = my_submission3 %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

in the plot (if there is a plot), "red" boxes are crowns our point cloud-based method extracted and "black" are the image annotated crowns

it looks like the overlay is generally the same but we are still extracting trees that may not be considered "canopy" trees ;\

what is in the return from `NeonTreeEvaluation::evaluate_image_crowns()` ?

```{r}
rslt_img_annttd_crwns %>% names()
```

`overall`: must be across all NEON sites, plots, and trees included for evaluation

```{r}
rslt_img_annttd_crwns3$overall
```

`by_site`: must be across plots, and trees included for evaluation in a NEON sites

```{r}
rslt_img_annttd_crwns$by_site
```

`plot_level`: must be across trees included for evaluation in a NEON site, plot combination

```{r}
rslt_img_annttd_crwns$plot_level
```

count_error is the number of predicted trees minus the number of "ground truth" trees but in graphical form so we'll skip it

#### Scores for an field-annotated crowns

The second data source is a small number of field-annotated crowns from two geographic sites. These crowns were drawn on a tablet while physically standing in the field, thereby reducing the uncertainty in crown segmentation.

*not all plots have field-annotated crowns* 

`NeonTreeEvaluation::evaluate_field_crowns()` returns an error if "No plot names matching the field crown data, see list_field_crowns for paths to RGB field crown imagery."... so, we'll have to capture errors in our checks?

```{r}
# safe it
safe_evaluate_field_crowns <- purrr::safely(NeonTreeEvaluation::evaluate_field_crowns)
# test it
rslt_fld_crwns <- safe_evaluate_field_crowns(
  predictions = return_sf %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

did it do it?

```{r}
rslt_fld_crwns$error
```

nope!

#### Scores for an field-collected stems

The third data source is the NEON Woody Vegetation Structure Dataset. Each tree stem is represented by a single point. This data has been filtered to represent overstory trees visible in the remote sensing imagery.

*not all plots have field-collected stems* 

`NeonTreeEvaluation::evaluate_field_stems()` returns an error if "No submitted plot_names with matching field stem data, see list_field_stems()"... so, we'll have to capture errors in our checks?

```{r}
# safe it
safe_evaluate_field_stems <- purrr::safely(NeonTreeEvaluation::evaluate_field_stems)
# test it
rslt_fld_stems <- safe_evaluate_field_stems(
  predictions = return_sf %>% sf::st_drop_geometry()
  , show = T
  , summarize = T
)
```

did it do it?

```{r}
rslt_fld_stems$error
```

nope!