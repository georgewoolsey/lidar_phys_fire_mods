[["index.html", "Aerial LiDAR for Fire Model Inputs Section 1 Introduction 1.1 Objective 1.2 Data", " Aerial LiDAR for Fire Model Inputs George Woolsey 21 October, 2024 Section 1 Introduction Code in support of “Using aerial LiDAR data for object-based physical fire modeling in conifer forests of the southwestern US” 1.1 Objective The objective of this study is to demonstrate the use of aerial LiDAR data to create inputs for physics-based fire models in frequent-fire forests of the southwestern United States. We review the methods used to extract tree location, species, and physical form from aerial LiDAR data. We evaluate this canopy crown detection methodology using a benchmark data set created to standardize evaluation metrics (Weinstein et al. 2021). We explain how to format this data for seamless integration with two commonly used object-based physical fire modeling tools. We demonstrate the end-to-end process using a case study from the southwestern United States. 1.2 Data LiDAR data from the southwest US "],["data-load-and-explore.html", "Section 2 Data Load and Explore 2.1 NeonTreeEvaluation 2.2 cloud2trees 2.3 LadderFuelsR", " Section 2 Data Load and Explore Load the standard libraries # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(ggnewscale) # ggnewscale library(plot3D) # 3d plotting library(rgl) # rgl plotting # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data # models library(brms) # bayesian modelling Load the libraries from GitHub. Here we’ll load: NeonTreeEvaluation: benchmark data set to evaluate lidar-based tree detection (Weinstein et al. 2021) cloud2trees: routines for processing point cloud data collected by airborne lidar to detect forest trees (Woolsey and Tinkham, 2024) LadderFuelsR: vertical fuel continuity quantification and crown base height (CBH) calculation (Viedma et al. 2024) lasR: complex processing pipelines on lidar data (Roussel 2024) leafR: set of functions for analyzing the ecological structure of forests based on LAI and LAD measures derived from LiDAR data (Roussel 2024). Data from this package used in the LadderFuelsR workflow even though this process is never explained by Viedma et al. 2024. library(pak) # load them c(&quot;NeonTreeEvaluation&quot;, &quot;cloud2trees&quot;, &quot;LadderFuelsR&quot;, &quot;lasR&quot;, &quot;leafR&quot;) %&gt;% # install and load purrr::map(function(x){ # locations df &lt;- dplyr::tibble( p = c(&quot;NeonTreeEvaluation&quot;, &quot;cloud2trees&quot;, &quot;LadderFuelsR&quot;, &quot;lasR&quot;, &quot;leafR&quot;) , l = c( &quot;weecology/NeonTreeEvaluation_package&quot; , &quot;georgewoolsey/cloud2trees&quot; , &quot;olgaviedma/LadderFuelsR&quot; , &quot;r-lidar/lasR&quot; , &quot;DRAAlmeida/leafR&quot; ) ) # install if needed if(!require(x, character.only = T)){ pak::pkg_install( pkg = df %&gt;% dplyr::filter(tolower(p)==tolower(x)) %&gt;% dplyr::pull(l) , upgrade = T ) } # load library(x, character.only = T) }) 2.1 NeonTreeEvaluation Weinstein et al. (2021) developed: a benchmark dataset of individual canopy crowns derived from multi-sensor imagery in the National Ecological Observatory Network (Table 1) that provides: 1) co-registered remote sensing data from multiple sensors (LiDAR, RGB imagery, and hyperspectral imagery) to allow comparisons of methods based on any single sensor (e.g., for LiDAR based methods), or any combination of sensors (e.g., combining RGB and hyperspectral), and 2) three types of evaluation data to allow assessing both ‘tree detection’, defined as the identifying the location of individual trees using evaluation data with a point at the crown center , and ‘crown delineation’ defined as identifying the boundary edge of crowns across a broad range of forest types. The benchmark is designed to allow flexibility in both workflow and sensor selection. (p. 2) Table 1. Summary of datasets included in the benchmark dataset. All sensor data has been cropped to the extent of NEON field sampling plots. The objective of the present analysis is to evaluate the use of this benchmark data set (Weinstein et al. 2021) for a scientific publication describing a workflow to ingest raw LiDAR data and export a tabular tree list for use as an input to the QUIC-Fire physics-based fire spread model (Linn et al. 2020). Weinstein et al. (2021) describe the LiDAR data in the benchmark data set: The LiDAR data are 3D coordinates (~5 points/m2) that provide high resolution information about canopy crown shape and height. LiDAR data are stored as 1000m x 1000m.laz files (Fig 2). These files contain the x,y,z coordinates for each return, as well as metadata on return intensity and point classification. Boundaries of individual canopy crowns are often apparent due to gaps among neighboring trees or differences in height among overlapping canopy crowns. For more information on NEON LiDAR data processing see NEON technical document NEON.DOC.001292. Due to the large spatial coverage of the collection effort, the point density of the NEON LiDAR clouds is much lower than the point density used for most studies of crown detection models ([20, 21]; point densities of 8–1000 pt/m2). (p. 4) what’s in this package? lsf.str(&quot;package:NeonTreeEvaluation&quot;) ## boxes_to_spatial_polygons : function (boxes, raster_object, project_boxes = TRUE) ## canopy_model : function (las, res = 0.5) ## check_download : function () ## compute_precision_recall : function (ground_truth, predictions, threshold = 0.4, summarize = TRUE) ## download : function (training = FALSE, savedir = NULL, force = F) ## evaluate_field_crowns : function (predictions, summarize = TRUE, show = TRUE, project = FALSE) ## evaluate_field_stems : function (predictions, project = TRUE, show = T, summarize = T) ## evaluate_image_crowns : function (predictions, project = FALSE, show = TRUE, summarize = TRUE) ## field_crowns : function (x, show = TRUE, project_boxes = TRUE) ## get_data : function (plot_name, type) ## grand_summary : function (results, threshold = 0.4) ## image_crowns : function (predictions, show = TRUE, project_boxes = TRUE) ## list_annotations : function () ## list_chm : function () ## list_field_crowns : function () ## list_field_stems : function () ## list_rgb : function () ## load_field_crown : function (plot_name, show = TRUE) ## load_ground_truth : function (plot_name, show = TRUE) ## xml_parse : function (path) ## zenodo_url : function (concept_rec_id = 3723356, rec_version = &quot;latest&quot;, rec_id = NULL) ## zenodo_versions : function (concept_rec_id, arg_checks = TRUE) we first have to download evaluation data from the Zenodo archive (1GB), use the download() function to place the data in the correct package location. Download the much larger training data, set training=TRUE. NeonTreeEvaluation::download(training = T, force = F) ## NULL what data is in this package? # what/where is this data paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = F) %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;NeonTreeEvaluation/evaluation/LiDAR/DELA_021_2019.laz&quot; ## [2] &quot;NeonTreeEvaluation/evaluation/LiDAR/UKFS_048_2018.laz&quot; ## [3] &quot;NeonTreeEvaluation/evaluation/LiDAR/WREF_018_2019.laz&quot; ## [4] &quot;NeonTreeEvaluation/evaluation/LiDAR/TALL_057_2019.laz&quot; ## [5] &quot;NeonTreeEvaluation/evaluation/LiDAR/unnamed_plot_45.las&quot; ## [6] &quot;NeonTreeEvaluation/evaluation/LiDAR/GUAN_060_2018.laz&quot; ## [7] &quot;NeonTreeEvaluation/evaluation/LiDAR/KONZ_030_2019.laz&quot; ## [8] &quot;NeonTreeEvaluation/evaluation/LiDAR/YELL_008_2018.laz&quot; ## [9] &quot;NeonTreeEvaluation/evaluation/LiDAR/OSBS_329.las&quot; ## [10] &quot;NeonTreeEvaluation/evaluation/LiDAR/SJER_053_2019.laz&quot; For a list of NEON site abbreviations https://www.neonscience.org/field-sites/field-sites-map NeonTreeEvaluation::list_annotations looks into package contents for ground truth annotations for the image-annotated crowns. # list_annotations NeonTreeEvaluation::list_annotations() %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;2018_TEAK_3_320000_4093000_image_222&quot; ## [2] &quot;2018_TEAK_3_318000_4107000_image_718&quot; ## [3] &quot;SJER_002_2018&quot; ## [4] &quot;DSNY_005_2018&quot; ## [5] &quot;ONAQ_021_2019&quot; ## [6] &quot;2018_SJER_3_254000_4107000_image_670&quot; ## [7] &quot;OSBS_003_2019&quot; ## [8] &quot;TEAK_047_2018&quot; ## [9] &quot;2018_SJER_3_252000_4113000_image_323&quot; ## [10] &quot;2018_SJER_3_254000_4108000_image_700&quot; The field collected stems are individual points for each tree. They overlap with a subset of the sensor data. Use the NeonTreeEvaluation::list_field_stems function to determine which plots have stem data. # list_field_stems NeonTreeEvaluation::list_field_stems() %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;DELA_046&quot; &quot;LAJA_015&quot; &quot;LENO_009&quot; &quot;GUAN_015&quot; &quot;DELA_044&quot; &quot;SERC_014&quot; ## [7] &quot;LENO_068&quot; &quot;RMNP_013&quot; &quot;LENO_015&quot; &quot;MLBS_009&quot; The NeonTreeEvaluation::crown_polygons function lists “field-annotated crowns” in which an observer annotates a polygon on the remote-sensing image on a tablet while standing in the field. From Ordway Swisher Biological Station, Florida and Mountain Lake Biological Station. # crown_polygons NeonTreeEvaluation::crown_polygons %&gt;% dplyr::glimpse() ## Rows: 564 ## Columns: 7 ## $ indvdID &lt;chr&gt; &quot;MLBSE00007&quot;, &quot;MLBSE00012&quot;, &quot;MLBSE00027&quot;, &quot;MLBSE00049&quot;, &quot;… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((541983.5 4136174,..., POLYGON ((542127 … ## $ plotID &lt;fct&gt; MLBS_14, MLBS_37, MLBS_42, MLBS_1, MLBS_21, MLBS_23, MLBS… ## $ siteID &lt;fct&gt; MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLB… ## $ utmZone &lt;fct&gt; 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17… ## $ plotEasting &lt;dbl&gt; 541986.3, 542125.7, 542267.8, 541883.4, 542053.1, 542075.… ## $ plotNorthing &lt;dbl&gt; 4136173, 4136182, 4136994, 4136586, 4136390, 4136400, 413… Sites with field annotated crowns # crown_polygons NeonTreeEvaluation::crown_polygons %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(siteID) ## # A tibble: 2 × 2 ## siteID n ## &lt;fct&gt; &lt;int&gt; ## 1 MLBS 106 ## 2 OSBS 458 hmmm this data only exists for two NEON sites The woody vegetation structure data contains information on field estimated height and maximum crown diameter for the majority of field collected stems. We annotated all trees in the 40x40 m plot, regardless of health status, provided they were visible in the image. NeonTreeEvaluation::field %&gt;% dplyr::glimpse() ## Rows: 37,776 ## Columns: 67 ## $ uid &lt;fct&gt; 411f5c60-79c4-41ef-b3d0-4e9b5365870e, 0d… ## $ namedLocation &lt;fct&gt; ABBY_063.basePlot.vst, ABBY_063.basePlot… ## $ date &lt;fct&gt; 2015-07-23, 2015-07-23, 2015-07-23, 2015… ## $ tagEventID &lt;fct&gt; vst_ABBY_2015, vst_ABBY_2015, vst_ABBY_2… ## $ domainID &lt;fct&gt; D16, D16, D16, D16, D16, D16, D16, D16, … ## $ siteID &lt;fct&gt; ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY… ## $ plotID &lt;fct&gt; ABBY_063, ABBY_063, ABBY_063, ABBY_063, … ## $ subplotID &lt;int&gt; 39, 21, 21, 21, 39, 39, 39, 39, 39, 39, … ## $ nestedSubplotID &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ pointID &lt;int&gt; 57, 21, 21, 21, 39, 41, 41, 41, 41, 41, … ## $ stemDistance &lt;dbl&gt; 3.0, 23.8, 23.8, 23.8, 26.2, 16.0, 16.0,… ## $ stemAzimuth &lt;dbl&gt; 111.0, 50.0, 50.0, 50.0, 45.4, 346.0, 34… ## $ recordType &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ individualID &lt;fct&gt; NEON.PLA.D16.ABBY.00441, NEON.PLA.D16.AB… ## $ supportingStemIndividualID &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ previouslyTaggedAs &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ samplingProtocolVersion &lt;fct&gt; NEON.DOC.000987vE, NEON.DOC.000987vE, NE… ## $ taxonID &lt;fct&gt; PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM… ## $ scientificName &lt;fct&gt; &quot;Pseudotsuga menziesii (Mirb.) Franco va… ## $ taxonRank &lt;fct&gt; variety, variety, variety, variety, vari… ## $ identificationReferences &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ morphospeciesID &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ morphospeciesIDRemarks &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ identificationQualifier &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ remarks &lt;fct&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;corrected using 201… ## $ measuredBy &lt;fct&gt; krian@neoninc.org, krian@neoninc.org, kr… ## $ recordedBy &lt;fct&gt; kzias@field-ops.org, kzias@field-ops.org… ## $ dataQF &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ plotType &lt;fct&gt; tower, tower, tower, tower, tower, tower… ## $ subtype &lt;fct&gt; basePlot, basePlot, basePlot, basePlot, … ## $ plotLatitude &lt;dbl&gt; 45.76074, 45.76037, 45.76037, 45.76037, … ## $ plotLongitude &lt;dbl&gt; -122.3303, -122.3303, -122.3303, -122.33… ## $ datum &lt;fct&gt; WGS84, WGS84, WGS84, WGS84, WGS84, WGS84… ## $ utmZone &lt;fct&gt; 10N, 10N, 10N, 10N, 10N, 10N, 10N, 10N, … ## $ plotEasting &lt;dbl&gt; 552081.2, 552079.1, 552079.1, 552079.1, … ## $ plotNorthing &lt;dbl&gt; 5067683, 5067642, 5067642, 5067642, 5067… ## $ horzUncert &lt;dbl&gt; 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10… ## $ crdSource &lt;fct&gt; Geo 7X, Geo 7X, Geo 7X, Geo 7X, Geo 7X, … ## $ elevation &lt;dbl&gt; 363.22, 362.29, 362.29, 362.29, 362.34, … ## $ vertUncert &lt;dbl&gt; 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10… ## $ nlcdClass &lt;fct&gt; evergreenForest, evergreenForest, evergr… ## $ appMods &lt;fct&gt; bbc|bgc|cdw|cfc|dhp|hbp|ltr|sme|vst, bbc… ## $ geometry &lt;fct&gt; &quot;c(-122.330278, 45.76074)&quot;, &quot;c(-122.3303… ## $ itcEasting &lt;dbl&gt; 552084.0, 552097.3, 552097.3, 552097.3, … ## $ itcNorthing &lt;dbl&gt; 5067682, 5067657, 5067657, 5067657, 5067… ## $ itcLongitude &lt;dbl&gt; -122.3302, -122.3301, -122.3301, -122.33… ## $ itcLatitude &lt;dbl&gt; 45.76073, 45.76051, 45.76051, 45.76051, … ## $ eventID &lt;fct&gt; vst_ABBY_2015, vst_ABBY_2016, vst_ABBY_2… ## $ tempShrubStemID &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tagStatus &lt;fct&gt; NA, ok, ok, ok, NA, NA, ok, ok, ok, NA, … ## $ growthForm &lt;fct&gt; single bole tree, single bole tree, sing… ## $ plantStatus &lt;fct&gt; &quot;Standing dead&quot;, &quot;Standing dead&quot;, &quot;Dead,… ## $ stemDiameter &lt;dbl&gt; 40.0, 90.0, 89.1, 88.3, 105.0, 28.3, 29.… ## $ measurementHeight &lt;int&gt; 130, 130, 130, 130, 130, 130, 140, 130, … ## $ height &lt;dbl&gt; NA, 7.5, 6.7, 6.8, NA, NA, NA, 22.5, 21.… ## $ baseCrownHeight &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ breakHeight &lt;dbl&gt; NA, NA, NA, 6.8, NA, NA, NA, NA, NA, NA,… ## $ breakDiameter &lt;dbl&gt; NA, NA, 61, NA, NA, NA, NA, NA, NA, NA, … ## $ maxCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ninetyCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ canopyPosition &lt;fct&gt; NA, , NA, NA, NA, NA, , NA, NA, NA, , NA… ## $ shape &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ basalStemDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basalStemDiameterMsrmntHeight &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ maxBaseCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ninetyBaseCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ area &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … Nice, there appears to be some useful data in here: uid, siteID, plotID, stemDiameter, height, maxCrownDiameter, ninetyCrownDiameter, baseCrownHeight, plantStatus, taxonID Also, I just found that there is a hidden function in the package to filter the field tree data …except for I’m going to change the minimum diameter from 15 cm to 10 cm clean_field_data&lt;-function(field){ field$area&lt;-field$maxCrownDiameter*field$ninetyCrownDiameter field&lt;-field %&gt;% filter(!is.na(itcEasting),!stringr::str_detect(eventID,&quot;2014&quot;),growthForm %in% c(&quot;single bole tree&quot;,&quot;multi-bole tree&quot;,&quot;small tree&quot;,&quot;sapling&quot;),stemDiameter&gt;10) %&gt;% droplevels() %&gt;% filter(height&gt;3|is.na(height)) #Limit difference in heights to_remove&lt;-field %&gt;% group_by(individualID) %&gt;% summarize(mean=mean(height),sum_difference = abs(sum(diff(height)))) %&gt;% filter(sum_difference &gt; 8) field&lt;-field %&gt;% filter(!individualID %in% to_remove$individualID) } clean this data and filter it # filter it field_trees &lt;- NeonTreeEvaluation::field %&gt;% clean_field_data() %&gt;% dplyr::select( uid, siteID, plotID, stemDiameter , height, maxCrownDiameter, ninetyCrownDiameter , baseCrownHeight, plantStatus, taxonID ) %&gt;% dplyr::filter(!is.na(maxCrownDiameter) &amp; !is.na(height)) %&gt;% dplyr::mutate(CrownRadius = maxCrownDiameter/2) # see it field_trees %&gt;% dplyr::glimpse() ## Rows: 6,878 ## Columns: 11 ## $ uid &lt;fct&gt; b4305401-a7d9-4e79-afc4-a7f0c82e98d3, 346b66a5-cd8… ## $ siteID &lt;fct&gt; ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, AB… ## $ plotID &lt;fct&gt; ABBY_007, ABBY_007, ABBY_007, ABBY_007, ABBY_007, … ## $ stemDiameter &lt;dbl&gt; 68.2, 54.1, 54.7, 58.0, 68.1, 20.2, 15.6, 19.6, 18… ## $ height &lt;dbl&gt; 49.6, 13.1, 22.9, 35.6, 50.2, 19.0, 10.8, 12.5, 9.… ## $ maxCrownDiameter &lt;dbl&gt; 9.7, 3.2, 9.1, 9.5, 11.3, 8.6, 4.5, 4.7, 5.2, 4.3,… ## $ ninetyCrownDiameter &lt;dbl&gt; 8.5, 0.0, 7.8, 7.9, 6.7, 7.6, 4.2, 4.5, 4.8, 3.8, … ## $ baseCrownHeight &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ plantStatus &lt;fct&gt; &quot;Live&quot;, &quot;Dead, broken bole&quot;, &quot;Live&quot;, &quot;Live&quot;, &quot;Live… ## $ taxonID &lt;fct&gt; PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, P… ## $ CrownRadius &lt;dbl&gt; 4.85, 1.60, 4.55, 4.75, 5.65, 4.30, 2.25, 2.35, 2.… what are these data? field_trees %&gt;% dplyr::select(dplyr::where(is.numeric)) %&gt;% summary() ## stemDiameter height maxCrownDiameter ninetyCrownDiameter ## Min. : 15.10 Min. : 3.10 Min. : 0.100 Min. : 0.000 ## 1st Qu.: 18.60 1st Qu.: 9.90 1st Qu.: 3.800 1st Qu.: 2.900 ## Median : 23.30 Median :13.30 Median : 6.200 Median : 4.700 ## Mean : 27.44 Mean :14.97 Mean : 6.975 Mean : 5.296 ## 3rd Qu.: 31.80 3rd Qu.:18.90 3rd Qu.: 9.200 3rd Qu.: 7.000 ## Max. :255.00 Max. :52.90 Max. :62.000 Max. :31.000 ## NA&#39;s :115 ## baseCrownHeight CrownRadius ## Min. : NA Min. : 0.050 ## 1st Qu.: NA 1st Qu.: 1.900 ## Median : NA Median : 3.100 ## Mean :NaN Mean : 3.487 ## 3rd Qu.: NA 3rd Qu.: 4.600 ## Max. : NA Max. :31.000 ## NA&#39;s :6878 status? field_trees %&gt;% dplyr::count(plantStatus) ## plantStatus n ## 1 Dead, broken bole 75 ## 2 Downed 2 ## 3 Live 5486 ## 4 Live, other damage 135 ## 5 Live, broken bole 43 ## 6 Live, disease damaged 199 ## 7 Live, insect damaged 157 ## 8 Live, physically damaged 154 ## 9 No longer qualifies 12 ## 10 Removed 1 ## 11 Standing dead 614 keep only live field_trees &lt;- field_trees %&gt;% dplyr::filter(plantStatus %&gt;% tolower() %&gt;% stringr::str_starts(&quot;live&quot;)) taxonID? field_trees %&gt;% dplyr::count(taxonID) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::slice_head(n = 20) ## taxonID n ## 1 PICOL 535 ## 2 PIEN 500 ## 3 ACRU 367 ## 4 ABLAL 333 ## 5 LITU 270 ## 6 QURU 267 ## 7 LIST2 238 ## 8 TSCA 211 ## 9 QUAL 197 ## 10 PIPA2 177 ## 11 ACSA3 137 ## 12 PIFL2 132 ## 13 OXYDE 117 ## 14 PSMEM 96 ## 15 PITA 95 ## 16 PSME 91 ## 17 CATO6 88 ## 18 PIMA 84 ## 19 POTR5 81 ## 20 JUNIP 80 let’s see the height versus diameter relationship field_trees %&gt;% ggplot(mapping = aes(x = height, y = stemDiameter)) + geom_point() + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + theme_light() let’s get conifer trees only??? ….sure, i found a NEON plant list with the codes: https://data.neonscience.org/taxonomic-lists?taxonTypeCode=PLANT conifer_spp &lt;- readr::read_csv( &quot;../data/OS_TAXON_PLANT-20220330T142149.csv&quot; , show_col_types = F , progress = F ) %&gt;% dplyr::filter( tolower(family) %in% c( &quot;pinaceae&quot;, &quot;podocarpaceae&quot;, &quot;araucariaceae&quot; , &quot;taxaceae&quot;, &quot;cephalotaxaceae&quot;, &quot;taxodiaceae&quot;, &quot;cupressaceae&quot; ) ) %&gt;% dplyr::mutate( taxonID = toupper(taxonID) , vernacularName = tolower(vernacularName) , genus = stringr::str_to_title(genus) ) %&gt;% dplyr::distinct(taxonID, vernacularName, genus) # huh? conifer_spp %&gt;% dplyr::slice_sample(n = 10) ## # A tibble: 10 × 3 ## taxonID vernacularName genus ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 PLATY6 platycladus Platycladus ## 2 PICOB bolander beach pine Pinus ## 3 PICOC beach pine Pinus ## 4 JUMO oneseed juniper Juniperus ## 5 PSMEG rocky mountain douglas-fir Pseudotsuga ## 6 JUGR7 western juniper Juniperus ## 7 CUPRESSPP &lt;NA&gt; &lt;NA&gt; ## 8 PINACESPP &lt;NA&gt; &lt;NA&gt; ## 9 TAAS pond cypress Taxodium ## 10 ABLO sierra white fir Abies filter that field tree list for conifers conifer_trees &lt;- field_trees %&gt;% dplyr::inner_join(conifer_spp, by = &quot;taxonID&quot;) check those conifers height and diameter conifer_trees %&gt;% ggplot(mapping = aes(x = height, y = stemDiameter, color = genus)) + geom_point() + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + facet_wrap(facets = dplyr::vars(genus)) + scale_color_viridis_d(option = &quot;turbo&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) what about this crown area data? conifer_trees %&gt;% ggplot(mapping = aes(x = CrownRadius, y = genus, fill = genus)) + geom_boxplot(width = 0.7, outliers = F) + scale_fill_viridis_d(option = &quot;turbo&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) radius data # height conifer_trees$height %&gt;% quantile(probs = c(0.01,0.05,0.5,0.95,0.99)) ## 1% 5% 50% 95% 99% ## 3.500 5.600 11.500 25.210 41.753 # radius conifer_trees$CrownRadius %&gt;% quantile(probs = c(0.01,0.05,0.5,0.95,0.99)) ## 1% 5% 50% 95% 99% ## 0.8500 1.1000 2.0000 5.1000 6.6255 let’s model crown radius based on height lm(formula = CrownRadius ~ height, data = conifer_trees) %&gt;% broom::tidy() %&gt;% kableExtra::kbl(digits = 4) %&gt;% kableExtra::kable_styling() term estimate std.error statistic p.value (Intercept) 1.0900 0.0464 23.5090 0 height 0.1014 0.0032 31.7895 0 plot this conifer_trees %&gt;% ggplot(mapping = aes(x = height, y = CrownRadius)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + theme_light() + theme(legend.position = &quot;none&quot;) what about a non-linear model? crown_height_model &lt;- brms::brm( formula = brms::bf( formula = CrownRadius ~ (b1 * height) + height^b2 , b1 + b2 ~ 1 , nl = TRUE # !! specify non-linear ) , data = conifer_trees , family = brms::brmsfamily(&quot;Gamma&quot;) , iter = 6000, warmup = 3000, chains = 4 , cores = lasR::half_cores() , file = &quot;../data/crown_height_model&quot; ) # plot(crown_height_model) summary(crown_height_model) ## Family: gamma ## Links: mu = log; shape = identity ## Formula: CrownRadius ~ (b1 * height) + height^b2 ## b1 ~ 1 ## b2 ~ 1 ## Data: conifer_trees (Number of observations: 2750) ## Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1; ## total post-warmup draws = 12000 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## b1_Intercept 0.04 0.00 0.04 0.05 1.00 5784 6848 ## b2_Intercept -0.55 0.03 -0.61 -0.51 1.00 5397 5756 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.72 0.15 5.43 6.02 1.00 6131 5494 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ## write out model estimates to tabular file #### extract posterior draws to a df brms::as_draws_df( crown_height_model , variable = c(&quot;^b_&quot;, &quot;shape&quot;) , regex = TRUE ) %&gt;% # quick way to get a table of summary statistics and diagnostics posterior::summarize_draws( &quot;mean&quot;, &quot;median&quot;, &quot;sd&quot; , ~quantile(.x, probs = c( 0.05, 0.95 , 0.025, 0.975 )) , &quot;rhat&quot; ) %&gt;% dplyr::mutate( variable = stringr::str_remove_all(variable, &quot;_Intercept&quot;) , formula = summary(crown_height_model)$formula %&gt;% as.character() %&gt;% .[1] ) %&gt;% write.csv( &quot;../data/crown_height_model.csv&quot; , row.names = F ) plot this plot(brms::conditional_effects(crown_height_model), points = T) what if we try to plot it with a function using the regression coefficients? ws_fn &lt;- function(x) { y = dplyr::case_when( is.na(x) ~ 1e-3 # requires non-null , x &lt; 0 ~ 1e-3 # requires positive , x &lt; 2.5 ~ 1 # set lower bound , x &gt; 40 ~ 6.7 # set upper bound # , TRUE ~ 0.75 + (x * 0.14) , TRUE ~ exp( (0.0446*x) + (x^-0.555) ) # used gamma regression so exp the result ) return(y) } plot it ggplot2::ggplot() + ggplot2::xlim(0,60) + ggplot2::ylim(0,NA) + ggplot2::geom_point(data = conifer_trees, mapping = aes(y = CrownRadius, x = height)) + ggplot2::geom_function(fun = ws_fn, lwd = 1.5, color = &quot;blue&quot;) NeonTreeEvaluation::get_data is a set of utility functions for finding the path of benchmark data on disk NeonTreeEvaluation::get_data(plot_name = &quot;RMNP_047&quot;, type = &quot;lidar&quot;) ## [1] &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extdata/NeonTreeEvaluation/evaluation/LiDAR/RMNP_047.laz&quot; let’s pull out all sites with .laz data and create a data frame for tracking purposes las_df &lt;- paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = T) %&gt;% unique() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(f_path = 1) %&gt;% # create some other variables dplyr::mutate( f_nm = f_path %&gt;% basename() %&gt;% stringr::str_remove_all(&quot;\\\\.(laz|las)$&quot;) , plot_nm = f_nm %&gt;% # this matches the file name with the plot name toupper() %&gt;% stringr::str_extract( pattern = NeonTreeEvaluation::list_field_stems() %&gt;% toupper() %&gt;% paste(collapse = &quot;|&quot;) ) , neon_site = plot_nm %&gt;% stringr::word(start = 1, sep = fixed(&quot;_&quot;)) ) %&gt;% dplyr::filter(!is.na(plot_nm)) %&gt;% # keep only las files with field stems dplyr::select(neon_site, plot_nm, f_nm, f_path) # what? las_df %&gt;% dplyr::glimpse() ## Rows: 278 ## Columns: 4 ## $ neon_site &lt;chr&gt; &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;BART&quot;, &quot;BART&quot;, &quot;BAR… ## $ plot_nm &lt;chr&gt; &quot;ABBY_003&quot;, &quot;ABBY_008&quot;, &quot;ABBY_010&quot;, &quot;ABBY_023&quot;, &quot;ABBY_068&quot;, … ## $ f_nm &lt;chr&gt; &quot;ABBY_003_2018&quot;, &quot;ABBY_008_2018&quot;, &quot;ABBY_010_2018&quot;, &quot;ABBY_023… ## $ f_path &lt;chr&gt; &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extda… 2.1.1 Explore LiDAR data from package which NEON sites have data? las_df %&gt;% dplyr::count(neon_site) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::mutate(neon_site = forcats::fct_reorder(neon_site, n)) %&gt;% # plot ggplot(aes(y = neon_site, x = n, fill = n)) + geom_col(width = 0.7) + labs(y = &quot;NEON site&quot;, x = &quot;lidar data plots&quot;) + harrypotter::scale_fill_hp(&quot;slytherin&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) where is this data? get_site_bbox &lt;- function(site, dta = las_df) { # read the las files for a site las_ctg = dta %&gt;% dplyr::filter(neon_site == site) %&gt;% dplyr::pull(f_path) %&gt;% lidR::readLAScatalog() # bbox that site if( is.na( sf::st_crs(las_ctg@data) ) ){ return(NULL) }else{ las_ctg@data %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(neon_site = site) %&gt;% sf::st_set_crs(sf::st_crs(las_ctg@data)) %&gt;% sf::st_transform(crs = paste0(&quot;EPSG:&quot;, 5070)) } } # take this for a spin las_df %&gt;% dplyr::pull(neon_site) %&gt;% unique() %&gt;% purrr::map(get_site_bbox) %&gt;% dplyr::bind_rows() %&gt;% dplyr::left_join( las_df %&gt;% dplyr::group_by(neon_site) %&gt;% dplyr::summarise(n = dplyr::n()) , by = &quot;neon_site&quot; ) %&gt;% st_centroid() %&gt;% mapview::mapview( zcol = &quot;n&quot; , layer.name = &quot;LiDAR plots&quot; , label = c(&quot;neon_site&quot;) , col.regions = viridis::mako(10, direction = -1) ) load one las data f_temp = las_df %&gt;% dplyr::slice_sample(n = 1) %&gt;% dplyr::pull(f_path) las_temp = lidR::readLAS(f_temp) # quick summary las_temp ## class : LAS (v1.3 format 3) ## memory : 2.5 Mb ## extent : 304694.8, 304734.8, 5122894, 5122934 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 16N ## area : 1675 m² ## points : 26.8 thousand points ## density : 16 points/m² ## density : 4.68 pulses/m² # data str las_temp@data %&gt;% dplyr::glimpse() ## Rows: 26,803 ## Columns: 22 ## $ X &lt;dbl&gt; 304734.5, 304734.1, 304734.2, 304733.4, 304733.6, 30… ## $ Y &lt;dbl&gt; 5122894, 5122894, 5122894, 5122894, 5122894, 5122894… ## $ Z &lt;dbl&gt; 506.85, 506.05, 504.44, 508.76, 506.31, 505.63, 504.… ## $ gpstime &lt;dbl&gt; 400667.5, 400667.5, 400667.5, 400667.5, 400667.5, 40… ## $ Intensity &lt;int&gt; 19, 22, 6, 14, 18, 47, 51, 61, 26, 51, 42, 57, 32, 1… ## $ ReturnNumber &lt;int&gt; 3, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 2, 3, 4, 3… ## $ NumberOfReturns &lt;int&gt; 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 5, 1, 2, 5, 1, 1, 2, 5, 5, 1, 5, 5, 5, 2, 5, 5, 2, 1… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4… ## $ UserData &lt;int&gt; 23, 16, 0, 43, 19, 12, 0, 42, 26, 2, 42, 36, 28, 0, … ## $ PointSourceID &lt;int&gt; 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, … ## $ R &lt;int&gt; 33280, 22272, 26368, 23040, 23808, 24576, 26624, 240… ## $ G &lt;int&gt; 30720, 20224, 27136, 25600, 23296, 25856, 30976, 245… ## $ B &lt;int&gt; 28416, 21760, 28928, 26112, 27136, 29184, 32256, 271… ## $ TargetThick &lt;dbl&gt; 0.344, 0.400, 0.176, 0.440, 0.000, 0.144, 0.192, 0.2… ## $ RangeErr &lt;dbl&gt; 0.019, 0.034, 0.075, 0.036, 0.013, 0.005, 0.006, 0.0… ## $ DevRatio &lt;dbl&gt; 1.0, 1.8, 1.8, 0.8, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 0.… summarize x, y, z las_temp@data %&gt;% dplyr::select(X,Y,Z) %&gt;% summary() ## X Y Z ## Min. :304695 Min. :5122894 Min. :500.3 ## 1st Qu.:304705 1st Qu.:5122906 1st Qu.:509.4 ## Median :304715 Median :5122916 Median :516.9 ## Mean :304715 Mean :5122916 Mean :516.7 ## 3rd Qu.:304726 3rd Qu.:5122926 3rd Qu.:523.4 ## Max. :304735 Max. :5122934 Max. :532.0 plot this las plot3D::scatter3D( x = las_temp@data$X , y = las_temp@data$Y , z = las_temp@data$Z , colvar = las_temp@data$Z , pch = 19, cex = 0.3 , colkey = F , phi = 0.5 ) let’s look at the classification (see table 5 here) las_temp@data %&gt;% dplyr::count(Classification) ## Classification n ## &lt;int&gt; &lt;int&gt; ## 1: 1 2954 ## 2: 2 1171 ## 3: 5 22678 plot color by classification plot3D::scatter3D( x = las_temp@data$X , y = las_temp@data$Y , z = las_temp@data$Z , colvar = las_temp@data$Classification , pch = 19, cex = 0.3 , colkey = F , phi = 0.5 ) 2.2 cloud2trees The cloud2trees package provides routines for processing point cloud data (.las|.laz format) to detect forest trees. let’s use it for one of the data sets from a conifer forest in the NeonTreeEvaluation benchmark # get one file (f_temp &lt;- las_df %&gt;% dplyr::filter(neon_site==&quot;RMNP&quot;) %&gt;% # rocky mtn national park dplyr::slice_sample(n = 1) %&gt;% dplyr::pull(f_path)) ## [1] &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extdata/NeonTreeEvaluation/evaluation/LiDAR/RMNP_004_2018.laz&quot; # read in the data las_temp &lt;- lidR::readLAS(f_temp) what is this data? las_temp@data %&gt;% dplyr::glimpse() ## Rows: 34,958 ## Columns: 16 ## $ X &lt;dbl&gt; 453936.8, 453936.4, 453935.9, 453935.4, 453934.7, 45… ## $ Y &lt;dbl&gt; 4448642, 4448642, 4448642, 4448642, 4448642, 4448642… ## $ Z &lt;dbl&gt; 2810.070, 2810.102, 2810.158, 2810.143, 2810.960, 28… ## $ gpstime &lt;dbl&gt; 410616.9, 410616.9, 410616.9, 410616.9, 410616.9, 41… ## $ Intensity &lt;int&gt; 145, 318, 330, 310, 55, 239, 118, 130, 20, 88, 20, 1… ## $ ReturnNumber &lt;int&gt; 4, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2… ## $ NumberOfReturns &lt;int&gt; 4, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2, 4, 4, 4, 4, 4… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 2, 2, 2, 2, 1, 2, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; 16, 16, 16, 16, 16, 16, 16, 16, 17, 16, 16, 16, 16, … ## $ UserData &lt;int&gt; 0, 0, 0, 0, 9, 0, 10, 0, 103, 104, 91, 92, 75, 100, … ## $ PointSourceID &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, … We can plot the point cloud with and color by the point height lidR::plot( las_temp , color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) notice the Z values are in meters above sea level 2.2.1 Get tree list and normalized cloud We’ll use the cloud2trees::cloud2trees() function to get a tree list from the lidar data with a regional estimate of the DBH because we enabled the estimate_tree_dbh parameter. Also returned is a canopy height model (CHM) raster and because we enabled the keep_intrmdt parameter we’ll get the normalized point cloud data as well. cloud2trees_ans &lt;- cloud2trees::cloud2trees( input_las_dir = f_temp , output_dir = &quot;../data&quot; , estimate_tree_dbh = T , keep_intrmdt = T ) let’s see what we got names(cloud2trees_ans) ## [1] &quot;crowns_sf&quot; &quot;treetops_sf&quot; &quot;dtm_rast&quot; &quot;chm_rast&quot; we got a CHM # could make an easy plot with... # terra::plot(cloud2trees_ans$chm_rast) # ...but we&#39;ll customize and save it as our base plot plt_chm &lt;- ggplot() + geom_tile( data = cloud2trees_ans$chm_rast %&gt;% as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = aes(x=x,y=y,fill=f) ) + harrypotter::scale_fill_hp(&quot;gryffindor&quot;, name = &quot;height (m)&quot;) + theme_light() + theme( axis.text = element_blank() ) # view plt_chm we also got tree top points plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) and we got tree crowns plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) + geom_sf(data = cloud2trees_ans$crowns_sf, fill = NA, color = &quot;steelblue&quot;) there is data on the individual trees in the crowns and tree tops data (which are the same data but one spaltial polygons and the other is spatial points). cloud2trees_ans$crowns_sf %&gt;% dplyr::glimpse() ## Rows: 245 ## Columns: 20 ## $ treeID &lt;chr&gt; &quot;1_453963.6_4448653.4&quot;, &quot;2_453965.1_4448653.… ## $ tree_height_m &lt;dbl&gt; 7.549, 4.914, 5.828, 6.106, 6.989, 6.549, 7.… ## $ tree_x &lt;dbl&gt; 453963.6, 453965.1, 453953.1, 453957.1, 4539… ## $ tree_y &lt;dbl&gt; 4448653, 4448653, 4448653, 4448653, 4448653,… ## $ crown_area_m2 &lt;dbl&gt; 1.8750, 0.8125, 0.5625, 0.5625, 0.5625, 0.75… ## $ geometry &lt;GEOMETRY [m]&gt; POLYGON ((453963.5 4448654,..., POL… ## $ fia_est_dbh_cm &lt;dbl&gt; 9.857196, 6.857835, 7.875589, 8.261772, 9.23… ## $ fia_est_dbh_cm_lower &lt;dbl&gt; 4.714820, 3.335065, 3.800855, 4.090477, 4.52… ## $ fia_est_dbh_cm_upper &lt;dbl&gt; 16.281707, 11.436202, 13.080811, 13.739062, … ## $ dbh_cm &lt;dbl&gt; 9.857196, 6.857835, 7.875589, 8.261772, 9.23… ## $ is_training_data &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… ## $ dbh_m &lt;dbl&gt; 0.09857196, 0.06857835, 0.07875589, 0.082617… ## $ radius_m &lt;dbl&gt; 0.04928598, 0.03428917, 0.03937795, 0.041308… ## $ basal_area_m2 &lt;dbl&gt; 0.007631268, 0.003693720, 0.004871425, 0.005… ## $ basal_area_ft2 &lt;dbl&gt; 0.08214297, 0.03975920, 0.05243602, 0.057704… ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … let’s check the height to DBH relationship cloud2trees_ans$crowns_sf %&gt;% ggplot(mapping = aes(x = tree_height_m, y = dbh_cm)) + geom_point(color = &quot;navy&quot;) + labs(x = &quot;height (m)&quot;, y = &quot;DBH (cm)&quot;) + theme_light() this all looks great. let’s check the normalized point cloud. for that we’ll dig in the output directory from the cloud2trees::cloud2trees() function (see that output_dir parameter). (n_f_temp &lt;- list.files( &quot;../data/point_cloud_processing_temp/02_normalize/&quot; , pattern = &quot;.las&quot; , full.names = T )) ## [1] &quot;../data/point_cloud_processing_temp/02_normalize/RMNP_004_2018_normalize.las&quot; # read in the data nlas_temp &lt;- lidR::readLAS(n_f_temp) plot it to check that it is height normalized lidR::plot( nlas_temp , color = &quot;Z&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) nice! let’s remove the ground points to check out potential vegetation nlas_temp %&gt;% lidR::filter_poi(Classification!=2) %&gt;% lidR::plot( color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) that’s a great workflow, guy. i’m not your guy, buddy. 2.3 LadderFuelsR The LadderFuelsR package (Viedma et al. 2024) is described as enabling the use of “LiDAR data and the LadderFuelsR package…[to] provide an automated tool for analysing the vertical fuel structure of a forest and to calculate crown base height (CBH) at tree-level, among other parameters” (p.1). let’s check what’s in this package lsf.str(&quot;package:LadderFuelsR&quot;) ## calculate_gaps_perc : function (LAD_profiles, min_height = 1.5) ## get_cbh_metrics : function (effective_LAD, min_height = 1.5, hdepth1_height = 2.5, verbose = TRUE) ## get_cum_break : function (LAD_profiles, cbh_metrics, threshold = 75, min_height = 1.5, ## verbose = TRUE) ## get_depths : function (LAD_profiles, distance_metrics, step = 1, min_height = 1.5, verbose = TRUE) ## get_distance : function (gap_cbh_metrics, gaps_perc, step = 1, min_height = 1.5, verbose = TRUE) ## get_effective_gap : function (effective_depth, number_steps = 1, min_height = 1.5, verbose = TRUE) ## get_gaps_fbhs : function (LAD_profiles, step = 1, min_height = 1.5, perc_gap = 25, perc_base = 25, ## verbose = TRUE) ## get_layers_lad : function (LAD_profiles, effective_distances, threshold = 10, step = 1, ## min_height = 1.5, verbose = TRUE) ## get_plots_cbh_bp : function (LAD_profiles, cummulative_LAD, min_height = 1.5) ## get_plots_cbh_LAD : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_cbh_lastdist : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_cbh_maxdist : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_effective : function (LAD_profiles, effective_LAD, min_height = 1.5) ## get_plots_gap_fbh : function (LAD_profiles, gap_cbh_metrics, min_height = 1.5) ## get_real_depths : function (effective_fbh, step = 1, min_height = 1.5, verbose = TRUE) ## get_real_fbh : function (depth_metrics, step = 1, number_steps = 1, min_height = 1.5, ## verbose = TRUE) ## get_renamed_df : function (df) ## get_renamed0_df : function (df) 2.3.1 Prep for the package For this package we need to do some cleaning of our las data and our polygon crown data. We need to attach the treeID column from our spatial crowns to the las data using lidR::merge_spatial(). This function allows for only polygons so we need to get rid of the multipolygons in the crown data. We’ll keep the largest part of the multipolygon as the smaller part is usually a residual pixel from the CHM. We also generate a tree_index as a numeric id which is needed by the LadderFuelsR package since treeID is character. # the lidR::merge_spatial requires only polygons so we need to rid the multipolygons crowns_sf_poly &lt;- # start with only polygons cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(geometry)==&quot;POLYGON&quot;) %&gt;% # union on cleaned multipolygons dplyr::bind_rows( cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(geometry)==&quot;MULTIPOLYGON&quot;) %&gt;% sf::st_cast(to = &quot;POLYGON&quot;, do_split = T, warn = F) %&gt;% dplyr::mutate(axxx = sf::st_area(geometry)) %&gt;% # axxx is so we don&#39;t overwrite a column dplyr::group_by(treeID) %&gt;% dplyr::filter(axxx == max(axxx)) %&gt;% # keep the biggest crown polygon by treeID dplyr::ungroup() %&gt;% dplyr::select(-axxx) ) %&gt;% # generate a treeID index because it needs to be numeric dplyr::ungroup() %&gt;% dplyr::mutate(tree_index = dplyr::row_number()) does it look good? plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) + geom_sf(data = crowns_sf_poly, fill = NA, color = &quot;steelblue&quot;) now we’ll attach the treeID column to the normalized las file and keep only the points that fall within a tree crown. crowns_nlas_temp &lt;- lidR::merge_spatial( las = nlas_temp , source = crowns_sf_poly , attribute = &quot;tree_index&quot; ) %&gt;% lidR::filter_poi(!is.na(tree_index)) %&gt;% lidR::filter_poi(Classification!=2) # what is this data? crowns_nlas_temp@data %&gt;% dplyr::glimpse() ## Rows: 12,122 ## Columns: 17 ## $ X &lt;dbl&gt; 453936.6, 453936.5, 453935.8, 453936.1, 453936.6, 45… ## $ Y &lt;dbl&gt; 4448642, 4448642, 4448642, 4448642, 4448642, 4448642… ## $ Z &lt;dbl&gt; 10.419, 9.239, 10.006, 8.787, 7.091, 8.389, 7.765, 5… ## $ gpstime &lt;dbl&gt; 410616.9, 410616.9, 410616.9, 410616.9, 410616.9, 41… ## $ Intensity &lt;int&gt; 88, 126, 24, 140, 41, 22, 57, 55, 45, 168, 33, 25, 2… ## $ ReturnNumber &lt;int&gt; 1, 1, 1, 2, 3, 1, 2, 3, 2, 2, 3, 4, 2, 3, 1, 2, 1, 1… ## $ NumberOfReturns &lt;int&gt; 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 2, 3… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, … ## $ UserData &lt;int&gt; 104, 92, 100, 88, 71, 84, 78, 57, 51, 52, 36, 21, 29… ## $ PointSourceID &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, … ## $ tree_index &lt;int&gt; 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, … plot the las data colored by tree_index crowns_nlas_temp %&gt;% lidR::plot( color = &quot;tree_index&quot;, bg = &quot;white&quot;, legend = F , pal = viridis::turbo( n = crowns_nlas_temp@data$tree_index %&gt;% # this whole thing gets n unique colors unique() %&gt;% length() %&gt;% `*`(2) # with some separation between the hues ) %&gt;% sample( crowns_nlas_temp@data$tree_index %&gt;% unique() %&gt;% length() ) ) check it for one tree crowns_nlas_temp %&gt;% lidR::filter_poi( tree_index == # get the tree with the most points crowns_nlas_temp@data %&gt;% dplyr::count(tree_index) %&gt;% dplyr::filter(n == max(n)) %&gt;% dplyr::slice_head(n=1) %&gt;% dplyr::pull(tree_index) ) %&gt;% lidR::plot(color = &quot;tree_index&quot;, bg = &quot;white&quot;, legend = F) interesting, with more dense point clouds this would look more like a tree 2.3.2 Defining function for computing crown-level metrics Not sure how necessary this is, but pulling it from the package README notice, none of these functions utilize the intensity, or “i”, parameter custom_crown_metrics &lt;- function(z, i) { # user-defined function metrics &lt;- list( dz = 1, th = 1, z_max = max(z),# max height z_min = min(z),# min height z_mean = mean(z),# mean height z_sd = sd(z), # vertical variability of points z_q1=quantile(z, probs = 0.01), z_q5=quantile(z, probs = 0.05), z_q25=quantile(z, probs = 0.25), z_q50=quantile(z, probs = 0.50), z_q75=quantile(z, probs = 0.75), z_q95=quantile(z, probs = 0.95), crr=(mean(z)-min(z))/(max(z)-min(z)) ) return(metrics) # output } # idk why they did this...just for shorthand? just define it like that from the start # ccm = ~custom_crown_metrics(z = Z, i = Intensity) 2.3.3 Computing crown level standard metrics within all trees detected let’s see how they do it from the package README first, calculate metrics from the las data by tree (with code updates by gw) # setting a minimum Z height to look at crown metrics fcrowns_nlas_temp &lt;- lidR::filter_poi(crowns_nlas_temp, Z &gt;= 1) # Metric derivation at different levels of regularization crowns_metrics_df &lt;- # gw updated this to do it all at once lidR::crown_metrics( las = fcrowns_nlas_temp , func = .stdtreemetrics # stdtreemetrics is a lidR predefined function for tree-based metrics , geom = &quot;convex&quot; # Geometry type of the output , attribute = &quot;tree_index&quot; ) %&gt;% dplyr::left_join( lidR::crown_metrics( las = fcrowns_nlas_temp , func = ~ custom_crown_metrics(z = Z) # the custom function defined above , geom = &quot;convex&quot; # Geometry type of the output , attribute = &quot;tree_index&quot; ) %&gt;% sf::st_drop_geometry() , by = &quot;tree_index&quot; ) %&gt;% # define crown diameter dplyr::mutate( crown_diam = sqrt(convhull_area/ pi) * 2 ) # a df, ok crowns_metrics_df %&gt;% dplyr::glimpse() ## Rows: 240 ## Columns: 19 ## $ tree_index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 1… ## $ Z &lt;dbl&gt; 9.196, 5.680, 6.439, 6.316, 8.224, 7.145, 8.062, 6.985, … ## $ npoints &lt;int&gt; 51, 13, 8, 6, 10, 17, 30, 18, 48, 19, 64, 39, 26, 29, 8,… ## $ convhull_area &lt;dbl&gt; 1.578, 0.439, 0.185, 0.136, 0.278, 0.420, 0.803, 0.649, … ## $ dz &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ th &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ z_max &lt;dbl&gt; 9.196, 5.680, 6.439, 6.316, 8.224, 7.145, 8.062, 6.985, … ## $ z_min &lt;dbl&gt; 1.401, 2.027, 5.122, 5.691, 4.114, 3.858, 1.296, 1.856, … ## $ z_mean &lt;dbl&gt; 5.408255, 4.115462, 5.743125, 5.936500, 6.302400, 5.7329… ## $ z_sd &lt;dbl&gt; 1.9586285, 1.2300555, 0.4851655, 0.2364883, 1.2844097, 1… ## $ z_q1 &lt;dbl&gt; 1.49850, 2.07476, 5.13719, 5.69330, 4.12039, 3.92120, 1.… ## $ z_q5 &lt;dbl&gt; 2.34850, 2.26580, 5.19795, 5.70250, 4.14595, 4.17400, 2.… ## $ z_q25 &lt;dbl&gt; 3.80450, 3.02500, 5.40950, 5.76725, 6.03500, 4.87600, 4.… ## $ z_q50 &lt;dbl&gt; 5.8750, 4.3910, 5.6725, 5.8845, 6.5675, 5.7410, 5.4025, … ## $ z_q75 &lt;dbl&gt; 6.90550, 4.91400, 5.98075, 6.05725, 6.97575, 6.76100, 6.… ## $ z_q95 &lt;dbl&gt; 7.92350, 5.60140, 6.43900, 6.26350, 7.74025, 7.13940, 7.… ## $ crr &lt;dbl&gt; 0.5140802, 0.5717113, 0.4716211, 0.3928000, 0.5324574, 0… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((453964.7 4448653,..., POLYGON ((453965… ## $ crown_diam &lt;dbl&gt; 1.4174526, 0.7476310, 0.4853342, 0.4161257, 0.5949459, 0… what “tree-based metrics” come from the .stdtreemetrics? maybe maximum Z, number of points, and crown area…not sure how useful these are for defining CBH. we shall see. the “z_” metrics are neat. does every crown have some crown metrics? # has the same number of trees as our crown polygons? dplyr::tibble( crowns_sf_poly_trees = nrow(crowns_sf_poly) , crowns_nlas_trees = fcrowns_nlas_temp@data$tree_index %&gt;% unique() %&gt;% length() , crowns_metrics_df_trees = nrow(crowns_metrics_df) ) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() crowns_sf_poly_trees crowns_nlas_trees crowns_metrics_df_trees 245 245 240 guess not. let’s look at some of those metrics and the convex hull polygons created by the lidR::crown_metrics() plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = z_mean), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) note the overlap of those polygons. what if we attach the crown metrics to the original crown polygons? plt_chm + ggnewscale::new_scale_fill() + geom_sf( data = crowns_sf_poly %&gt;% dplyr::left_join( crowns_metrics_df %&gt;% sf::st_drop_geometry() , by = &quot;tree_index&quot; ) , mapping = aes(fill = z_mean), color = &quot;steelblue&quot; ) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8, na.value = &quot;black&quot;) what is this crr=(mean(z)-min(z))/(max(z)-min(z)) variable? plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = crr), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) how about crown diameter? plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = crown_diam), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) 2.3.4 LAI-LAD metrics by Trees see this section of the package README after height normalization and crown segmentation, the LiDAR returns were cropped with the crown contours being voxelized to obtain VHPs from which the absolute mean LAD at each height bin was retrieved (de Almeida et al., 2019) (p.2). in this section, the las files cropped to individual trees (i.e. one tree at a time) are passed to the leafR package to calculate the LAI-LAD metrics. it seems very inefficient to perform this one-by-one for individual tree point clouds and not something that would work well if many, many trees. let’s go through the process for one tree point cloud # leafR::lad.voxels requires a file location :\\ fn &lt;- paste0(tempdir(), &quot;/temp.las&quot;) # let&#39;s sample the tree with the most points ti &lt;- crowns_nlas_temp@data %&gt;% dplyr::count(tree_index) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::slice_head(n=1) %&gt;% dplyr::pull(tree_index) f &lt;- crowns_nlas_temp %&gt;% lidR::filter_poi(tree_index == ti) %&gt;% # put this in a function and map over trees lidR::writeLAS(file = fn) 2.3.4.1 leafR::lad.voxels Creates a data frame of the 3D voxels information (xyz) with Leaf Area Density values from las file. ##### leafR::lad.voxels # Creates a data frame of the 3D voxels information (xyz) with Leaf Area Density values from las file lad_voxels &lt;- leafR::lad.voxels( # normlas.file requires a file location :\\ normlas.file = f , grain.size = 2 ) class(lad_voxels) ## [1] &quot;list&quot; str(lad_voxels) ## List of 2 ## $ LAD : num [1:12, 1:18] NA 0 0.0267 0 NA ... ## $ coordenates:&#39;data.frame&#39;: 12 obs. of 2 variables: ## ..$ X: num [1:12] 453955 453957 453959 453961 453955 ... ## ..$ Y: num [1:12] 4448624 4448624 4448624 4448624 4448622 ... 2.3.4.2 leafR::lad.profile This function calculate the lad profile from the input lad.voxels. By “profile” I think they mean “vertical height profile” ##### leafR::lad.profile # This function calculate the lad profile from the input lad.voxels lad_profile &lt;- leafR::lad.profile(lad_voxels, relative = F) class(lad_profile) ## [1] &quot;data.frame&quot; str(lad_profile) ## &#39;data.frame&#39;: 18 obs. of 2 variables: ## $ height: num 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 ... ## $ lad : num 1.099 0.764 0.519 0.275 0.364 ... 2.3.4.3 leafR::lai calculates the lead area index (LAI) lai_tot &lt;- leafR::lai(lad_profile) lai_understory &lt;- leafR::lai(lad_profile, min = 0.3, max = 2.5) class(lai_tot) ## [1] &quot;numeric&quot; str(lai_tot) ## num 4.66 str(lai_understory) ## num 1.86 2.3.4.4 leafR::LAHV Calculates the leaf area height volume (LAHV) metric as described in Almeida et al. (2019) lahv_metric &lt;- leafR::LAHV(lad_profile, LAI.weighting = FALSE, height.weighting = FALSE) class(lahv_metric) ## [1] &quot;numeric&quot; str(lahv_metric) ## num 24.4 2.3.4.5 Bring together and clean they call this “Depurating Tree LAD profiles” replace missing LAD values with 0.01 (no explanation of “why”) keep only trees where there are at least 6 profile (vertical height profile) records (&gt;5) leafr_df &lt;- dplyr::tibble( tree_index = ti # put this in a function and map over trees ) %&gt;% dplyr::bind_cols(lad_profile) %&gt;% dplyr::mutate( lad = dplyr::coalesce(lad, 0.01) # not sure why they put in 0.01 here , lai_tot = lai_tot[1] , lai_understory = lai_understory[1] , lahv = lahv_metric[1] , vhp_n = dplyr::n() # they keep trees where there are at least 6 (&gt;5) ) %&gt;% dplyr::arrange(tree_index, height) what is this? leafr_df %&gt;% dplyr::glimpse() ## Rows: 18 ## Columns: 7 ## $ tree_index &lt;int&gt; 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, … ## $ height &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5… ## $ lad &lt;dbl&gt; 1.09861229, 0.76367463, 0.51878210, 0.27533286, 0.36442… ## $ lai_tot &lt;dbl&gt; 4.657606, 4.657606, 4.657606, 4.657606, 4.657606, 4.657… ## $ lai_understory &lt;dbl&gt; 1.862287, 1.862287, 1.862287, 1.862287, 1.862287, 1.862… ## $ lahv &lt;dbl&gt; 24.40711, 24.40711, 24.40711, 24.40711, 24.40711, 24.40… ## $ vhp_n &lt;int&gt; 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,… seems like the data used to create Figure 1 (b) leafr_df %&gt;% ggplot(mapping = aes(x = lad, y = height)) + geom_path() + geom_point() + theme_light() what about the point cloud in voxels? # calculate voxel metrics voxel_metrics( crowns_nlas_temp %&gt;% lidR::filter_poi(tree_index == ti) , ~list(N = length(Z)) , 2 ) %&gt;% lidR::plot( color=&quot;N&quot;, pal = viridis::mako(n = 11, direction = -1) , size = 2, bg = &quot;white&quot;, voxel = TRUE, legend = T ) 2.3.5 Gaps and Fuel Layers Base Height (FBH) see this section of the package README uses the LAD profiles derived from normalized point cloud data after applying leafR::lad.profile() function and passes this data to the LadderFuelsR::get_gaps_fbhs() function to: calculates gaps and fuel layers base height (FBH) as the difference in percentiles between consecutive LAD values along the vertical tree profile (VTP). Negative differences are linked to gaps and positive differences to fuel base height. ### this function is broken!!!!!!!!!!!!!!!!!!!!!!!!!! gaps_fbhs &lt;- get_gaps_fbhs( LAD_profiles = leafr_df %&gt;% dplyr::filter(tree_index == ti) %&gt;% # # it looks like this function requires the treeID column dplyr::mutate(treeID = factor(tree_index)) %&gt;% dplyr::select(treeID, height, lad) , step=1 , min_height=1.5 , perc_gap= 25, perc_base= 25 , verbose=TRUE ) # Remove the row with all NA values from the original data frame # First remove &quot;treeID&quot; and &quot;treeID1&quot; columns gaps_fbhs_list1_no_treeID &lt;- gaps_fbhs_list1[, -which(names(gaps_fbhs_list1) == c(&quot;treeID&quot;,&quot;treeID1&quot;))] # Check if any row has all NA values rows_with_all_NA_or_zero &lt;- apply(gaps_fbhs_list1_no_treeID, 1, function(row) all(is.na(row) | row == 0)) # Get the row index with all NA values row_index &lt;- which(rows_with_all_NA_or_zero) # Remove the row with all NA values from the original data frame if (length(row_index) &gt; 0) { gaps_fbhs_metrics &lt;- gaps_fbhs_list1[-row_index, ] } else { gaps_fbhs_metrics &lt;- gaps_fbhs_list1 } rownames(gaps_fbhs_metrics) &lt;- NULL head(gaps_fbhs_metrics) 2.3.6 CBH based on different criteria: maximum LAD, maximum and last distance there is a bunch of other stuff that i’m not quite sure how useful it is for our purposes but we’ll skip to this section of the package README # Tree metrics derived from get_layers_lad() function LAD_gt10p &lt;- fuels_LAD_metrics[[2]] trees_name1 &lt;- as.character(LAD_gt10p$treeID) trees_name2 &lt;- factor(unique(trees_name1)) cbh_metrics_list &lt;- list() for (j in levels(trees_name2)){ # Filter data for each tree tree1 &lt;- LAD_gt10p |&gt; dplyr::filter(treeID == j) cbh_metrics &lt;- get_cbh_metrics(tree1,min_height= 1.5) cbh_metrics_list[[j]] &lt;- cbh_metrics } # Combine depth values for all trees cbh_metrics_all &lt;- dplyr::bind_rows(cbh_metrics_list) # Get original column names original_column_names &lt;- colnames(cbh_metrics_all) # Specify prefixes desired_order &lt;- c(&quot;treeID&quot;, &quot;Hcbh&quot;, &quot;dptf&quot;,&quot;effdist&quot;,&quot;dist&quot;, &quot;Hdist&quot;, &quot;Hdptf&quot;,&quot;maxlad_&quot;,&quot;max_&quot;,&quot;last_&quot;,&quot;nlayers&quot;) # Identify unique prefixes prefixes &lt;- unique(sub(&quot;^([a-zA-Z]+).*&quot;, &quot;\\\\1&quot;, original_column_names)) # Initialize vector to store new order new_order &lt;- c() # Loop over desired order of prefixes for (prefix in desired_order) { # Find column names matching the current prefix matching_columns &lt;- grep(paste0(&quot;^&quot;, prefix), original_column_names, value = TRUE) # Append to the new order new_order &lt;- c(new_order, matching_columns) } # Reorder columns cbh_metrics_all &lt;- cbh_metrics_all[, new_order] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
