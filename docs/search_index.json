[["index.html", "Aerial LiDAR for Fire Model Inputs Section 1 Introduction 1.1 Objective 1.2 Data", " Aerial LiDAR for Fire Model Inputs George Woolsey 05 December, 2024 Section 1 Introduction Code in support of “Using aerial LiDAR data for object-based physical fire modeling in conifer forests of the southwestern US” 1.1 Objective The objective of this study is to demonstrate the use of aerial LiDAR data to create inputs for physics-based fire models in frequent-fire forests of the southwestern United States. We review the methods used to extract tree location, species, and physical form from aerial LiDAR data. We evaluate this canopy crown detection methodology using a benchmark data set created to standardize evaluation metrics (Weinstein et al. 2021). We explain how to format this data for seamless integration with two commonly used object-based physical fire modeling tools. We demonstrate the end-to-end process using a case study from the southwestern United States. 1.2 Data LiDAR data from the southwest US "],["s01.html", "Section 2 Data Load and Methods Explore 2.1 NeonTreeEvaluation 2.2 cloud2trees 2.3 LadderFuelsR 2.4 LadderFuelsR - simplified", " Section 2 Data Load and Methods Explore In this section we’ll review the packages we’ll be using to process and evaluate the lidar data. None of the analysis is happening here, just reviewing the methodologies. Load the standard libraries # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(ggnewscale) # ggnewscale library(plot3D) # 3d plotting library(rgl) # rgl plotting # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data # models library(brms) # bayesian modelling # utilities library(rvest) # web scraping Load the libraries from GitHub. Here we’ll load: NeonTreeEvaluation: benchmark data set to evaluate lidar-based tree detection (Weinstein et al. 2021) cloud2trees: routines for processing point cloud data collected by airborne lidar to detect forest trees (Woolsey and Tinkham, 2024) LadderFuelsR: vertical fuel continuity quantification and crown base height (CBH) calculation (Viedma et al. 2024) lasR: complex processing pipelines on lidar data (Roussel 2024) leafR: set of functions for analyzing the ecological structure of forests based on LAI and LAD measures derived from LiDAR data (Roussel 2024). Data from this package used in the LadderFuelsR workflow even though this process is never explained by Viedma et al. 2024. library(pak) # load them c(&quot;NeonTreeEvaluation&quot;, &quot;cloud2trees&quot;, &quot;LadderFuelsR&quot;, &quot;lasR&quot;, &quot;leafR&quot;) %&gt;% # install and load purrr::map(function(x){ # locations df &lt;- dplyr::tibble( p = c(&quot;NeonTreeEvaluation&quot;, &quot;cloud2trees&quot;, &quot;LadderFuelsR&quot;, &quot;lasR&quot;, &quot;leafR&quot;) , l = c( &quot;weecology/NeonTreeEvaluation_package&quot; , &quot;georgewoolsey/cloud2trees&quot; , &quot;olgaviedma/LadderFuelsR&quot; , &quot;r-lidar/lasR&quot; , &quot;DRAAlmeida/leafR&quot; ) ) # install if needed if(!require(x, character.only = T)){ pak::pkg_install( pkg = df %&gt;% dplyr::filter(tolower(p)==tolower(x)) %&gt;% dplyr::pull(l) , upgrade = T ) } # load library(x, character.only = T) }) 2.1 NeonTreeEvaluation Weinstein et al. (2021) developed: a benchmark dataset of individual canopy crowns derived from multi-sensor imagery in the National Ecological Observatory Network (Table 1) that provides: 1) co-registered remote sensing data from multiple sensors (LiDAR, RGB imagery, and hyperspectral imagery) to allow comparisons of methods based on any single sensor (e.g., for LiDAR based methods), or any combination of sensors (e.g., combining RGB and hyperspectral), and 2) three types of evaluation data to allow assessing both ‘tree detection’, defined as the identifying the location of individual trees using evaluation data with a point at the crown center , and ‘crown delineation’ defined as identifying the boundary edge of crowns across a broad range of forest types. The benchmark is designed to allow flexibility in both workflow and sensor selection. (p. 2) Table 1. Summary of datasets included in the benchmark dataset. All sensor data has been cropped to the extent of NEON field sampling plots. The objective of the present analysis is to evaluate the use of this benchmark data set (Weinstein et al. 2021) for a scientific publication describing a workflow to ingest raw LiDAR data and export a tabular tree list for use as an input to the QUIC-Fire physics-based fire spread model (Linn et al. 2020). Weinstein et al. (2021) describe the LiDAR data in the benchmark data set: The LiDAR data are 3D coordinates (~5 points/m2) that provide high resolution information about canopy crown shape and height. LiDAR data are stored as 1000m x 1000m.laz files (Fig 2). These files contain the x,y,z coordinates for each return, as well as metadata on return intensity and point classification. Boundaries of individual canopy crowns are often apparent due to gaps among neighboring trees or differences in height among overlapping canopy crowns. For more information on NEON LiDAR data processing see NEON technical document NEON.DOC.001292. Due to the large spatial coverage of the collection effort, the point density of the NEON LiDAR clouds is much lower than the point density used for most studies of crown detection models ([20, 21]; point densities of 8–1000 pt/m2). (p. 4) what’s in this package? lsf.str(&quot;package:NeonTreeEvaluation&quot;) ## boxes_to_spatial_polygons : function (boxes, raster_object, project_boxes = TRUE) ## canopy_model : function (las, res = 0.5) ## check_download : function () ## compute_precision_recall : function (ground_truth, predictions, threshold = 0.4, summarize = TRUE) ## download : function (training = FALSE, savedir = NULL, force = F) ## evaluate_field_crowns : function (predictions, summarize = TRUE, show = TRUE, project = FALSE) ## evaluate_field_stems : function (predictions, project = TRUE, show = T, summarize = T) ## evaluate_image_crowns : function (predictions, project = FALSE, show = TRUE, summarize = TRUE) ## field_crowns : function (x, show = TRUE, project_boxes = TRUE) ## get_data : function (plot_name, type) ## grand_summary : function (results, threshold = 0.4) ## image_crowns : function (predictions, show = TRUE, project_boxes = TRUE) ## list_annotations : function () ## list_chm : function () ## list_field_crowns : function () ## list_field_stems : function () ## list_rgb : function () ## load_field_crown : function (plot_name, show = TRUE) ## load_ground_truth : function (plot_name, show = TRUE) ## xml_parse : function (path) ## zenodo_url : function (concept_rec_id = 3723356, rec_version = &quot;latest&quot;, rec_id = NULL) ## zenodo_versions : function (concept_rec_id, arg_checks = TRUE) we first have to download evaluation data from the Zenodo archive (1GB), use the download() function to place the data in the correct package location. Download the much larger training data, set training=TRUE. NeonTreeEvaluation::download(training = T, force = F) ## NULL what data is in this package? # what/where is this data paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = F) %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;NeonTreeEvaluation/evaluation/LiDAR/ABBY_068_2019.laz&quot; ## [2] &quot;NeonTreeEvaluation/evaluation/LiDAR/BONA_018_2018.laz&quot; ## [3] &quot;NeonTreeEvaluation/evaluation/LiDAR/JERC_049_2018.laz&quot; ## [4] &quot;NeonTreeEvaluation/evaluation/LiDAR/2018_TEAK_3_315000_4107000_image_237.laz&quot; ## [5] &quot;NeonTreeEvaluation/evaluation/LiDAR/TEAK_011_2019.laz&quot; ## [6] &quot;NeonTreeEvaluation/evaluation/LiDAR/OSBS_56.las&quot; ## [7] &quot;NeonTreeEvaluation/evaluation/LiDAR/SOAP_015_2018.laz&quot; ## [8] &quot;NeonTreeEvaluation/evaluation/LiDAR/DELA_024_2019.laz&quot; ## [9] &quot;NeonTreeEvaluation/evaluation/LiDAR/UNDE_060_2020.laz&quot; ## [10] &quot;NeonTreeEvaluation/evaluation/LiDAR/UKFS_050_2018.laz&quot; For a list of NEON site abbreviations https://www.neonscience.org/field-sites/field-sites-map NeonTreeEvaluation::list_annotations looks into package contents for ground truth annotations for the image-annotated crowns. # list_annotations NeonTreeEvaluation::list_annotations() %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;2018_TEAK_3_322000_4097000_image_216&quot; ## [2] &quot;TEAK_061_2018&quot; ## [3] &quot;NIWO_042_2018&quot; ## [4] &quot;TEAK_059_2018&quot; ## [5] &quot;TEAK_062_2018&quot; ## [6] &quot;SJER_058_2018&quot; ## [7] &quot;2018_TEAK_3_323000_4101000_image_415&quot; ## [8] &quot;2018_SJER_3_253000_4105000_image_72&quot; ## [9] &quot;2018_TEAK_3_316000_4097000_image_35&quot; ## [10] &quot;SJER_064_2018&quot; The field collected stems are individual points for each tree. They overlap with a subset of the sensor data. Use the NeonTreeEvaluation::list_field_stems function to determine which plots have stem data. # list_field_stems NeonTreeEvaluation::list_field_stems() %&gt;% sample() %&gt;% .[1:10] ## [1] &quot;RMNP_043&quot; &quot;SERC_012&quot; &quot;DELA_044&quot; &quot;BLAN_012&quot; &quot;SERC_005&quot; &quot;SCBI_018&quot; ## [7] &quot;HARV_002&quot; &quot;GUAN_054&quot; &quot;TALL_008&quot; &quot;SERC_055&quot; The NeonTreeEvaluation::crown_polygons function lists “field-annotated crowns” in which an observer annotates a polygon on the remote-sensing image on a tablet while standing in the field. From Ordway Swisher Biological Station, Florida and Mountain Lake Biological Station. # crown_polygons NeonTreeEvaluation::crown_polygons %&gt;% dplyr::glimpse() ## Rows: 564 ## Columns: 7 ## $ indvdID &lt;chr&gt; &quot;MLBSE00007&quot;, &quot;MLBSE00012&quot;, &quot;MLBSE00027&quot;, &quot;MLBSE00049&quot;, &quot;… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((541983.5 4136174,..., POLYGON ((542127 … ## $ plotID &lt;fct&gt; MLBS_14, MLBS_37, MLBS_42, MLBS_1, MLBS_21, MLBS_23, MLBS… ## $ siteID &lt;fct&gt; MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLBS, MLB… ## $ utmZone &lt;fct&gt; 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17N, 17… ## $ plotEasting &lt;dbl&gt; 541986.3, 542125.7, 542267.8, 541883.4, 542053.1, 542075.… ## $ plotNorthing &lt;dbl&gt; 4136173, 4136182, 4136994, 4136586, 4136390, 4136400, 413… Sites with field annotated crowns # crown_polygons NeonTreeEvaluation::crown_polygons %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(siteID) ## # A tibble: 2 × 2 ## siteID n ## &lt;fct&gt; &lt;int&gt; ## 1 MLBS 106 ## 2 OSBS 458 hmmm this data only exists for two NEON sites The woody vegetation structure data contains information on field estimated height and maximum crown diameter for the majority of field collected stems. We annotated all trees in the 40x40 m plot, regardless of health status, provided they were visible in the image. NeonTreeEvaluation::field %&gt;% dplyr::glimpse() ## Rows: 37,776 ## Columns: 67 ## $ uid &lt;fct&gt; 411f5c60-79c4-41ef-b3d0-4e9b5365870e, 0d… ## $ namedLocation &lt;fct&gt; ABBY_063.basePlot.vst, ABBY_063.basePlot… ## $ date &lt;fct&gt; 2015-07-23, 2015-07-23, 2015-07-23, 2015… ## $ tagEventID &lt;fct&gt; vst_ABBY_2015, vst_ABBY_2015, vst_ABBY_2… ## $ domainID &lt;fct&gt; D16, D16, D16, D16, D16, D16, D16, D16, … ## $ siteID &lt;fct&gt; ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY… ## $ plotID &lt;fct&gt; ABBY_063, ABBY_063, ABBY_063, ABBY_063, … ## $ subplotID &lt;int&gt; 39, 21, 21, 21, 39, 39, 39, 39, 39, 39, … ## $ nestedSubplotID &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ pointID &lt;int&gt; 57, 21, 21, 21, 39, 41, 41, 41, 41, 41, … ## $ stemDistance &lt;dbl&gt; 3.0, 23.8, 23.8, 23.8, 26.2, 16.0, 16.0,… ## $ stemAzimuth &lt;dbl&gt; 111.0, 50.0, 50.0, 50.0, 45.4, 346.0, 34… ## $ recordType &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ individualID &lt;fct&gt; NEON.PLA.D16.ABBY.00441, NEON.PLA.D16.AB… ## $ supportingStemIndividualID &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ previouslyTaggedAs &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ samplingProtocolVersion &lt;fct&gt; NEON.DOC.000987vE, NEON.DOC.000987vE, NE… ## $ taxonID &lt;fct&gt; PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM… ## $ scientificName &lt;fct&gt; &quot;Pseudotsuga menziesii (Mirb.) Franco va… ## $ taxonRank &lt;fct&gt; variety, variety, variety, variety, vari… ## $ identificationReferences &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ morphospeciesID &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ morphospeciesIDRemarks &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ identificationQualifier &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ remarks &lt;fct&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;corrected using 201… ## $ measuredBy &lt;fct&gt; krian@neoninc.org, krian@neoninc.org, kr… ## $ recordedBy &lt;fct&gt; kzias@field-ops.org, kzias@field-ops.org… ## $ dataQF &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ plotType &lt;fct&gt; tower, tower, tower, tower, tower, tower… ## $ subtype &lt;fct&gt; basePlot, basePlot, basePlot, basePlot, … ## $ plotLatitude &lt;dbl&gt; 45.76074, 45.76037, 45.76037, 45.76037, … ## $ plotLongitude &lt;dbl&gt; -122.3303, -122.3303, -122.3303, -122.33… ## $ datum &lt;fct&gt; WGS84, WGS84, WGS84, WGS84, WGS84, WGS84… ## $ utmZone &lt;fct&gt; 10N, 10N, 10N, 10N, 10N, 10N, 10N, 10N, … ## $ plotEasting &lt;dbl&gt; 552081.2, 552079.1, 552079.1, 552079.1, … ## $ plotNorthing &lt;dbl&gt; 5067683, 5067642, 5067642, 5067642, 5067… ## $ horzUncert &lt;dbl&gt; 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10… ## $ crdSource &lt;fct&gt; Geo 7X, Geo 7X, Geo 7X, Geo 7X, Geo 7X, … ## $ elevation &lt;dbl&gt; 363.22, 362.29, 362.29, 362.29, 362.34, … ## $ vertUncert &lt;dbl&gt; 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10… ## $ nlcdClass &lt;fct&gt; evergreenForest, evergreenForest, evergr… ## $ appMods &lt;fct&gt; bbc|bgc|cdw|cfc|dhp|hbp|ltr|sme|vst, bbc… ## $ geometry &lt;fct&gt; &quot;c(-122.330278, 45.76074)&quot;, &quot;c(-122.3303… ## $ itcEasting &lt;dbl&gt; 552084.0, 552097.3, 552097.3, 552097.3, … ## $ itcNorthing &lt;dbl&gt; 5067682, 5067657, 5067657, 5067657, 5067… ## $ itcLongitude &lt;dbl&gt; -122.3302, -122.3301, -122.3301, -122.33… ## $ itcLatitude &lt;dbl&gt; 45.76073, 45.76051, 45.76051, 45.76051, … ## $ eventID &lt;fct&gt; vst_ABBY_2015, vst_ABBY_2016, vst_ABBY_2… ## $ tempShrubStemID &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tagStatus &lt;fct&gt; NA, ok, ok, ok, NA, NA, ok, ok, ok, NA, … ## $ growthForm &lt;fct&gt; single bole tree, single bole tree, sing… ## $ plantStatus &lt;fct&gt; &quot;Standing dead&quot;, &quot;Standing dead&quot;, &quot;Dead,… ## $ stemDiameter &lt;dbl&gt; 40.0, 90.0, 89.1, 88.3, 105.0, 28.3, 29.… ## $ measurementHeight &lt;int&gt; 130, 130, 130, 130, 130, 130, 140, 130, … ## $ height &lt;dbl&gt; NA, 7.5, 6.7, 6.8, NA, NA, NA, 22.5, 21.… ## $ baseCrownHeight &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ breakHeight &lt;dbl&gt; NA, NA, NA, 6.8, NA, NA, NA, NA, NA, NA,… ## $ breakDiameter &lt;dbl&gt; NA, NA, 61, NA, NA, NA, NA, NA, NA, NA, … ## $ maxCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ninetyCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ canopyPosition &lt;fct&gt; NA, , NA, NA, NA, NA, , NA, NA, NA, , NA… ## $ shape &lt;fct&gt; , , , , , , , , , , , , , , , , , , , , … ## $ basalStemDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basalStemDiameterMsrmntHeight &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ maxBaseCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ninetyBaseCrownDiameter &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ area &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … Nice, there appears to be some useful data in here: uid, siteID, plotID, stemDiameter, height, maxCrownDiameter, ninetyCrownDiameter, baseCrownHeight, plantStatus, taxonID Also, I just found that there is a hidden function in the package to filter the field tree data …except for I’m going to change the minimum diameter from 15 cm to 10 cm clean_field_data&lt;-function(field){ field$area&lt;-field$maxCrownDiameter*field$ninetyCrownDiameter field&lt;-field %&gt;% filter(!is.na(itcEasting),!stringr::str_detect(eventID,&quot;2014&quot;),growthForm %in% c(&quot;single bole tree&quot;,&quot;multi-bole tree&quot;,&quot;small tree&quot;,&quot;sapling&quot;),stemDiameter&gt;10) %&gt;% droplevels() %&gt;% filter(height&gt;3|is.na(height)) #Limit difference in heights to_remove&lt;-field %&gt;% group_by(individualID) %&gt;% summarize(mean=mean(height),sum_difference = abs(sum(diff(height)))) %&gt;% filter(sum_difference &gt; 8) field&lt;-field %&gt;% filter(!individualID %in% to_remove$individualID) } clean this data and filter it # filter it field_trees &lt;- NeonTreeEvaluation::field %&gt;% clean_field_data() %&gt;% dplyr::select( uid, siteID, plotID, stemDiameter , height, maxCrownDiameter, ninetyCrownDiameter , baseCrownHeight, plantStatus, taxonID ) %&gt;% dplyr::filter(!is.na(maxCrownDiameter) &amp; !is.na(height)) %&gt;% dplyr::mutate(CrownRadius = maxCrownDiameter/2) # see it field_trees %&gt;% dplyr::glimpse() ## Rows: 6,878 ## Columns: 11 ## $ uid &lt;fct&gt; b4305401-a7d9-4e79-afc4-a7f0c82e98d3, 346b66a5-cd8… ## $ siteID &lt;fct&gt; ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, ABBY, AB… ## $ plotID &lt;fct&gt; ABBY_007, ABBY_007, ABBY_007, ABBY_007, ABBY_007, … ## $ stemDiameter &lt;dbl&gt; 68.2, 54.1, 54.7, 58.0, 68.1, 20.2, 15.6, 19.6, 18… ## $ height &lt;dbl&gt; 49.6, 13.1, 22.9, 35.6, 50.2, 19.0, 10.8, 12.5, 9.… ## $ maxCrownDiameter &lt;dbl&gt; 9.7, 3.2, 9.1, 9.5, 11.3, 8.6, 4.5, 4.7, 5.2, 4.3,… ## $ ninetyCrownDiameter &lt;dbl&gt; 8.5, 0.0, 7.8, 7.9, 6.7, 7.6, 4.2, 4.5, 4.8, 3.8, … ## $ baseCrownHeight &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ plantStatus &lt;fct&gt; &quot;Live&quot;, &quot;Dead, broken bole&quot;, &quot;Live&quot;, &quot;Live&quot;, &quot;Live… ## $ taxonID &lt;fct&gt; PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, PSMEM, P… ## $ CrownRadius &lt;dbl&gt; 4.85, 1.60, 4.55, 4.75, 5.65, 4.30, 2.25, 2.35, 2.… what are these data? field_trees %&gt;% dplyr::select(dplyr::where(is.numeric)) %&gt;% summary() ## stemDiameter height maxCrownDiameter ninetyCrownDiameter ## Min. : 15.10 Min. : 3.10 Min. : 0.100 Min. : 0.000 ## 1st Qu.: 18.60 1st Qu.: 9.90 1st Qu.: 3.800 1st Qu.: 2.900 ## Median : 23.30 Median :13.30 Median : 6.200 Median : 4.700 ## Mean : 27.44 Mean :14.97 Mean : 6.975 Mean : 5.296 ## 3rd Qu.: 31.80 3rd Qu.:18.90 3rd Qu.: 9.200 3rd Qu.: 7.000 ## Max. :255.00 Max. :52.90 Max. :62.000 Max. :31.000 ## NA&#39;s :115 ## baseCrownHeight CrownRadius ## Min. : NA Min. : 0.050 ## 1st Qu.: NA 1st Qu.: 1.900 ## Median : NA Median : 3.100 ## Mean :NaN Mean : 3.487 ## 3rd Qu.: NA 3rd Qu.: 4.600 ## Max. : NA Max. :31.000 ## NA&#39;s :6878 status? field_trees %&gt;% dplyr::count(plantStatus) ## plantStatus n ## 1 Dead, broken bole 75 ## 2 Downed 2 ## 3 Live 5486 ## 4 Live, other damage 135 ## 5 Live, broken bole 43 ## 6 Live, disease damaged 199 ## 7 Live, insect damaged 157 ## 8 Live, physically damaged 154 ## 9 No longer qualifies 12 ## 10 Removed 1 ## 11 Standing dead 614 keep only live field_trees &lt;- field_trees %&gt;% dplyr::filter(plantStatus %&gt;% tolower() %&gt;% stringr::str_starts(&quot;live&quot;)) taxonID? field_trees %&gt;% dplyr::count(taxonID) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::slice_head(n = 20) ## taxonID n ## 1 PICOL 535 ## 2 PIEN 500 ## 3 ACRU 367 ## 4 ABLAL 333 ## 5 LITU 270 ## 6 QURU 267 ## 7 LIST2 238 ## 8 TSCA 211 ## 9 QUAL 197 ## 10 PIPA2 177 ## 11 ACSA3 137 ## 12 PIFL2 132 ## 13 OXYDE 117 ## 14 PSMEM 96 ## 15 PITA 95 ## 16 PSME 91 ## 17 CATO6 88 ## 18 PIMA 84 ## 19 POTR5 81 ## 20 JUNIP 80 let’s see the height versus diameter relationship field_trees %&gt;% ggplot(mapping = aes(x = height, y = stemDiameter)) + geom_point() + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + theme_light() let’s get conifer trees only??? ….sure, i found a NEON plant list with the codes: https://data.neonscience.org/taxonomic-lists?taxonTypeCode=PLANT conifer_spp &lt;- readr::read_csv( &quot;../data/OS_TAXON_PLANT-20220330T142149.csv&quot; , show_col_types = F , progress = F ) %&gt;% dplyr::filter( tolower(family) %in% c( &quot;pinaceae&quot;, &quot;podocarpaceae&quot;, &quot;araucariaceae&quot; , &quot;taxaceae&quot;, &quot;cephalotaxaceae&quot;, &quot;taxodiaceae&quot;, &quot;cupressaceae&quot; ) ) %&gt;% dplyr::mutate( taxonID = toupper(taxonID) , vernacularName = tolower(vernacularName) , genus = stringr::str_to_title(genus) ) %&gt;% dplyr::distinct(taxonID, vernacularName, genus) # huh? conifer_spp %&gt;% dplyr::slice_sample(n = 10) ## # A tibble: 10 × 3 ## taxonID vernacularName genus ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 PIFL2 limber pine Pinus ## 2 PIBA foxtail pine Pinus ## 3 TAXUS yew Taxus ## 4 PICO3 coulter pine Pinus ## 5 JUPI pinchot&#39;s juniper Juniperus ## 6 PIGL2 spruce pine Pinus ## 7 SEQUOSPP redwood Sequoia ## 8 CALOC2SPP incense cedar Calocedrus ## 9 CULA chinese fir Cunninghamia ## 10 PIHA7 aleppo pine Pinus filter that field tree list for conifers conifer_trees &lt;- field_trees %&gt;% dplyr::inner_join(conifer_spp, by = &quot;taxonID&quot;) check those conifers height and diameter conifer_trees %&gt;% ggplot(mapping = aes(x = height, y = stemDiameter, color = genus)) + geom_point() + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + facet_wrap(facets = dplyr::vars(genus)) + scale_color_viridis_d(option = &quot;turbo&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) what about this crown area data? conifer_trees %&gt;% ggplot(mapping = aes(x = CrownRadius, y = genus, fill = genus)) + geom_boxplot(width = 0.7, outliers = F) + scale_fill_viridis_d(option = &quot;turbo&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) radius data # height conifer_trees$height %&gt;% quantile(probs = c(0.01,0.05,0.5,0.95,0.99)) ## 1% 5% 50% 95% 99% ## 3.500 5.600 11.500 25.210 41.753 # radius conifer_trees$CrownRadius %&gt;% quantile(probs = c(0.01,0.05,0.5,0.95,0.99)) ## 1% 5% 50% 95% 99% ## 0.8500 1.1000 2.0000 5.1000 6.6255 let’s model crown radius based on height lm(formula = CrownRadius ~ height, data = conifer_trees) %&gt;% broom::tidy() %&gt;% kableExtra::kbl(digits = 4) %&gt;% kableExtra::kable_styling() term estimate std.error statistic p.value (Intercept) 1.0900 0.0464 23.5090 0 height 0.1014 0.0032 31.7895 0 plot this conifer_trees %&gt;% ggplot(mapping = aes(x = height, y = CrownRadius)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,NA)) + scale_y_continuous(limits = c(0,NA)) + theme_light() + theme(legend.position = &quot;none&quot;) what about a non-linear model? crown_height_model &lt;- brms::brm( formula = brms::bf( formula = CrownRadius ~ (b1 * height) + height^b2 , b1 + b2 ~ 1 , nl = TRUE # !! specify non-linear ) , data = conifer_trees , family = brms::brmsfamily(&quot;Gamma&quot;) , iter = 6000, warmup = 3000, chains = 4 , cores = lasR::half_cores() , file = &quot;../data/crown_height_model&quot; ) # plot(crown_height_model) summary(crown_height_model) ## Family: gamma ## Links: mu = log; shape = identity ## Formula: CrownRadius ~ (b1 * height) + height^b2 ## b1 ~ 1 ## b2 ~ 1 ## Data: conifer_trees (Number of observations: 2750) ## Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 1; ## total post-warmup draws = 12000 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## b1_Intercept 0.04 0.00 0.04 0.05 1.00 5784 6848 ## b2_Intercept -0.55 0.03 -0.61 -0.51 1.00 5397 5756 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 5.72 0.15 5.43 6.02 1.00 6131 5494 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). ## write out model estimates to tabular file #### extract posterior draws to a df brms::as_draws_df( crown_height_model , variable = c(&quot;^b_&quot;, &quot;shape&quot;) , regex = TRUE ) %&gt;% # quick way to get a table of summary statistics and diagnostics posterior::summarize_draws( &quot;mean&quot;, &quot;median&quot;, &quot;sd&quot; , ~quantile(.x, probs = c( 0.05, 0.95 , 0.025, 0.975 )) , &quot;rhat&quot; ) %&gt;% dplyr::mutate( variable = stringr::str_remove_all(variable, &quot;_Intercept&quot;) , formula = summary(crown_height_model)$formula %&gt;% as.character() %&gt;% .[1] ) %&gt;% write.csv( &quot;../data/crown_height_model.csv&quot; , row.names = F ) plot this plot(brms::conditional_effects(crown_height_model), points = T) what if we try to plot it with a function using the regression coefficients? ws_fn &lt;- function(x) { y = dplyr::case_when( is.na(x) ~ 1e-3 # requires non-null , x &lt; 0 ~ 1e-3 # requires positive , x &lt; 2.5 ~ 1 # set lower bound , x &gt; 40 ~ 6.7 # set upper bound # , TRUE ~ 0.75 + (x * 0.14) , TRUE ~ exp( (0.0446*x) + (x^-0.555) ) # used gamma regression so exp the result ) return(y) } plot it ggplot2::ggplot() + ggplot2::xlim(0,60) + ggplot2::ylim(0,NA) + ggplot2::geom_point(data = conifer_trees, mapping = aes(y = CrownRadius, x = height)) + ggplot2::geom_function(fun = ws_fn, lwd = 1.5, color = &quot;blue&quot;) NeonTreeEvaluation::get_data is a set of utility functions for finding the path of benchmark data on disk NeonTreeEvaluation::get_data(plot_name = &quot;RMNP_047&quot;, type = &quot;lidar&quot;) ## [1] &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extdata/NeonTreeEvaluation/evaluation/LiDAR/RMNP_047.laz&quot; let’s pull out all sites with .laz data and create a data frame for tracking purposes las_df &lt;- paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = T) %&gt;% unique() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(f_path = 1) %&gt;% # create some other variables dplyr::mutate( f_nm = f_path %&gt;% basename() %&gt;% stringr::str_remove_all(&quot;\\\\.(laz|las)$&quot;) , plot_nm = f_nm %&gt;% # this matches the file name with the plot name toupper() %&gt;% stringr::str_extract( pattern = NeonTreeEvaluation::list_field_stems() %&gt;% toupper() %&gt;% paste(collapse = &quot;|&quot;) ) , neon_site = plot_nm %&gt;% stringr::word(start = 1, sep = fixed(&quot;_&quot;)) ) %&gt;% dplyr::filter(!is.na(plot_nm)) %&gt;% # keep only las files with field stems dplyr::select(neon_site, plot_nm, f_nm, f_path) # what? las_df %&gt;% dplyr::glimpse() ## Rows: 278 ## Columns: 4 ## $ neon_site &lt;chr&gt; &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;ABBY&quot;, &quot;BART&quot;, &quot;BART&quot;, &quot;BAR… ## $ plot_nm &lt;chr&gt; &quot;ABBY_003&quot;, &quot;ABBY_008&quot;, &quot;ABBY_010&quot;, &quot;ABBY_023&quot;, &quot;ABBY_068&quot;, … ## $ f_nm &lt;chr&gt; &quot;ABBY_003_2018&quot;, &quot;ABBY_008_2018&quot;, &quot;ABBY_010_2018&quot;, &quot;ABBY_023… ## $ f_path &lt;chr&gt; &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extda… 2.1.1 Explore LiDAR data from package which NEON sites have data? las_df %&gt;% dplyr::count(neon_site) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::mutate(neon_site = forcats::fct_reorder(neon_site, n)) %&gt;% # plot ggplot(aes(y = neon_site, x = n, fill = n)) + geom_col(width = 0.7) + labs(y = &quot;NEON site&quot;, x = &quot;lidar data plots&quot;) + harrypotter::scale_fill_hp(&quot;slytherin&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) where is this data? get_site_bbox &lt;- function(site, dta = las_df) { # read the las files for a site las_ctg = dta %&gt;% dplyr::filter(neon_site == site) %&gt;% dplyr::pull(f_path) %&gt;% lidR::readLAScatalog() # bbox that site if( is.na( sf::st_crs(las_ctg@data) ) ){ return(NULL) }else{ las_ctg@data %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate(neon_site = site) %&gt;% sf::st_set_crs(sf::st_crs(las_ctg@data)) %&gt;% sf::st_transform(crs = paste0(&quot;EPSG:&quot;, 5070)) } } # take this for a spin las_df %&gt;% dplyr::pull(neon_site) %&gt;% unique() %&gt;% purrr::map(get_site_bbox) %&gt;% dplyr::bind_rows() %&gt;% dplyr::left_join( las_df %&gt;% dplyr::group_by(neon_site) %&gt;% dplyr::summarise(n = dplyr::n()) , by = &quot;neon_site&quot; ) %&gt;% st_centroid() %&gt;% mapview::mapview( zcol = &quot;n&quot; , layer.name = &quot;LiDAR plots&quot; , label = c(&quot;neon_site&quot;) , col.regions = viridis::mako(10, direction = -1) ) load one las data f_temp = las_df %&gt;% dplyr::slice_sample(n = 1) %&gt;% dplyr::pull(f_path) las_temp = lidR::readLAS(f_temp) # quick summary las_temp ## class : LAS (v1.3 format 3) ## memory : 713.4 Kb ## extent : 747724, 747764, 4308468, 4308508 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 17N ## area : 1629 m² ## points : 9.1 thousand points ## density : 5.59 points/m² ## density : 3.27 pulses/m² # data str las_temp@data %&gt;% dplyr::glimpse() ## Rows: 9,098 ## Columns: 19 ## $ X &lt;dbl&gt; 747763.5, 747762.7, 747760.8, 747761.8, 747762.6, 74… ## $ Y &lt;dbl&gt; 4308468, 4308468, 4308468, 4308468, 4308468, 4308468… ## $ Z &lt;dbl&gt; 333.64, 334.22, 333.85, 334.04, 334.05, 333.53, 333.… ## $ gpstime &lt;dbl&gt; 488976.4, 488976.4, 488976.4, 488976.4, 488976.4, 48… ## $ Intensity &lt;int&gt; 16, 18, 9, 15, 14, 14, 19, 19, 22, 15, 13, 1, 14, 10… ## $ ReturnNumber &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2… ## $ NumberOfReturns &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 3, 3, 2… ## $ ScanDirectionFlag &lt;int&gt; 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8… ## $ UserData &lt;int&gt; 29, 35, 32, 33, 33, 27, 30, 35, 35, 35, 48, 250, 46,… ## $ PointSourceID &lt;int&gt; 1511, 1511, 1511, 1511, 1511, 1511, 1511, 1511, 1511… ## $ R &lt;int&gt; 22272, 28160, 30464, 18944, 32512, 7168, 33792, 4172… ## $ G &lt;int&gt; 28416, 37120, 37376, 23296, 39680, 12288, 39424, 483… ## $ B &lt;int&gt; 25344, 27392, 28416, 16128, 28160, 11776, 32512, 363… summarize x, y, z las_temp@data %&gt;% dplyr::select(X,Y,Z) %&gt;% summary() ## X Y Z ## Min. :747724 Min. :4308468 Min. :327.3 ## 1st Qu.:747733 1st Qu.:4308481 1st Qu.:343.4 ## Median :747743 Median :4308490 Median :356.4 ## Mean :747744 Mean :4308489 Mean :352.4 ## 3rd Qu.:747754 3rd Qu.:4308498 3rd Qu.:361.6 ## Max. :747764 Max. :4308508 Max. :368.7 plot this las plot3D::scatter3D( x = las_temp@data$X , y = las_temp@data$Y , z = las_temp@data$Z , colvar = las_temp@data$Z , pch = 19, cex = 0.3 , colkey = F , phi = 0.5 ) let’s look at the classification (see table 5 here) las_temp@data %&gt;% dplyr::count(Classification) ## Classification n ## &lt;int&gt; &lt;int&gt; ## 1: 1 403 ## 2: 2 455 ## 3: 5 8236 ## 4: 7 4 plot color by classification plot3D::scatter3D( x = las_temp@data$X , y = las_temp@data$Y , z = las_temp@data$Z , colvar = las_temp@data$Classification , pch = 19, cex = 0.3 , colkey = F , phi = 0.5 ) 2.2 cloud2trees The cloud2trees package provides routines for processing point cloud data (.las|.laz format) to detect forest trees. let’s use it for one of the data sets from a conifer forest in the NeonTreeEvaluation benchmark # get one file (f_temp &lt;- las_df %&gt;% dplyr::filter(neon_site==&quot;RMNP&quot;) %&gt;% # rocky mtn national park dplyr::slice_sample(n = 1) %&gt;% dplyr::pull(f_path)) ## [1] &quot;C:/Program Files/R/R-4.3.0/library/NeonTreeEvaluation/extdata/NeonTreeEvaluation/evaluation/LiDAR/RMNP_042_2018.laz&quot; # read in the data las_temp &lt;- lidR::readLAS(f_temp) what is this data? las_temp@data %&gt;% dplyr::glimpse() ## Rows: 20,407 ## Columns: 16 ## $ X &lt;dbl&gt; 453532.6, 453546.3, 453546.8, 453547.2, 453547.7, 45… ## $ Y &lt;dbl&gt; 4458594, 4458556, 4458556, 4458556, 4458556, 4458556… ## $ Z &lt;dbl&gt; 2750.133, 2746.354, 2746.339, 2746.320, 2746.295, 27… ## $ gpstime &lt;dbl&gt; 409989.8, 409990.3, 409990.3, 409990.3, 409990.3, 40… ## $ Intensity &lt;int&gt; 74, 306, 289, 344, 273, 270, 306, 324, 344, 330, 335… ## $ ReturnNumber &lt;int&gt; 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ NumberOfReturns &lt;int&gt; 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; -6, -7, -7, -7, -7, -6, -6, -6, -6, -6, -6, -6, -6, … ## $ UserData &lt;int&gt; 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ PointSourceID &lt;int&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9… We can plot the point cloud with and color by the point height lidR::plot( las_temp , color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) notice the Z values are in meters above sea level 2.2.1 Get tree list and normalized cloud We’ll use the cloud2trees::cloud2trees() function to get a tree list from the lidar data with a regional estimate of the DBH because we enabled the estimate_tree_dbh parameter. Also returned is a canopy height model (CHM) raster and because we enabled the keep_intrmdt parameter we’ll get the normalized point cloud data as well. cloud2trees_ans &lt;- cloud2trees::cloud2trees( input_las_dir = f_temp , output_dir = &quot;../data&quot; , estimate_tree_dbh = T , keep_intrmdt = T ) let’s see what we got names(cloud2trees_ans) ## [1] &quot;crowns_sf&quot; &quot;treetops_sf&quot; &quot;dtm_rast&quot; &quot;chm_rast&quot; we got a CHM # could make an easy plot with... # terra::plot(cloud2trees_ans$chm_rast) # ...but we&#39;ll customize and save it as our base plot plt_chm &lt;- ggplot() + geom_tile( data = cloud2trees_ans$chm_rast %&gt;% as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , mapping = aes(x=x,y=y,fill=f) ) + harrypotter::scale_fill_hp(&quot;gryffindor&quot;, name = &quot;height (m)&quot;) + theme_light() + theme( axis.text = element_blank() ) # view plt_chm we also got tree top points plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) and we got tree crowns plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) + geom_sf(data = cloud2trees_ans$crowns_sf, fill = NA, color = &quot;steelblue&quot;) there is data on the individual trees in the crowns and tree tops data (which are the same data but one spaltial polygons and the other is spatial points). cloud2trees_ans$crowns_sf %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 22 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ tree_x &lt;dbl&gt; 453532.6, 453544.6, 453542.6, 453547.4, 4535… ## $ tree_y &lt;dbl&gt; 4458595, 4458595, 4458594, 4458593, 4458592,… ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ geometry &lt;GEOMETRY [m]&gt; POLYGON ((453532.5 4458595,..., POL… ## $ fia_est_dbh_cm &lt;dbl&gt; 4.885335, 19.681832, 17.947632, 6.304991, 13… ## $ fia_est_dbh_cm_lower &lt;dbl&gt; 2.627119, 10.629138, 9.517971, 3.365314, 7.1… ## $ fia_est_dbh_cm_upper &lt;dbl&gt; 7.734413, 30.988583, 28.330646, 9.932887, 20… ## $ dbh_cm &lt;dbl&gt; 4.885335, 19.681832, 17.947632, 6.304991, 13… ## $ is_training_data &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… ## $ dbh_m &lt;dbl&gt; 0.04885335, 0.19681832, 0.17947632, 0.063049… ## $ radius_m &lt;dbl&gt; 0.02442668, 0.09840916, 0.08973816, 0.031524… ## $ basal_area_m2 &lt;dbl&gt; 0.001874471, 0.030424322, 0.025299050, 0.003… ## $ basal_area_ft2 &lt;dbl&gt; 0.02017680, 0.32748740, 0.27231897, 0.033607… ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_cbh &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … let’s check the height to DBH relationship cloud2trees_ans$crowns_sf %&gt;% ggplot(mapping = aes(x = tree_height_m, y = dbh_cm)) + geom_point(color = &quot;navy&quot;) + labs(x = &quot;height (m)&quot;, y = &quot;DBH (cm)&quot;) + theme_light() this all looks great. let’s check the normalized point cloud. for that we’ll dig in the output directory from the cloud2trees::cloud2trees() function (see that output_dir parameter). (n_f_temp &lt;- list.files( &quot;../data/point_cloud_processing_temp/02_normalize/&quot; , pattern = &quot;.las&quot; , full.names = T )) ## [1] &quot;../data/point_cloud_processing_temp/02_normalize/RMNP_042_2018_normalize.las&quot; # read in the data nlas_temp &lt;- lidR::readLAS(n_f_temp) plot it to check that it is height normalized lidR::plot( nlas_temp , color = &quot;Z&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) nice! let’s remove the ground points to check out potential vegetation nlas_temp %&gt;% lidR::filter_poi(Classification!=2) %&gt;% lidR::plot( color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) that’s a great workflow, guy. i’m not your guy, buddy. 2.3 LadderFuelsR The LadderFuelsR package (Viedma et al. 2024) is described as enabling the use of “LiDAR data and the LadderFuelsR package…[to] provide an automated tool for analysing the vertical fuel structure of a forest and to calculate crown base height (CBH) at tree-level, among other parameters” (p.1). let’s check what’s in this package lsf.str(&quot;package:LadderFuelsR&quot;) ## calculate_gaps_perc : function (LAD_profiles, min_height = 1.5) ## get_cbh_metrics : function (effective_LAD, min_height = 1.5, hdepth1_height = 2.5, verbose = TRUE) ## get_cum_break : function (LAD_profiles, cbh_metrics, threshold = 75, min_height = 1.5, ## verbose = TRUE) ## get_depths : function (LAD_profiles, distance_metrics, step = 1, min_height = 1.5, verbose = TRUE) ## get_distance : function (gap_cbh_metrics, gaps_perc, step = 1, min_height = 1.5, verbose = TRUE) ## get_effective_gap : function (effective_depth, number_steps = 1, min_height = 1.5, verbose = TRUE) ## get_gaps_fbhs : function (LAD_profiles, step = 1, min_height = 1.5, perc_gap = 25, perc_base = 25, ## verbose = TRUE) ## get_layers_lad : function (LAD_profiles, effective_distances, threshold = 10, step = 1, ## min_height = 1.5, verbose = TRUE) ## get_plots_cbh_bp : function (LAD_profiles, cummulative_LAD, min_height = 1.5) ## get_plots_cbh_LAD : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_cbh_lastdist : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_cbh_maxdist : function (LAD_profiles, cbh_metrics, min_height = 1.5) ## get_plots_effective : function (LAD_profiles, effective_LAD, min_height = 1.5) ## get_plots_gap_fbh : function (LAD_profiles, gap_cbh_metrics, min_height = 1.5) ## get_real_depths : function (effective_fbh, step = 1, min_height = 1.5, verbose = TRUE) ## get_real_fbh : function (depth_metrics, step = 1, number_steps = 1, min_height = 1.5, ## verbose = TRUE) ## get_renamed_df : function (df) ## get_renamed0_df : function (df) 2.3.1 Prep for the package For this package we need to do some cleaning of our las data and our polygon crown data. We need to attach the treeID column from our spatial crowns to the las data using lidR::merge_spatial(). This function allows for only polygons so we need to get rid of the multipolygons in the crown data. We’ll keep the largest part of the multipolygon as the smaller part is usually a residual pixel from the CHM. We also generate a tree_index as a numeric id which is needed by the LadderFuelsR package since treeID is character. # the lidR::merge_spatial requires only polygons so we need to rid the multipolygons crowns_sf_poly &lt;- # start with only polygons cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(geometry)==&quot;POLYGON&quot;) %&gt;% # union on cleaned multipolygons dplyr::bind_rows( cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(geometry)==&quot;MULTIPOLYGON&quot;) %&gt;% sf::st_cast(to = &quot;POLYGON&quot;, do_split = T, warn = F) %&gt;% dplyr::mutate(axxx = sf::st_area(geometry)) %&gt;% # axxx is so we don&#39;t overwrite a column dplyr::group_by(treeID) %&gt;% dplyr::filter(axxx == max(axxx)) %&gt;% # keep the biggest crown polygon by treeID dplyr::ungroup() %&gt;% dplyr::select(-axxx) ) %&gt;% # generate a treeID index because it needs to be numeric dplyr::ungroup() %&gt;% dplyr::mutate(tree_index = dplyr::row_number()) does it look good? plt_chm + geom_sf(data = cloud2trees_ans$treetops_sf, color = &quot;blue&quot;) + geom_sf(data = crowns_sf_poly, fill = NA, color = &quot;steelblue&quot;) now we’ll attach the treeID column to the normalized las file and keep only the points that fall within a tree crown. crowns_nlas_temp &lt;- lidR::merge_spatial( las = nlas_temp , source = crowns_sf_poly , attribute = &quot;tree_index&quot; ) %&gt;% lidR::filter_poi(!is.na(tree_index)) %&gt;% lidR::filter_poi(Classification!=2) # what is this data? crowns_nlas_temp@data %&gt;% dplyr::glimpse() ## Rows: 9,885 ## Columns: 17 ## $ X &lt;dbl&gt; 453540.9, 453541.3, 453541.5, 453541.8, 453542.0, 45… ## $ Y &lt;dbl&gt; 4458556, 4458556, 4458556, 4458556, 4458556, 4458556… ## $ Z &lt;dbl&gt; 6.196, 7.331, 5.996, 7.657, 6.043, 10.264, 8.629, 7.… ## $ gpstime &lt;dbl&gt; 409990.3, 409990.3, 409990.3, 409990.3, 409990.3, 40… ## $ Intensity &lt;int&gt; 15, 24, 47, 137, 41, 83, 43, 37, 9, 168, 151, 9, 92,… ## $ ReturnNumber &lt;int&gt; 1, 1, 2, 1, 2, 1, 2, 3, 4, 1, 1, 1, 1, 2, 1, 2, 3, 1… ## $ NumberOfReturns &lt;int&gt; 2, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 2, 3, 3, 3, 3, 3, 2… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, … ## $ UserData &lt;int&gt; 62, 74, 61, 76, 60, 102, 85, 76, 60, 103, 115, 32, 8… ## $ PointSourceID &lt;int&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9… ## $ tree_index &lt;int&gt; 64, 64, 64, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, … plot the las data colored by tree_index crowns_nlas_temp %&gt;% lidR::plot( color = &quot;tree_index&quot;, bg = &quot;white&quot;, legend = F , pal = viridis::turbo( n = crowns_nlas_temp@data$tree_index %&gt;% # this whole thing gets n unique colors unique() %&gt;% length() %&gt;% `*`(2) # with some separation between the hues ) %&gt;% sample( crowns_nlas_temp@data$tree_index %&gt;% unique() %&gt;% length() ) ) check it for one tree crowns_nlas_temp %&gt;% lidR::filter_poi( tree_index == # get the tree with the most points crowns_nlas_temp@data %&gt;% dplyr::count(tree_index) %&gt;% dplyr::filter(n == max(n)) %&gt;% dplyr::slice_head(n=1) %&gt;% dplyr::pull(tree_index) ) %&gt;% lidR::plot(color = &quot;tree_index&quot;, bg = &quot;white&quot;, legend = F) interesting, with more dense point clouds this would look more like a tree 2.3.2 Defining function for computing crown-level metrics Not sure how necessary this is, but pulling it from the package README notice, none of these functions utilize the intensity, or “i”, parameter custom_crown_metrics &lt;- function(z, i) { # user-defined function metrics &lt;- list( dz = 1, th = 1, z_max = max(z),# max height z_min = min(z),# min height z_mean = mean(z),# mean height z_sd = sd(z), # vertical variability of points z_q1=quantile(z, probs = 0.01), z_q5=quantile(z, probs = 0.05), z_q25=quantile(z, probs = 0.25), z_q50=quantile(z, probs = 0.50), z_q75=quantile(z, probs = 0.75), z_q95=quantile(z, probs = 0.95), crr=(mean(z)-min(z))/(max(z)-min(z)) ) return(metrics) # output } # idk why they did this...just for shorthand? just define it like that from the start # ccm = ~custom_crown_metrics(z = Z, i = Intensity) 2.3.3 Computing crown level standard metrics within all trees detected let’s see how they do it from the package README first, calculate metrics from the las data by tree (with code updates by gw) # setting a minimum Z height to look at crown metrics fcrowns_nlas_temp &lt;- lidR::filter_poi(crowns_nlas_temp, Z &gt;= 1) # Metric derivation at different levels of regularization crowns_metrics_df &lt;- # gw updated this to do it all at once lidR::crown_metrics( las = fcrowns_nlas_temp , func = .stdtreemetrics # stdtreemetrics is a lidR predefined function for tree-based metrics , geom = &quot;convex&quot; # Geometry type of the output , attribute = &quot;tree_index&quot; ) %&gt;% dplyr::left_join( lidR::crown_metrics( las = fcrowns_nlas_temp , func = ~ custom_crown_metrics(z = Z) # the custom function defined above , geom = &quot;convex&quot; # Geometry type of the output , attribute = &quot;tree_index&quot; ) %&gt;% sf::st_drop_geometry() , by = &quot;tree_index&quot; ) %&gt;% # define crown diameter dplyr::mutate( crown_diam = sqrt(convhull_area/ pi) * 2 ) # a df, ok crowns_metrics_df %&gt;% dplyr::glimpse() ## Rows: 89 ## Columns: 19 ## $ tree_index &lt;int&gt; 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 16, 18, 21, 22, 23, 24… ## $ Z &lt;dbl&gt; 12.866, 11.826, 8.980, 7.009, 6.352, 6.489, 7.472, 9.940… ## $ npoints &lt;int&gt; 108, 73, 48, 13, 11, 16, 11, 25, 118, 128, 8, 80, 21, 27… ## $ convhull_area &lt;dbl&gt; 7.166, 8.132, 3.042, 0.853, 1.141, 1.137, 0.554, 5.327, … ## $ dz &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ th &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ z_max &lt;dbl&gt; 12.866, 11.826, 8.980, 7.009, 6.352, 6.489, 7.472, 9.940… ## $ z_min &lt;dbl&gt; 1.926, 1.705, 2.469, 2.513, 1.702, 1.456, 2.428, 2.994, … ## $ z_mean &lt;dbl&gt; 7.870843, 8.036315, 5.881000, 4.762000, 4.380545, 4.4591… ## $ z_sd &lt;dbl&gt; 2.8488448, 2.2873433, 1.8985180, 1.6263112, 1.6196375, 1… ## $ z_q1 &lt;dbl&gt; 2.02244, 3.89092, 2.54702, 2.53208, 1.71760, 1.69855, 2.… ## $ z_q5 &lt;dbl&gt; 2.80340, 4.96060, 2.76435, 2.60840, 1.78000, 2.66875, 2.… ## $ z_q25 &lt;dbl&gt; 5.75425, 5.91900, 4.03000, 3.00000, 3.45850, 3.41000, 3.… ## $ z_q50 &lt;dbl&gt; 7.8825, 8.0970, 6.3520, 5.2200, 5.0770, 4.9280, 4.9980, … ## $ z_q75 &lt;dbl&gt; 10.27750, 10.05700, 7.25700, 5.75000, 5.36450, 5.44450, … ## $ z_q95 &lt;dbl&gt; 12.19095, 11.50240, 8.42115, 6.95260, 6.34900, 6.34575, … ## $ crr &lt;dbl&gt; 0.5434043, 0.6255622, 0.5240362, 0.5002224, 0.5760313, 0… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((453546.1 4458594,..., POLYGON ((453543… ## $ crown_diam &lt;dbl&gt; 3.0206017, 3.2177607, 1.9680434, 1.0421484, 1.2053076, 1… what “tree-based metrics” come from the .stdtreemetrics? maybe maximum Z, number of points, and crown area…not sure how useful these are for defining CBH. we shall see. the “z_” metrics are neat. does every crown have some crown metrics? # has the same number of trees as our crown polygons? dplyr::tibble( crowns_sf_poly_trees = nrow(crowns_sf_poly) , crowns_nlas_trees = fcrowns_nlas_temp@data$tree_index %&gt;% unique() %&gt;% length() , crowns_metrics_df_trees = nrow(crowns_metrics_df) ) %&gt;% kableExtra::kbl() %&gt;% kableExtra::kable_styling() crowns_sf_poly_trees crowns_nlas_trees crowns_metrics_df_trees 107 107 89 guess not. let’s look at some of those metrics and the convex hull polygons created by the lidR::crown_metrics() plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = z_mean), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) note the overlap of those polygons. what if we attach the crown metrics to the original crown polygons? plt_chm + ggnewscale::new_scale_fill() + geom_sf( data = crowns_sf_poly %&gt;% dplyr::left_join( crowns_metrics_df %&gt;% sf::st_drop_geometry() , by = &quot;tree_index&quot; ) , mapping = aes(fill = z_mean), color = &quot;steelblue&quot; ) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8, na.value = &quot;black&quot;) what is this crr=(mean(z)-min(z))/(max(z)-min(z)) variable? plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = crr), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) how about crown diameter? plt_chm + ggnewscale::new_scale_fill() + geom_sf(data = crowns_metrics_df, mapping = aes(fill = crown_diam), color = &quot;steelblue&quot;) + harrypotter::scale_fill_hp(&quot;always&quot;, alpha = 0.8) 2.3.4 LAI-LAD metrics by Trees see this section of the package README after height normalization and crown segmentation, the LiDAR returns were cropped with the crown contours being voxelized to obtain VHPs from which the absolute mean LAD at each height bin was retrieved (Viedma et al. 2024, p.2). in this section, the las files cropped to individual trees (i.e. one tree at a time) are passed to the leafR package to calculate the LAI-LAD metrics. it seems very inefficient to perform this one-by-one for individual tree point clouds and not something that would work well if many, many trees. let’s go through the process for one tree point cloud # leafR::lad.voxels requires a file location :\\ fn &lt;- paste0(tempdir(), &quot;/temp.las&quot;) # let&#39;s sample the tree with the most points ti &lt;- crowns_nlas_temp@data %&gt;% dplyr::count(tree_index) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::slice_head(n=1) %&gt;% dplyr::pull(tree_index) f &lt;- crowns_nlas_temp %&gt;% lidR::filter_poi(tree_index == ti) %&gt;% # put this in a function and map over trees lidR::writeLAS(file = fn) 2.3.4.1 leafR::lad.voxels Creates a data frame of the 3D voxels information (xyz) with Leaf Area Density values from las file. ##### leafR::lad.voxels # Creates a data frame of the 3D voxels information (xyz) with Leaf Area Density values from las file lad_voxels &lt;- leafR::lad.voxels( # normlas.file requires a file location :\\ normlas.file = f , grain.size = 2 ) class(lad_voxels) ## [1] &quot;list&quot; str(lad_voxels) ## List of 2 ## $ LAD : num [1:20, 1:14] NA 0 0 0 0 ... ## $ coordenates:&#39;data.frame&#39;: 20 obs. of 2 variables: ## ..$ X: num [1:20] 453559 453561 453563 453565 453567 ... ## ..$ Y: num [1:20] 4458585 4458585 4458585 4458585 4458585 ... 2.3.4.2 leafR::lad.profile This function calculate the lad profile from the input lad.voxels. By “profile” I think they mean “vertical height profile” ##### leafR::lad.profile # This function calculate the lad profile from the input lad.voxels lad_profile &lt;- leafR::lad.profile(lad_voxels, relative = F) class(lad_profile) ## [1] &quot;data.frame&quot; str(lad_profile) ## &#39;data.frame&#39;: 14 obs. of 2 variables: ## $ height: num 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 ... ## $ lad : num 0.693 0.405 0.78 0.45 0.289 ... 2.3.4.3 leafR::lai calculates the lead area index (LAI) lai_tot &lt;- leafR::lai(lad_profile) lai_understory &lt;- leafR::lai(lad_profile, min = 0.3, max = 2.5) class(lai_tot) ## [1] &quot;numeric&quot; str(lai_tot) ## num 3.83 str(lai_understory) ## num 1.1 2.3.4.4 leafR::LAHV Calculates the leaf area height volume (LAHV) metric as described in Almeida et al. (2019) lahv_metric &lt;- leafR::LAHV(lad_profile, LAI.weighting = FALSE, height.weighting = FALSE) class(lahv_metric) ## [1] &quot;numeric&quot; str(lahv_metric) ## num 18.2 2.3.4.5 Bring together and clean they call this “Depurating Tree LAD profiles” replace missing LAD values with 0.01 (no explanation of “why”) keep only trees where there are at least 6 profile (vertical height profile) records (&gt;5) leafr_df &lt;- dplyr::tibble( tree_index = ti # put this in a function and map over trees ) %&gt;% dplyr::bind_cols(lad_profile) %&gt;% dplyr::mutate( lad = dplyr::coalesce(lad, 0.01) # not sure why they put in 0.01 here , lai_tot = lai_tot[1] , lai_understory = lai_understory[1] , lahv = lahv_metric[1] , vhp_n = dplyr::n() # they keep trees where there are at least 6 (&gt;5) ) %&gt;% dplyr::arrange(tree_index, height) what is this? leafr_df %&gt;% dplyr::glimpse() ## Rows: 14 ## Columns: 7 ## $ tree_index &lt;int&gt; 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78 ## $ height &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5… ## $ lad &lt;dbl&gt; 0.693147181, 0.405465108, 0.780157428, 0.449590086, 0.2… ## $ lai_tot &lt;dbl&gt; 3.825655, 3.825655, 3.825655, 3.825655, 3.825655, 3.825… ## $ lai_understory &lt;dbl&gt; 1.098612, 1.098612, 1.098612, 1.098612, 1.098612, 1.098… ## $ lahv &lt;dbl&gt; 18.2418, 18.2418, 18.2418, 18.2418, 18.2418, 18.2418, 1… ## $ vhp_n &lt;int&gt; 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14 seems like the data used to create Figure 1 (b) leafr_df %&gt;% ggplot(mapping = aes(x = lad, y = height)) + geom_path() + geom_point() + theme_light() what about the point cloud in voxels? # calculate voxel metrics voxel_metrics( crowns_nlas_temp %&gt;% lidR::filter_poi(tree_index == ti) , ~list(N = length(Z)) , 2 ) %&gt;% lidR::plot( color=&quot;N&quot;, pal = viridis::mako(n = 11, direction = -1) , size = 2, bg = &quot;white&quot;, voxel = TRUE, legend = T ) 2.3.5 I quit I quit following the package README because it’s unnecessarily complex 2.4 LadderFuelsR - simplified the package README is so convoluted and difficult to follow. let’s just cut the superfluity (i’ll see your “depurating” and raise you “superfluity”). someone had to identify the minimum steps needed to get CBH and cut out the superfluous clutter (bonus points if you see what i did there ;). 2.4.1 Setup the las files cropped to individual trees (i.e. one tree at a time) are passed to the leafR package to calculate the LAI-LAD metrics. it seems very inefficient to perform this one-by-one for individual tree point clouds and not something that would work well if many, many trees. let’s go through the process for one tree point cloud # leafR::lad.voxels requires a file location :\\ fn &lt;- paste0(tempdir(), &quot;/temp.las&quot;) # let&#39;s sample the tree with the most points ti &lt;- crowns_nlas_temp@data %&gt;% dplyr::count(tree_index) %&gt;% dplyr::arrange(desc(n)) %&gt;% dplyr::slice_head(n=1) %&gt;% dplyr::pull(tree_index) ( f &lt;- crowns_nlas_temp %&gt;% lidR::filter_poi(tree_index == ti) %&gt;% # put this in a function and map over trees lidR::writeLAS(file = fn) ) ## [1] &quot;C:\\\\Users\\\\georg\\\\AppData\\\\Local\\\\Temp\\\\RtmpUFx6fA/temp.las&quot; 2.4.2 Step 0 - leafR steps leafR::lad.voxels() - use normalized las file to create a data frame of the 3D voxels information (xyz) with Leaf Area Density values leafR::lad.profile() - calculate the lad profile from the input lad.voxels (step 1) ensure that the data frame returned from leafR::lad.profile() has a column named treeID which uniquely identifies individual trees. also, that column has to be the first column (bad practice by the authors) ## leafR::lad.voxels lad_voxels &lt;- leafR::lad.voxels(normlas.file = f, grain.size = 2) lad_voxels %&gt;% dplyr::glimpse() ## List of 2 ## $ LAD : num [1:20, 1:14] NA 0 0 0 0 ... ## $ coordenates:&#39;data.frame&#39;: 20 obs. of 2 variables: ## ..$ X: num [1:20] 453559 453561 453563 453565 453567 ... ## ..$ Y: num [1:20] 4458585 4458585 4458585 4458585 4458585 ... ## leafR::lad.profile lad_profile &lt;- leafR::lad.profile(lad_voxels, relative = F) ## add treeID column that is required by the package, though it&#39;s never stated lad_profile &lt;- lad_profile %&gt;% dplyr::mutate(tree_index = ti, treeID = factor(tree_index)) %&gt;% ## !!!!! not only does the treeID column have to exist...it has to be the first column dplyr::relocate(treeID) lad_profile %&gt;% dplyr::glimpse() ## Rows: 14 ## Columns: 4 ## $ treeID &lt;fct&gt; 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78 ## $ height &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12… ## $ lad &lt;dbl&gt; 0.693147181, 0.405465108, 0.780157428, 0.449590086, 0.28920… ## $ tree_index &lt;int&gt; 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78 2.4.3 Step 1 - LadderFuelsR::get_gaps_fbhs calculates gaps and fuel layers base height (FBH) as the difference in percentiles between consecutive LAD values along the vertical tree profile (VTP). Negative differences are linked to gaps and positive differences to fuel base height. notice that this function is broken in the package…see this issue Viedma et al. 2024 note: Function get_gaps_fbhs() identifies height bins with negative differences in LAD percentile for identifying gaps. When among consecutive height bins differences are negative, it selects the height bin with the lowest LAD (&lt;= perc_gap [P25th]). Additionally, the function looks for height bins with LAD &lt;= P25th, and when they are consecutive, it takes only the first and last values of the set being considered. For obtaining fuel layer base heights (FBHs), it identifies height bins with positive differences in LAD percentile. When such positive differences are consecutive, it selects the height bin with minimum LAD (&gt; perc_base [P25th]). Moreover, it filters height bins with LAD &gt; P25th, and when these are consecutive it takes only the first and last values of each set. Finally, to avoid any duplicated height bins in gaps and FBHs, it selects only the height bins identified as gaps that were not present in the FBH file, giving preference to the FBH height bins (p.3-5) ### this function is broken!!!!!!!!!!!!!!!!!!!!!!!!!! source(&quot;_broken_gap_fbh_from_LadderFuelsR.R&quot;) # gw fix here ## LadderFuelsR::get_gaps_fbhs gaps_fbhs &lt;- gw_get_gaps_fbhs( # LadderFuelsR::get_gaps_fbhs( LAD_profiles = lad_profile , step=1 , min_height=1.5 , perc_gap= 25, perc_base= 25 , verbose=TRUE ) gaps_fbhs %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 24 ## $ treeID &lt;fct&gt; 78 ## $ cbh1 &lt;chr&gt; &quot;1.5&quot; ## $ cbh2 &lt;chr&gt; &quot;3.5&quot; ## $ cbh3 &lt;chr&gt; &quot;6.5&quot; ## $ cbh4 &lt;chr&gt; &quot;9.5&quot; ## $ gap1 &lt;chr&gt; &quot;10.5&quot; ## $ cbh5 &lt;chr&gt; &quot;11.5&quot; ## $ gap2 &lt;chr&gt; &quot;12.5&quot; ## $ gap3 &lt;chr&gt; &quot;14.5&quot; ## $ gap_lad1 &lt;dbl&gt; 0 ## $ gap_lad2 &lt;dbl&gt; 0 ## $ gap_lad3 &lt;dbl&gt; 0 ## $ cbh_perc1 &lt;dbl&gt; 95 ## $ cbh_perc2 &lt;dbl&gt; 100 ## $ cbh_perc3 &lt;dbl&gt; 80 ## $ cbh_perc4 &lt;dbl&gt; 40 ## $ cbh_perc5 &lt;dbl&gt; 35 ## $ cbh_lad1 &lt;dbl&gt; 1 ## $ cbh_lad2 &lt;dbl&gt; 3 ## $ cbh_lad3 &lt;dbl&gt; 6 ## $ cbh_lad4 &lt;dbl&gt; 9 ## $ cbh_lad5 &lt;dbl&gt; 11 ## $ max_height &lt;dbl&gt; 14.5 ## $ treeID1 &lt;dbl&gt; 78 # fix the columns that should be numeric gaps_fbhs &lt;- gaps_fbhs %&gt;% dplyr::mutate(dplyr::across( !tidyselect::starts_with(&quot;treeID&quot;) , as.numeric )) let’s take LadderFuelsR::get_plots_gap_fbh() for a spin which creates the plot in Figure 3 (plots of leaf area density profiles with fuel base heights in green and gaps &gt;= step: Distance between bins in red). This function plots gaps and fuel layers base height (fbh) in the vertical tree profile (VTP). LadderFuelsR::get_plots_gap_fbh( LAD_profiles = lad_profile , gap_cbh_metrics = gaps_fbhs , min_height = 1.5 ) ## $`78` in RED are the GAPS and in GREEN the FBHs can we re-create this? ggplot() + geom_path(data = lad_profile, mapping = aes(x = lad, y = height)) + geom_point(data = lad_profile, mapping = aes(x = lad, y = height)) + # gaps data geom_hline( data = gaps_fbhs %&gt;% dplyr::select( tidyselect::starts_with(&quot;gap&quot;) &amp; !tidyselect::starts_with(&quot;gap_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything()) , aes(yintercept = value, color = &quot;gaps&quot;) , linetype = &quot;dotted&quot; , lwd = 1.2 ) + # fbh data geom_hline( data = gaps_fbhs %&gt;% dplyr::select( tidyselect::starts_with(&quot;cbh&quot;) &amp; !tidyselect::starts_with(&quot;cbh_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything()) , aes(yintercept = value, color = &quot;FBHs&quot;) , linetype = &quot;dotdash&quot; , lwd = 1.2 ) + scale_color_manual(values = c(&quot;green4&quot;, &quot;red&quot;), name = &quot;&quot;) + scale_y_continuous(breaks = scales::extended_breaks(10)) + theme_light() + theme(legend.position = &quot;top&quot;) yes. the gap and cbh columns contain the data ( but not the gap_ and cbh_ columns ;/ ). but what are these columns? cbh - Height of the fuel layer base height (m) gap - Height of gap between fuel layers (m) 2.4.4 Step 2 - LadderFuelsR::calculate_gaps_perc this function calculates the percentile value of each height ## LadderFuelsR::calculate_gaps_perc #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ERROR if treeID is not the first column gaps_perc &lt;- LadderFuelsR::calculate_gaps_perc( LAD_profiles = lad_profile %&gt;% dplyr::select(-tree_index) , min_height=1.5 ) ## [1] &quot;treeID: 78&quot; gaps_perc %&gt;% dplyr::glimpse() ## Rows: 14 ## Columns: 5 ## $ treeID &lt;fct&gt; 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78 ## $ height &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.… ## $ lad &lt;dbl&gt; 0.693147181, 0.405465108, 0.780157428, 0.449590086, 0.… ## $ critical_points &lt;dbl&gt; -0.0000002167, 0.0000920681, -0.0000699130, 0.00015765… ## $ percentil &lt;dbl&gt; 95, 70, 100, 85, 65, 80, 55, 50, 40, 25, 35, 20, 10, 5 2.4.5 Step 3 - LadderFuelsR::get_distance calculates distances (and their heights) between fuel layers as the difference between consecutive gaps and fuel bases (the gap height always must be lower than the fuel base height). Viedma et al. 2024 note: Function get_distance() calculates the distance between fuel layers as the height difference between each pair of consecutive gaps and FBHs (Figure 4a). In addition, when there are consecutive gaps, the distance is calculated as the difference between the minimum gap and the next FBH encountered (Figure 4b). Similarly, when there were consecutive FBHs, the distance was calculated as the difference between the minimum FBH and the previous gap encountered. When there are gaps above the last FBH, these values were removed for further analysis. (p.5) ## LadderFuelsR::get_distance metrics_distance &lt;- LadderFuelsR::get_distance( gap_cbh_metrics = gaps_fbhs , gaps_perc = gaps_perc , step=1, min_height=1.5 ) metrics_distance %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 21 ## $ treeID1 &lt;fct&gt; 78 ## $ treeID &lt;fct&gt; 78 ## $ cbh1 &lt;dbl&gt; 1.5 ## $ cbh2 &lt;dbl&gt; 3.5 ## $ cbh3 &lt;dbl&gt; 6.5 ## $ cbh4 &lt;dbl&gt; 9.5 ## $ gap1 &lt;dbl&gt; 10.5 ## $ cbh5 &lt;dbl&gt; 11.5 ## $ gap2 &lt;dbl&gt; 12.5 ## $ gap3 &lt;dbl&gt; 14.5 ## $ dist5 &lt;dbl&gt; 1 ## $ dist1 &lt;dbl&gt; 0 ## $ max_height &lt;dbl&gt; 14.5 ## $ dist2 &lt;dbl&gt; 0 ## $ dist3 &lt;dbl&gt; 0 ## $ dist4 &lt;dbl&gt; 0 ## $ Hdist5 &lt;dbl&gt; 10.5 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ Hdist2 &lt;dbl&gt; 0 ## $ Hdist3 &lt;dbl&gt; 0 ## $ Hdist4 &lt;dbl&gt; 0 2.4.6 Step 4 - LadderFuelsR::get_depths calculates fuels depth as the difference between gaps interleaved between fuel layers minus one step if the fuel depths are greater than one step. Viedma et al. 2024 note: Function get_depths() calculates the depth of each fuel layer as the difference between the gaps comprising the FBHs. Finally, to get the real layer depth, and only when layer depth is greater than the step, it subtracts the step value from the depth (Figure 5). There are special cases when there are no gaps between FBHs: (i) if the gap height is less than the minimum height of the FBHs, depth is calculated as the difference between the maximum height of the FBHs set and the height of that gap minus the step (Figure 6a); (ii) if the gap height is greater than the maximum height of FBHs, depth is the difference between the maximum gap height and the minimum height of the FBHs set minus the step (Figure 6b). (p.5) ## LadderFuelsR::get_depths metrics_depth &lt;- LadderFuelsR::get_depths( LAD_profiles = lad_profile , distance_metrics = metrics_distance , step= 1, min_height= 1.5 ) metrics_depth %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 13 ## $ treeID &lt;fct&gt; 78 ## $ treeID1 &lt;fct&gt; 78 ## $ Hdepth1 &lt;dbl&gt; 9.5 ## $ Hdepth2 &lt;dbl&gt; 11.5 ## $ dist1 &lt;dbl&gt; 1.5 ## $ dist2 &lt;dbl&gt; 1 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ Hdist2 &lt;dbl&gt; 10.5 ## $ depth1 &lt;dbl&gt; 8 ## $ depth2 &lt;dbl&gt; 1 ## $ cbh1 &lt;dbl&gt; 1.5 ## $ cbh2 &lt;dbl&gt; 11.5 ## $ max_height &lt;dbl&gt; 14.5 2.4.7 Step 5 - LadderFuelsR::get_real_fbh reshapes fuel layers after removing distances equal to any number of height bin steps, keeping the first “base height” from those consecutive ones separated by such distance. Viedma et al. 2024 note: Function get_real_fbh() identifies the first FBH from consecutive FBHs or the first FBH from those separated by a distance equal to number of steps that can be skipped to reshape the fuel layers. For each distance value, it locates the next FBH value. If distance = num_step, the height of that FBH is propagated upwards. If distance &gt; num_step, the height of that FBH is kept (Figure 7a,b). (p.5-6) ## LadderFuelsR::get_real_fbh real_fbh &lt;- LadderFuelsR::get_real_fbh( depth_metrics = metrics_depth , step= 1, number_steps = 1, min_height=1.5 ) real_fbh %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 13 ## $ treeID1 &lt;dbl&gt; 78 ## $ Hdepth1 &lt;dbl&gt; 9.5 ## $ dist1 &lt;dbl&gt; 1.5 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ depth1 &lt;dbl&gt; 8 ## $ Hcbh1 &lt;dbl&gt; 1.5 ## $ Hdepth2 &lt;dbl&gt; 11.5 ## $ dist2 &lt;dbl&gt; 1 ## $ Hdist2 &lt;dbl&gt; 10.5 ## $ depth2 &lt;dbl&gt; 1 ## $ Hcbh2 &lt;dbl&gt; 1.5 ## $ treeID &lt;fct&gt; 78 ## $ max_height &lt;dbl&gt; 14.5 2.4.8 Step 6 - LadderFuelsR::get_real_depths recalculates fuel layers depth after considering distances greater than the actual height bin step. Viedma et al. 2024 note: Function get_real_depths() calculates the cumulative heights of depth values when distance = num_step. It iterates over each distance value and if dist[i] &gt; num_step, it keeps the corresponding depth value. However, if dist[i] = num_step, it sums all consecutive distances and corresponding depth values (Figure 7a,b). (p.6) ## LadderFuelsR::get_real_depths real_depth &lt;- LadderFuelsR::get_real_depths(effective_fbh = real_fbh, step=1, min_height=1.5) real_depth %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 8 ## $ treeID &lt;fct&gt; 78 ## $ treeID1 &lt;dbl&gt; 78 ## $ Hdptf1 &lt;dbl&gt; 11.5 ## $ dist1 &lt;dbl&gt; 0 ## $ dptf1 &lt;dbl&gt; 10 ## $ Hcbh1 &lt;dbl&gt; 1.5 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ max_height &lt;dbl&gt; 14.5 2.4.9 Step 7 - LadderFuelsR::get_effective_gap recalculates the distance between fuel layers after considering distances greater than any number of height bin steps. Viedma et al. 2024 note: Function get_effective_gap() calculates the effective distance between fuel layers based on the previously identified FBHs. It loops over all the FBHs and, at each iteration, it checks if the current value and the next value in FBHs are not equal. If they are not equal, it keeps the corresponding distance value, otherwise it removes it (Figure 8). (p.6) ## LadderFuelsR::get_effective_gap eff_gap &lt;- LadderFuelsR::get_effective_gap( effective_depth = real_depth , number_steps = 1, min_height= 1.5 ) eff_gap %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 9 ## $ treeID &lt;fct&gt; 78 ## $ treeID1 &lt;dbl&gt; 78 ## $ dist1 &lt;dbl&gt; 0 ## $ dptf1 &lt;dbl&gt; 10 ## $ effdist1 &lt;dbl&gt; 0 ## $ Hcbh1 &lt;dbl&gt; 1.5 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ Hdptf1 &lt;dbl&gt; 11.5 ## $ max_height &lt;dbl&gt; 14.5 2.4.10 Step 8 - LadderFuelsR::get_layers_lad calculates the percentage of Leaf Area Density (LAD) within each fuel layer (first output) and removes those fuel layers with LAD percentage less than a specified threshold (default 10 the depth of the remaining ones (second output). Viedma et al. 2024 note: Function get_layers_lad() calculates LAD (%) within each fuel layer, which is defined by the height range between the FBH and its depth. First, it calculates the total LAD from the original profile. Next, it retrieves the beginning and end height bin of each fuel layer and calculates the percentage of total LAD that falls within that height range. Later, the fuel layers that had a LAD (%) less than a specified threshold (default 10%) were removed, recalculating the distances (Figure 9). (p.7) ## LadderFuelsR::get_layers_lad layers_lad_df &lt;- LadderFuelsR::get_layers_lad( LAD_profiles = lad_profile , effective_distances = eff_gap , threshold=10,step = 1,min_height= 1.5 ) layers_lad_df %&gt;% str() ## List of 2 ## $ df1:&#39;data.frame&#39;: 1 obs. of 12 variables: ## ..$ treeID1 : num 78 ## ..$ treeID : Factor w/ 1 level &quot;78&quot;: 1 ## ..$ dist1 : num 0 ## ..$ dptf1 : num 10 ## ..$ effdist1 : num 0 ## ..$ Hcbh1 : num 1.5 ## ..$ Hdist1 : num 1.5 ## ..$ Hdptf1 : num 11.5 ## ..$ max1 : num 14.5 ## ..$ Hcbh1_Hdptf1: num 99.5 ## ..$ max_height : num 14.5 ## ..$ nlayers : int 1 ## $ df2:&#39;data.frame&#39;: 1 obs. of 11 variables: ## ..$ treeID1 : num 78 ## ..$ treeID : Factor w/ 1 level &quot;78&quot;: 1 ## ..$ dptf1 : num 10 ## ..$ effdist1 : num 0 ## ..$ Hcbh1 : num 1.5 ## ..$ Hdist1 : num 1.5 ## ..$ Hdptf1 : num 11.5 ## ..$ max1 : num 14.5 ## ..$ max_height : num 14.5 ## ..$ Hcbh1_Hdptf1: num 99.5 ## ..$ nlayers : int 1 idk why it is a list of 2 with the same data just the order of the max_height and Hcbh1_Hdptf1 columns are switched. do you spot another difference?? looking through the befuddling README it looks like the authors only keep the second data frame in the list (layers_lad_df &lt;- layers_lad_df[[2]]) ## treeID1 treeID dptf1 effdist1 Hcbh1 Hdist1 Hdptf1 max1 max_height ## 1 78 78 10 0 1.5 1.5 11.5 14.5 14.5 ## Hcbh1_Hdptf1 nlayers ## 1 99.47572 1 is CBH in here? did we do it? treeID: tree ID with strings and numeric values treeID1: tree ID with only numeric values dptf: Depth of fuel layers (m) after considering distances greater than the actual height bin step effdist: Effective distance between consecutive fuel layers (m) after considering distances greater than any number of steps Hcbh: Base height of each fuel separated by a distance greater than the certain number of steps Hdptf: Height of the depth of fuel layers (m) after considering distances greater than the actual step Hdist: Height of the distance (&gt; any number of steps) between consecutive fuel layers (m) Hcbh_Hdptf - Percentage of LAD values comprised in each effective fuel layer max_height - Maximum height of the tree profile nlayers - Number of effective fuel layers is it possible to have multiple Hcbh values for one tree? is step 9 below even necessary at this point? let’s take the LadderFuelsR::get_plots_effective() function for a spin LadderFuelsR::get_plots_effective( LAD_profiles = lad_profile , effective_LAD = layers_lad_df , min_height = 1.5 ) ## $`78` maybe we’ll try to recreate this plot at some point # wanna recreate this? 2.4.11 Step 9 - LadderFuelsR::get_cbh_dist LadderFuelsR::get_cbh_metrics LadderFuelsR::get_cbh_dist is described in the research article but does not exist in the package or README. Looks like LadderFuelsR::get_cbh_metrics is there though. determines the CBH of a segmented tree using three criteria: maximum LAD percentage, maximum distance and the last distance. Viedma et al. 2024 note: Function get_cbh_dist() applies three criteria to define the CBH in a segmented tree: the fuel layer containing the maximum LAD (%) (Figure 10a), the fuel layer located at the highest distance (Figure 10b), and the fuel layer separated by the last effective distance (Figure 10c). In the case of maximum LAD (%), the output also gives the CBH from the second fuel layer when the first one has the maximum LAD (%) but its depth is smaller than the value indicated in the parameter ‘hdepth1_height’ (default 2m). (p.8) ## LadderFuelsR::get_cbh_metrics cbh_metrics &lt;- LadderFuelsR::get_cbh_metrics(effective_LAD = layers_lad_df, min_height= 1.5) cbh_metrics %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 29 ## $ treeID1 &lt;dbl&gt; 78 ## $ dptf1 &lt;dbl&gt; 10 ## $ effdist1 &lt;dbl&gt; 0 ## $ Hcbh1 &lt;dbl&gt; 1.5 ## $ Hdist1 &lt;dbl&gt; 1.5 ## $ Hdptf1 &lt;dbl&gt; 11.5 ## $ max1 &lt;dbl&gt; 14.5 ## $ Hcbh1_Hdptf1 &lt;dbl&gt; 99.47572 ## $ treeID &lt;fct&gt; 78 ## $ max_height &lt;dbl&gt; 14.5 ## $ nlayers &lt;int&gt; 1 ## $ maxlad_Hcbh &lt;dbl&gt; 1.5 ## $ maxlad_Hdist &lt;dbl&gt; 1.5 ## $ maxlad_Hdptf &lt;dbl&gt; 11.5 ## $ maxlad_dptf &lt;dbl&gt; 10 ## $ maxlad_effdist &lt;dbl&gt; 0 ## $ maxlad_lad &lt;dbl&gt; 99.47572 ## $ max_Hcbh &lt;dbl&gt; 1.5 ## $ max_Hdist &lt;dbl&gt; 1.5 ## $ max_Hdptf &lt;dbl&gt; 11.5 ## $ max_dptf &lt;dbl&gt; 10 ## $ max_effdist &lt;dbl&gt; 0 ## $ max_lad &lt;dbl&gt; 99.47572 ## $ last_Hcbh &lt;dbl&gt; 1.5 ## $ last_Hdist &lt;dbl&gt; 1.5 ## $ last_Hdptf &lt;dbl&gt; 11.5 ## $ last_dptf &lt;dbl&gt; 10 ## $ last_effdist &lt;dbl&gt; 0 ## $ last_lad &lt;dbl&gt; 99.47572 what are these? treeID: tree ID with strings and numeric values treeID1: tree ID with only numeric values dptf: Depth of fuel layers (m) after considering distances greater than the actual height bin step effdist: Effective distance between consecutive fuel layers (m) after considering distances greater than any number of steps Hcbh: Base height of each fuel separated by a distance greater than the certain number of steps Hdptf: Height of the depth of fuel layers (m) after considering distances greater than the actual step Hdist: Height of the distance (&gt; any number of steps) between consecutive fuel layers (m) Hcbh_Hdptf - Percentage of LAD values comprised in each effective fuel layer maxlad_Hcbh - Height of the CBH of the segmented tree based on the maximum LAD percentage maxlad1_Hcbh - Height of the CBH from the second fuel layer when the maximum LAD occurred in the first fuel layer but its depth &lt;= “hdepth1_height” max_Hcbh - Height of the CBH of the segmented tree based on the maximum distance found in its profile last_Hcbh - Height of the CBH of the segmented tree based on the last distance found in its profile maxlad_ - Values of distance and fuel depth and their corresponding heights at the maximum LAD percentage maxlad1_ - Values of distance and fuel depth and their corresponding heights for the second fuel layer when the maximum LAD occurred in the first fuel layer but its depth &lt;= “hdepth1_height” max_ - Values of distance and fuel depth and their corresponding heights at the maximum distance last_ - Values of distance and fuel depth and their corresponding heights at the last distance nlayers - Number of effective fuel layers max_height - Maximum height of the tree profile there are also some plotting functions # Generate plots for fuels LAD metrics plots_cbh_maxlad &lt;- LadderFuelsR::get_plots_cbh_LAD( LAD_profiles = lad_profile , cbh_metrics = cbh_metrics , min_height=1.5 ) plots_cbh_maxdist &lt;- LadderFuelsR::get_plots_cbh_maxdist( LAD_profiles = lad_profile , cbh_metrics = cbh_metrics , min_height=1.5 ) plots_cbh_lastdist &lt;- LadderFuelsR::get_plots_cbh_lastdist( LAD_profiles = lad_profile , cbh_metrics = cbh_metrics , min_height=1.5 ) # patchwork them (plots_cbh_maxlad[[1]] + labs(title = &quot;get_plots_cbh_LAD&quot;)) + (plots_cbh_maxdist[[1]] + labs(title = &quot;get_plots_cbh_maxdist&quot;)) + (plots_cbh_lastdist[[1]] + labs(title = &quot;get_plots_cbh_lastdist&quot;)) + patchwork::plot_layout(ncol = 2) these plots represent the three criteria to define the CBH in a segmented tree: get_plots_cbh_LAD = the fuel layer containing the maximum LAD percentage (column named maxlad_Hcbh) get_plots_cbh_maxdist = the fuel layer located at the highest distance (column named max_Hcbh) get_plots_cbh_lastdist = the fuel layer separated by the last effective distance (column named last_Hcbh) "],["s02.html", "Section 3 CBH Process 3.1 Get some lidar data 3.2 Define LadderFuelsR Processing Function 3.3 Function to CBH a tree list 3.4 Test CBH process - lidar 3.5 Test CBH process - UAS", " Section 3 CBH Process In this prior section we reviewed the methodologies to process lidar data, extract a tree list, and estimate CBH. Presently, we will outline the end-to-end process for accomplishing this task given some example lidar data. 3.1 Get some lidar data Let’s load an example lidar dataset from Weinstein et al. (2021) in their NeonTreeEvaluation package. We’ll use data from a NEON site that we know has conifers: RMNP (Rocky Mountain National Park) # let&#39;s see some field trees data NeonTreeEvaluation::field %&gt;% dplyr::filter(siteID == &quot;RMNP&quot;) %&gt;% dplyr::count(taxonID) %&gt;% dplyr::arrange(desc(n)) ## taxonID n ## 1 PICOL 773 ## 2 POTR5 292 ## 3 PIPOS 91 ## 4 PSME 89 ## 5 ABLAL 57 ## 6 PIEN 39 ## 7 PIFL2 34 let’s pick a site with the lowest proportion of POTR5 plots_temp &lt;- NeonTreeEvaluation::field %&gt;% dplyr::filter(siteID == &quot;RMNP&quot;) %&gt;% dplyr::group_by(plotID) %&gt;% dplyr::summarise( trees = dplyr::n() , conifers = sum(ifelse(taxonID==&quot;POTR5&quot;, 0, 1)) ) %&gt;% dplyr::mutate(pct_conifer = conifers/trees) %&gt;% dplyr::filter(trees&gt;20) %&gt;% dplyr::arrange(desc(pct_conifer), desc(trees)) plots_temp ## # A tibble: 20 × 4 ## plotID trees conifers pct_conifer ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 RMNP_042 111 111 1 ## 2 RMNP_043 104 104 1 ## 3 RMNP_047 59 59 1 ## 4 RMNP_008 50 50 1 ## 5 RMNP_048 50 50 1 ## 6 RMNP_001 41 41 1 ## 7 RMNP_006 39 39 1 ## 8 RMNP_014 36 36 1 ## 9 RMNP_012 35 35 1 ## 10 RMNP_003 30 30 1 ## 11 RMNP_018 29 29 1 ## 12 RMNP_005 24 24 1 ## 13 RMNP_002 21 21 1 ## 14 RMNP_041 131 128 0.977 ## 15 RMNP_004 27 26 0.963 ## 16 RMNP_049 36 34 0.944 ## 17 RMNP_007 30 24 0.8 ## 18 RMNP_044 111 68 0.613 ## 19 RMNP_045 229 57 0.249 ## 20 RMNP_046 73 13 0.178 get the lidar data # get the laz file path las_f_path &lt;- paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = T) %&gt;% unique() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(f_path = 1) %&gt;% dplyr::filter( stringr::str_detect(f_path, as.character(plots_temp[1,]$plotID)) ) %&gt;% .[1] %&gt;% dplyr::pull(f_path) # check the data lidR::readLAS(las_f_path) ## class : LAS (v1.3 format 1) ## memory : 1.2 Mb ## extent : 453532.6, 453572.6, 4458556, 4458596 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1653 m² ## points : 20.4 thousand points ## density : 12.35 points/m² ## density : 7.63 pulses/m² where in the world is this data? las_ctg &lt;- lidR::readLAScatalog(las_f_path) mapview::mapview(las_ctg@data) zoom out if you can’t see anything let’s read one file las &lt;- lidR::readLAS(las_f_path) las ## class : LAS (v1.3 format 1) ## memory : 1.2 Mb ## extent : 453532.6, 453572.6, 4458556, 4458596 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1653 m² ## points : 20.4 thousand points ## density : 12.35 points/m² ## density : 7.63 pulses/m² plot a sample las %&gt;% lidR::plot( color = &quot;Z&quot;, breaks = &quot;quantile&quot;, bg = &quot;white&quot;, legend = T , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) 3.1.1 cloud2trees that lidar data extract trees from the lidar data using cloud2trees to create some example tree-level point cloud data to test the LadderFuelsR function we define below with cloud2trees_ans &lt;- cloud2trees::cloud2trees( input_las_dir = las_f_path , output_dir = &quot;../data&quot; , estimate_tree_dbh = F , keep_intrmdt = T ) ## Read files headers: [==========] 100% (1 threads) Overall: [ ] 0% (1 threads) | : no progress Overall: [ ] 0% (1 threads) | read_las: [ ] 0% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 1% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 2% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 3% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 4% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 5% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 6% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 7% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 8% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [ ] 9% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 10% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 11% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 12% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 13% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 14% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 15% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 16% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 17% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 18% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [= ] 19% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 20% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 21% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 22% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 23% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 24% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 25% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 26% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 27% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 28% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [== ] 29% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 30% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 31% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 32% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 33% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 34% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 35% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 36% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 37% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 38% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [=== ] 39% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 40% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 41% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 42% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 43% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 44% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 45% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 46% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 47% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 48% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==== ] 49% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 50% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 51% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 52% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 53% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 54% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 55% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 56% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 57% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 58% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [===== ] 59% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 60% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 61% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 62% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 63% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 64% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 65% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 66% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 67% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 68% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [====== ] 69% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 70% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 71% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 72% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 73% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 74% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 75% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 76% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 77% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 78% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======= ] 79% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 80% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 81% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 82% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 83% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 84% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 85% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 86% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 87% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 88% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [======== ] 89% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 90% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 91% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 92% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 93% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 94% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 95% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 96% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 97% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 98% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [========= ] 99% (1 threads) Overall: [ ] 0% (1 threads) | read_las: [==========] 100% (1 threads) Overall: [ ] 0% (1 threads) | CSF: no progress Overall: [ ] 0% (1 threads) | Write LAS: [ ] 0% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 1% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 2% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 3% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 4% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 5% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 6% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 7% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 8% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 9% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 10% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 11% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 12% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 13% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 14% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 15% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 16% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 17% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 18% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 19% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 20% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 21% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 22% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 23% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 24% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 25% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 26% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 27% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 28% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 29% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 30% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 31% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 32% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 33% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 34% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 35% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 36% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 37% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 38% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 39% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 40% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 41% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 42% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 43% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 44% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 45% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 46% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 47% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 48% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 49% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 50% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 51% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 52% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 53% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 54% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 55% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 56% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 57% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 58% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 59% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 60% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 61% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 62% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 63% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 64% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 65% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 66% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 67% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 68% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 69% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 70% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 71% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 72% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 73% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 74% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 75% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 76% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 77% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 78% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 79% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 80% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 81% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 82% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 83% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 84% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 85% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 86% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 87% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 88% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 89% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 90% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 91% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 92% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 93% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 94% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 95% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 96% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 97% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 98% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 99% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==========] 100% (1 threads) Overall: [ ] 0% (1 threads) | Delaunay triangulation: no progress Overall: [ ] 0% (1 threads) | Delaunay triangulation: no progress Overall: [ ] 0% (1 threads) | Interpolation: [ ] 0% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 1% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 2% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 3% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 4% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 5% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 6% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 7% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 8% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 9% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [==========] 100% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 0% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 1% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 2% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 3% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 4% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 5% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 6% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 7% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 8% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [ ] 9% (10 threads) Overall: [ ] 0% (1 threads) | Interpolation: [==========] 100% (10 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 0% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 1% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 2% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 3% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 4% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 5% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 6% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 7% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 8% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [ ] 9% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 10% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 11% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 12% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 13% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 14% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 15% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 16% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 17% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 18% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [= ] 19% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 20% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 21% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 22% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 23% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 24% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 25% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 26% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 27% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 28% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [== ] 29% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 30% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 31% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 32% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 33% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 34% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 35% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 36% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 37% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 38% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [=== ] 39% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 40% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 41% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 42% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 43% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 44% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 45% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 46% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 47% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 48% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==== ] 49% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 50% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 51% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 52% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 53% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 54% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 55% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 56% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 57% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 58% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [===== ] 59% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 60% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 61% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 62% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 63% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 64% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 65% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 66% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 67% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 68% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [====== ] 69% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 70% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 71% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 72% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 73% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 74% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 75% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 76% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 77% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 78% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======= ] 79% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 80% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 81% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 82% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 83% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 84% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 85% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 86% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 87% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 88% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [======== ] 89% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 90% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 91% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 92% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 93% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 94% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 95% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 96% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 97% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 98% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [========= ] 99% (1 threads) Overall: [ ] 0% (1 threads) | Write LAS: [==========] 100% (1 threads) Overall: [==========] 100% (1 threads) | Overall: [==========] 100% (1 threads) norm_las_dir &lt;- &quot;../data/point_cloud_processing_temp/02_normalize/&quot; # what? cloud2trees_ans %&gt;% names() ## [1] &quot;crowns_sf&quot; &quot;treetops_sf&quot; &quot;dtm_rast&quot; &quot;chm_rast&quot; cloud2trees_ans$crowns_sf %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 22 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ tree_x &lt;dbl&gt; 453532.6, 453544.6, 453542.6, 453547.4, 4535… ## $ tree_y &lt;dbl&gt; 4458595, 4458595, 4458594, 4458593, 4458592,… ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ geometry &lt;GEOMETRY [m]&gt; POLYGON ((453532.5 4458595,..., POL… ## $ fia_est_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_lower &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_upper &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_data &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_ft2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_cbh &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … clean it for LadderFuelsR to attach treeID to the point cloud # the lidR::merge_spatial requires only polygons so we need to rid the multipolygons crowns_sf_poly &lt;- # start with only polygons cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(.)==&quot;POLYGON&quot;) %&gt;% # union on cleaned multipolygons dplyr::bind_rows( cloud2trees_ans$crowns_sf %&gt;% dplyr::filter(sf::st_geometry_type(.)==&quot;MULTIPOLYGON&quot;) %&gt;% sf::st_cast(to = &quot;POLYGON&quot;, do_split = T, warn = F) %&gt;% dplyr::mutate(axxx = sf::st_area(.)) %&gt;% # axxx is so we don&#39;t overwrite a column dplyr::group_by(treeID) %&gt;% dplyr::filter(axxx == max(axxx)) %&gt;% # keep the biggest crown polygon by treeID dplyr::ungroup() %&gt;% dplyr::select(-axxx) ) %&gt;% # generate a treeID index because it needs to be numeric dplyr::ungroup() %&gt;% dplyr::mutate( treeID_backup = treeID , treeID = dplyr::row_number() ) read in normalized las files and filter one for testing # read in catalog crowns_nlas_ctg &lt;- lidR::readLAScatalog(norm_las_dir) # filter for single tree point cloud one_tree_sf &lt;- crowns_sf_poly %&gt;% # get one of the taller trees dplyr::filter(tree_height_m &gt;= quantile(crowns_sf_poly$tree_height_m, probs = 0.9)) %&gt;% dplyr::slice_sample(n=1) now we’ll attach the treeID column to the normalized las file and keep only the points that fall within a tree crown. # clip the point cloud nlas_one_tree &lt;- lidR::clip_roi( las = crowns_nlas_ctg , geometry = one_tree_sf ) %&gt;% sf::st_set_crs(sf::st_crs(crowns_sf_poly)) %&gt;% lidR::merge_spatial( source = crowns_sf_poly , attribute = &quot;treeID&quot; ) %&gt;% lidR::filter_poi(!is.na(treeID)) # what is this data? nlas_one_tree@data %&gt;% dplyr::glimpse() ## Rows: 253 ## Columns: 17 ## $ X &lt;dbl&gt; 453548.8, 453548.6, 453546.3, 453546.5, 453546.8, 45… ## $ Y &lt;dbl&gt; 4458561, 4458561, 4458561, 4458561, 4458561, 4458561… ## $ Z &lt;dbl&gt; 0.000, 6.142, 1.974, 0.000, 1.947, 0.000, 7.642, 5.3… ## $ gpstime &lt;dbl&gt; 409990.2, 409990.2, 409990.2, 409990.2, 409990.2, 40… ## $ Intensity &lt;int&gt; 70, 83, 45, 196, 27, 224, 33, 30, 12, 53, 72, 67, 14… ## $ ReturnNumber &lt;int&gt; 3, 1, 2, 3, 1, 2, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1… ## $ NumberOfReturns &lt;int&gt; 3, 2, 3, 3, 2, 2, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4… ## $ ScanDirectionFlag &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ EdgeOfFlightline &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Classification &lt;int&gt; 2, 5, 5, 2, 1, 2, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5… ## $ Synthetic_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Keypoint_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ Withheld_flag &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL… ## $ ScanAngleRank &lt;int&gt; -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, -7, … ## $ UserData &lt;int&gt; 0, 61, 20, 0, 19, 0, 76, 54, 26, 0, 94, 81, 61, 0, 1… ## $ PointSourceID &lt;int&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9… ## $ treeID &lt;int&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 10… 3.2 Define LadderFuelsR Processing Function In this prior section we identified the minimum steps needed to get CBH using the LadderFuelsR and leafR packages. Unfortunately, extracting CBH from the point cloud following these methods is performed one-by-one for individual trees. This does not seem like something that would work well if many, many trees. There are a few possible paths forward to get CBH from point cloud data: * Extract CBH from the point cloud for all trees using the LadderFuelsR methodology * Extract CBH from the point cloud for a sample of trees using the LadderFuelsR methodology and build a model to estimate the rest * Use the TreeMap 2016 data to model CBH using a regional model Let’s build a function to combine the LadderFuelsR steps for estimating CBH from the individual tree point cloud. Our function will take a point cloud as input and return a data frame. ladderfuelsr_cbh &lt;- function( las , treeID = NA # minimum vhp records # https://github.com/olgaviedma/LadderFuelsR?tab=readme-ov-file#8depurating-tree-lad-profiles , min_vhp_n = 6 # leafR::lad.voxels , voxel_grain_size_m = 2 # grain.size # LadderFuelsR::get_gaps_fbhs , dist_btwn_bins_m = 1 # step , min_fuel_layer_ht_m = 1.5 # min_height , lad_pct_gap = 25 # perc_gap , lad_pct_base = 25 # perc_base # LadderFuelsR::get_real_fbh , num_jump_steps = 1 # number_steps # LadderFuelsR::get_layers_lad , min_lad_pct = 10 # threshold # LadderFuelsR::get_cbh_metrics , frst_layer_min_ht_m = 2.5 # hdepth1_height ) { # check if string to las/laz file if(inherits(las, &quot;character&quot;)){ if(!stringr::str_ends(las, &quot;.*\\\\.(laz|las)$&quot;)){ stop(&quot;must pass a .las|.laz file path -OR- an object of class LAS to the `las` parameter&quot;) } # set the file path f &lt;- normalizePath(las) }else if(inherits(las, &quot;LAS&quot;)){ # have to write the las to a tempfile fn &lt;- paste0(tempdir(), &quot;/temp.las&quot;) # check if has a treeID if( (names(las@data) %&gt;% stringr::str_detect(&quot;treeID&quot;) %&gt;% max())==1 ){ n &lt;- las@data$treeID %&gt;% unique() %&gt;% length() if(n&gt;1 &amp; is.na(treeID)){ stop(&quot;the treeID column has more than one tree detected. set the `treeID` parameter&quot;) }else if(is.na(treeID)){ # set the treeID treeID &lt;- las@data$treeID %&gt;% unique() # write it f &lt;- las %&gt;% lidR::filter_poi(treeID == treeID) %&gt;% lidR::writeLAS(file = fn) }else{ # write it f &lt;- las %&gt;% lidR::filter_poi(treeID == treeID) %&gt;% lidR::writeLAS(file = fn) } }else{ # write it f &lt;- las %&gt;% lidR::writeLAS(file = fn) } }else{ stop(&quot;must pass a .las|.laz file path -OR- an object of class LAS to the `las` parameter&quot;) } # check the treeID treeID &lt;- dplyr::coalesce(as.character(treeID), as.character(1)) # if the treeID parameter is not set, fake 1 ####################################### ### Step 0 - `leafR` steps ####################################### # 1) `leafR::lad.voxels()` - use normalized las file to create # a data frame of the 3D voxels information (xyz) with Leaf Area Density values # 2) `leafR::lad.profile()` - calculate the lad profile from # the input lad.voxels (step 1) # 3) ensure that the data frame returned from `leafR::lad.profile()` # has a column named `treeID` which uniquely identifies individual trees. # also, that column has to be the first column (bad practice by the authors) ## leafR::lad.voxels lad_voxels &lt;- leafR::lad.voxels(normlas.file = f, grain.size = voxel_grain_size_m) ## leafR::lad.profile lad_profile &lt;- leafR::lad.profile(lad_voxels, relative = F) ## add treeID column that is required by the package, though it&#39;s never stated lad_profile &lt;- lad_profile %&gt;% dplyr::mutate( treeID = treeID %&gt;% factor() ) %&gt;% ## !!!!! not only does the treeID column have to exist...it has to be the first column dplyr::relocate(treeID) %&gt;% dplyr::filter(treeID == treeID) ### check if all NA or all 0, whereby no fuel gaps can be determined prof_na &lt;- lad_profile %&gt;% dplyr::filter(dplyr::coalesce(lad,0) == 0) %&gt;% nrow() if( nrow(lad_profile)-prof_na &lt;= 1 ){ message( paste0( &quot;no fuel gaps found. unable to quantify CBH (treeID=&quot; , treeID, &quot;).&quot; ) ) return(NULL) }else if(nrow(lad_profile) &lt; min_vhp_n){ message( paste0( nrow(lad_profile) , &quot; fuel vertical height profiles found. unable to quantify CBH (treeID=&quot; , treeID, &quot;). try decreasing the `min_vhp_n` parameter?&quot; ) ) return(NULL) } else{ ## &quot;depurating tree lad profiles&quot; ## see: https://github.com/olgaviedma/LadderFuelsR#8depurating-tree-lad-profiles lad_profile &lt;- lad_profile %&gt;% dplyr::mutate(lad = dplyr::coalesce(as.numeric(lad), 0.01)) %&gt;% dplyr::arrange(treeID, height) ####################################### ### Step 1 - `LadderFuelsR::get_gaps_fbhs` ####################################### ### this function is fixed: https://github.com/olgaviedma/LadderFuelsR/pull/3 ### LadderFuelsR::get_gaps_fbhs ### This function calculates gaps and fuel layers base height (FBH) as ### the difference in percentiles between consecutive LAD values along the vertical tree profile (VTP) # quiet this function quiet_get_gaps_fbhs &lt;- purrr::quietly(LadderFuelsR::get_gaps_fbhs) gaps_fbhs &lt;- # gw_get_gaps_fbhs( # LadderFuelsR::get_gaps_fbhs( quiet_get_gaps_fbhs( LAD_profiles = lad_profile , step = dist_btwn_bins_m , min_height = min_fuel_layer_ht_m , perc_gap = lad_pct_gap , perc_base = lad_pct_base , verbose = F ) # just get the result gaps_fbhs &lt;- gaps_fbhs$result # fix the columns that should be numeric gaps_fbhs &lt;- gaps_fbhs %&gt;% dplyr::mutate(dplyr::across( !tidyselect::starts_with(&quot;treeID&quot;) , as.numeric )) ### check for all NA or 0 gaps_na &lt;- gaps_fbhs %&gt;% dplyr::filter( dplyr::if_all( .cols = -tidyselect::starts_with(&quot;treeID&quot;) , .fns = ~ dplyr::coalesce(.x, 0) == 0 ) ) %&gt;% nrow() if(gaps_na&gt;0){ message( paste0( &quot;no fuel gaps found. unable to quantify CBH (treeID=&quot; , treeID, &quot;).&quot; ) ) return(NULL) }else{ ######`################################# ### Step 2 - `LadderFuelsR::calculate_gaps_perc` ####################################### ### this function calculates the percentile value of each height ## LadderFuelsR::calculate_gaps_perc #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ERROR if treeID is not the first column # quiet this function quiet_calculate_gaps_perc &lt;- purrr::quietly(LadderFuelsR::calculate_gaps_perc) # run it quietly gaps_perc &lt;- quiet_calculate_gaps_perc( # LadderFuelsR::calculate_gaps_perc( LAD_profiles = lad_profile , min_height = min_fuel_layer_ht_m ) # just get the result gaps_perc &lt;- gaps_perc$result ####################################### ### Step 3 - `LadderFuelsR::get_distance` ####################################### ### calculates distances (and their heights) between fuel layers as ### the difference between consecutive gaps and fuel bases ### (the gap height always must be lower than the fuel base height). ## LadderFuelsR::get_distance metrics_distance &lt;- LadderFuelsR::get_distance( gap_cbh_metrics = gaps_fbhs , gaps_perc = gaps_perc , step = dist_btwn_bins_m , min_height = min_fuel_layer_ht_m , verbose = F ) ####################################### ### Step 4 - `LadderFuelsR::get_depths` ####################################### ### calculates fuels depth as the difference between gaps ### interleaved between fuel layers minus one step if ### the fuel depths are greater than one step. ## LadderFuelsR::get_depths metrics_depth &lt;- LadderFuelsR::get_depths( LAD_profiles = lad_profile , distance_metrics = metrics_distance , step = dist_btwn_bins_m , min_height= min_fuel_layer_ht_m , verbose = F ) ####################################### ### Step 5 - `LadderFuelsR::get_real_fbh` ####################################### ### reshapes fuel layers after removing distances equal ### to any number of height bin steps, keeping the first ### &quot;base height&quot; from those consecutive ones separated by such distance. ## LadderFuelsR::get_real_fbh real_fbh &lt;- LadderFuelsR::get_real_fbh( depth_metrics = metrics_depth , step = dist_btwn_bins_m , number_steps = num_jump_steps , min_height = min_fuel_layer_ht_m , verbose = F ) ####################################### ### Step 6 - `LadderFuelsR::get_real_depths` ####################################### ### recalculates fuel layers depth after considering ### distances greater than the actual height bin step. ## LadderFuelsR::get_real_depths real_depth &lt;- LadderFuelsR::get_real_depths( effective_fbh = real_fbh , step = dist_btwn_bins_m , min_height = min_fuel_layer_ht_m , verbose = F ) ####################################### ### Step 7 - `LadderFuelsR::get_effective_gap` ####################################### ### recalculates the distance between fuel layers after considering ### distances greater than any number of height bin steps. ## LadderFuelsR::get_effective_gap eff_gap &lt;- LadderFuelsR::get_effective_gap( effective_depth = real_depth , number_steps = num_jump_steps , min_height = min_fuel_layer_ht_m , verbose = F ) ####################################### ### Step 8 - `LadderFuelsR::get_layers_lad` ####################################### ### calculates the percentage of Leaf Area Density (LAD) within ### each fuel layer (first output) and removes those fuel layers ### with LAD percentage less than a specified threshold ### (default 10 the depth of the remaining ones (second output). ## LadderFuelsR::get_layers_lad layers_lad_df &lt;- LadderFuelsR::get_layers_lad( LAD_profiles = lad_profile , effective_distances = eff_gap , threshold = min_lad_pct , step = dist_btwn_bins_m , min_height = min_fuel_layer_ht_m , verbose = F ) ### idk why it is a list of 2 with the same data just the order ### of the `max_height` and `Hcbh1_Hdptf1` columns are switched. do you spot another difference?? ### looking through the befuddling README it looks like the authors only keep ### the second data frame in the list if(length(layers_lad_df)&gt;1){ layers_lad_df &lt;- layers_lad_df[[2]] } ####################################### ### Step 9 - `LadderFuelsR::get_cbh_metrics` ####################################### ### `LadderFuelsR::get_cbh_dist` is described in the research article but does not ### exist in the package or README. Looks like `LadderFuelsR::get_cbh_metrics` is there though. ### determines the CBH of a segmented tree using three criteria: ### maximum LAD percentage, maximum distance and the last distance. ## LadderFuelsR::get_cbh_metrics cbh_metrics &lt;- LadderFuelsR::get_cbh_metrics( effective_LAD = layers_lad_df , min_height = min_fuel_layer_ht_m , hdepth1_height = frst_layer_min_ht_m , verbose = F ) # return return(list( gaps_fbhs = gaps_fbhs , lad_profile = lad_profile , gaps_perc = gaps_perc , metrics_distance = metrics_distance , metrics_depth = metrics_depth , real_fbh = real_fbh , real_depth = real_depth , eff_gap = eff_gap , layers_lad_df = layers_lad_df , cbh_metrics = cbh_metrics )) } # if all NA or all 0, whereby no fuel gaps can be determined } # if all NA or all 0, whereby no fuel gaps can be determined } # CALL IT ladderfuelsr_cbh_ans &lt;- cloud2trees::ladderfuelsr_cbh( las = nlas_one_tree # %&gt;% lidR::decimate_points(random(0.5)) ) ladderfuelsr_cbh_ans %&gt;% names() ## [1] &quot;gaps_fbhs&quot; &quot;lad_profile&quot; &quot;gaps_perc&quot; &quot;metrics_distance&quot; ## [5] &quot;metrics_depth&quot; &quot;real_fbh&quot; &quot;real_depth&quot; &quot;eff_gap&quot; ## [9] &quot;layers_lad_df&quot; &quot;cbh_metrics&quot; ladderfuelsr_cbh_ans$lad_profile %&gt;% dplyr::glimpse() ## Rows: 13 ## Columns: 3 ## $ treeID &lt;fct&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100 ## $ height &lt;dbl&gt; 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, … ## $ lad &lt;dbl&gt; 0.04794701, 0.05489677, 0.05870343, 0.03551554, 0.09216243, 0.1… Create our own plot of the gaps and fuel layers base height in the vertical tree profile ggplot() + geom_path(data = ladderfuelsr_cbh_ans$lad_profile, mapping = aes(x = lad, y = height)) + geom_point(data = ladderfuelsr_cbh_ans$lad_profile, mapping = aes(x = lad, y = height)) + # gaps data geom_hline( data = ladderfuelsr_cbh_ans$gaps_fbhs %&gt;% dplyr::select( tidyselect::starts_with(&quot;gap&quot;) &amp; !tidyselect::starts_with(&quot;gap_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything()) , aes(yintercept = value, color = &quot;gaps&quot;) , linetype = &quot;dotted&quot; , lwd = 1.2 ) + # fbh data geom_hline( data = ladderfuelsr_cbh_ans$gaps_fbhs %&gt;% dplyr::select( tidyselect::starts_with(&quot;cbh&quot;) &amp; !tidyselect::starts_with(&quot;cbh_&quot;) ) %&gt;% tidyr::pivot_longer(dplyr::everything()) , aes(yintercept = value, color = &quot;FBHs&quot;) , linetype = &quot;dotdash&quot; , lwd = 1.2 ) + scale_color_manual(values = c(&quot;green4&quot;, &quot;red&quot;), name = &quot;&quot;) + scale_y_continuous(breaks = scales::extended_breaks(10)) + theme_light() + theme(legend.position = &quot;top&quot;) note, the gap and cbh columns in ladderfuelsr_cbh_ans$gaps_fbhs contain the data needed for the plot ( but not the gap_ and cbh_ columns ;/ ). but what are these columns? cbh - Height of the fuel layer base height (m) gap - Height of gap between fuel layers (m) 3.2.1 Return CBH Metrics ladderfuelsr_cbh_ans$cbh_metrics %&gt;% dplyr::glimpse() ## Rows: 1 ## Columns: 29 ## $ treeID1 &lt;dbl&gt; 100 ## $ dptf1 &lt;dbl&gt; 1 ## $ effdist1 &lt;dbl&gt; 4 ## $ Hcbh1 &lt;dbl&gt; 5.5 ## $ Hdist1 &lt;dbl&gt; 4.5 ## $ Hdptf1 &lt;dbl&gt; 5.5 ## $ max1 &lt;dbl&gt; 13.5 ## $ Hcbh1_Hdptf1 &lt;dbl&gt; 26.0422 ## $ treeID &lt;fct&gt; 100 ## $ max_height &lt;dbl&gt; 13.5 ## $ nlayers &lt;int&gt; 1 ## $ maxlad_Hcbh &lt;dbl&gt; 5.5 ## $ maxlad_Hdist &lt;dbl&gt; 4.5 ## $ maxlad_Hdptf &lt;dbl&gt; 5.5 ## $ maxlad_dptf &lt;dbl&gt; 1 ## $ maxlad_effdist &lt;dbl&gt; 4 ## $ maxlad_lad &lt;dbl&gt; 26.0422 ## $ max_Hcbh &lt;dbl&gt; 5.5 ## $ max_Hdist &lt;dbl&gt; 4.5 ## $ max_Hdptf &lt;dbl&gt; 5.5 ## $ max_dptf &lt;dbl&gt; 1 ## $ max_effdist &lt;dbl&gt; 4 ## $ max_lad &lt;dbl&gt; 26.0422 ## $ last_Hcbh &lt;dbl&gt; 5.5 ## $ last_Hdist &lt;dbl&gt; 4.5 ## $ last_Hdptf &lt;dbl&gt; 5.5 ## $ last_dptf &lt;dbl&gt; 1 ## $ last_effdist &lt;dbl&gt; 4 ## $ last_lad &lt;dbl&gt; 26.0422 what are these? treeID: tree ID with strings and numeric values treeID1: tree ID with only numeric values dptf: Depth of fuel layers (m) after considering distances greater than the actual height bin step effdist: Effective distance between consecutive fuel layers (m) after considering distances greater than any number of steps Hcbh: Base height of each fuel separated by a distance greater than the certain number of steps Hdptf: Height of the depth of fuel layers (m) after considering distances greater than the actual step Hdist: Height of the distance (&gt; any number of steps) between consecutive fuel layers (m) Hcbh_Hdptf - Percentage of LAD values comprised in each effective fuel layer maxlad_Hcbh - Height of the CBH of the segmented tree based on the maximum LAD percentage maxlad1_Hcbh - Height of the CBH from the second fuel layer when the maximum LAD occurred in the first fuel layer but its depth &lt;= “hdepth1_height” max_Hcbh - Height of the CBH of the segmented tree based on the maximum distance found in its profile last_Hcbh - Height of the CBH of the segmented tree based on the last distance found in its profile maxlad_ - Values of distance and fuel depth and their corresponding heights at the maximum LAD percentage maxlad1_ - Values of distance and fuel depth and their corresponding heights for the second fuel layer when the maximum LAD occurred in the first fuel layer but its depth &lt;= “hdepth1_height” max_ - Values of distance and fuel depth and their corresponding heights at the maximum distance last_ - Values of distance and fuel depth and their corresponding heights at the last distance nlayers - Number of effective fuel layers max_height - Maximum height of the tree profile there are also some plotting functions # Generate plots for fuels LAD metrics plots_cbh_maxlad &lt;- LadderFuelsR::get_plots_cbh_LAD( LAD_profiles = ladderfuelsr_cbh_ans$lad_profile , cbh_metrics = ladderfuelsr_cbh_ans$cbh_metrics , min_height = 0.5 ) plots_cbh_maxdist &lt;- LadderFuelsR::get_plots_cbh_maxdist( LAD_profiles = ladderfuelsr_cbh_ans$lad_profile , cbh_metrics = ladderfuelsr_cbh_ans$cbh_metrics , min_height = 0.5 ) plots_cbh_lastdist &lt;- LadderFuelsR::get_plots_cbh_lastdist( LAD_profiles = ladderfuelsr_cbh_ans$lad_profile , cbh_metrics = ladderfuelsr_cbh_ans$cbh_metrics , min_height = 0.5 ) # patchwork them (plots_cbh_maxlad[[1]] + labs(title = &quot;get_plots_cbh_LAD&quot;)) + (plots_cbh_maxdist[[1]] + labs(title = &quot;get_plots_cbh_maxdist&quot;)) + (plots_cbh_lastdist[[1]] + labs(title = &quot;get_plots_cbh_lastdist&quot;)) + patchwork::plot_layout(ncol = 2) these plots represent the three criteria to define the CBH in a segmented tree: get_plots_cbh_LAD = the fuel layer containing the maximum LAD percentage (column named maxlad_Hcbh) get_plots_cbh_maxdist = the fuel layer located at the highest distance (column named max_Hcbh) get_plots_cbh_lastdist = the fuel layer separated by the last effective distance (column named last_Hcbh) 3.2.2 CBH on the point cloud can we make a view of the CBH on the point cloud? # make a matrix to represent the cbh x_temp &lt;- seq( min(nlas_one_tree@data$X) , max(nlas_one_tree@data$X) , length.out = 2 ) y_temp &lt;- seq( min(nlas_one_tree@data$Y) , max(nlas_one_tree@data$Y) , length.out = 2 ) xy_temp &lt;- expand.grid(x = x_temp, y = y_temp) z_temp &lt;- matrix( rep( ladderfuelsr_cbh_ans$cbh_metrics$last_Hcbh , nrow(xy_temp) ) , nrow = length(x_temp), ncol = length(y_temp) ) # plot it plot3D::scatter3D( x = nlas_one_tree@data$X , y = nlas_one_tree@data$Y , z = nlas_one_tree@data$Z , colvar = nlas_one_tree@data$Z , cex = 0.3, pch = 19 , colkey = T , phi = -6 , col = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) , main =&quot;CBH shown in black&quot; , surf = list( x = x_temp , y = y_temp , z = z_temp , facets = NA , border = &quot;black&quot; , lwd = 2 ) ) 3.3 Function to CBH a tree list first, an intermediate function to clip the point cloud to a polygon and run it through the ladderfuelsr_cbh() function we defined above call_ladderfuelsr_cbh &lt;- function( id , poly_df , nlas , my_min_vhp_n , my_voxel_grain_size_m , my_dist_btwn_bins_m , my_min_fuel_layer_ht_m , my_lad_pct_gap , my_lad_pct_base , my_num_jump_steps , my_min_lad_pct , my_frst_layer_min_ht_m ){ ################################## # filter sf ################################## one_tree_sf &lt;- poly_df %&gt;% dplyr::filter(treeID==id) ################################## # clip the point cloud ################################## nlas_one_tree &lt;- lidR::clip_roi(las = nlas, geometry = one_tree_sf) %&gt;% lidR::filter_poi(!Classification %in% c(2,9,18)) %&gt;% ## class 2 = ground; 9 = water; 18 = noise lidR::add_attribute(x = id, name = &quot;treeID&quot;) ################################## # check for points ################################## if(nrow(nlas_one_tree@data)&gt;10){ # quiet this function quiet_ladderfuelsr_cbh &lt;- purrr::quietly(ladderfuelsr_cbh) # CALL ladderfuelsr_cbh ladderfuelsr_cbh_ans &lt;- quiet_ladderfuelsr_cbh( las = nlas_one_tree , treeID = id , min_vhp_n = my_min_vhp_n , voxel_grain_size_m = my_voxel_grain_size_m , dist_btwn_bins_m = my_dist_btwn_bins_m , min_fuel_layer_ht_m = my_min_fuel_layer_ht_m , lad_pct_gap = my_lad_pct_gap , lad_pct_base = my_lad_pct_base , num_jump_steps = my_num_jump_steps , min_lad_pct = my_min_lad_pct , frst_layer_min_ht_m = my_frst_layer_min_ht_m ) # just get the result ladderfuelsr_cbh_ans &lt;- ladderfuelsr_cbh_ans$result }else{ ladderfuelsr_cbh_ans &lt;- NULL } # build return data if(is.null(ladderfuelsr_cbh_ans$cbh_metrics)){ # blank the cbh columns df &lt;- one_tree_sf %&gt;% dplyr::mutate( cbh_maxlad_height_m = as.numeric(NA) , cbh_max_height_m = as.numeric(NA) , cbh_last_height_m = as.numeric(NA) ) }else{ df &lt;- one_tree_sf %&gt;% dplyr::mutate( cbh_maxlad_height_m = ladderfuelsr_cbh_ans$cbh_metrics$maxlad_Hcbh[1] , cbh_max_height_m = ladderfuelsr_cbh_ans$cbh_metrics$max_Hcbh[1] , cbh_last_height_m = ladderfuelsr_cbh_ans$cbh_metrics$last_Hcbh[1] ) } return(df) } let’s define a function for performing the CBH estimation over multiple trees and combining all of the data trees_cbh &lt;- function( trees_poly , norm_las = NA , tree_sample_prop = 1 , which_cbh = &quot;lowest&quot; # maxlad_Hcbh = max_lad # max_Hcbh = highest # last_Hcbh = lowest , estimate_missing_cbh = FALSE ##### LadderFuelsR # minimum vhp records # https://github.com/olgaviedma/LadderFuelsR?tab=readme-ov-file#8depurating-tree-lad-profiles , min_vhp_n = 6 # leafR::lad.voxels , voxel_grain_size_m = 2 # LadderFuelsR::get_gaps_fbhs , dist_btwn_bins_m = 1 # step , min_fuel_layer_ht_m = 1.5 # min_height , lad_pct_gap = 25 # perc_gap , lad_pct_base = 25 # perc_base # LadderFuelsR::get_real_fbh , num_jump_steps = 1 # number_steps # LadderFuelsR::get_layers_lad , min_lad_pct = 10 # threshold # LadderFuelsR::get_cbh_metrics , frst_layer_min_ht_m = 2.5 # hdepth1_height ){ ################################## # check which cbh ################################## # clean it which_cbh &lt;- dplyr::coalesce(which_cbh, &quot;lowest&quot;) which_cbh &lt;- ifelse( stringr::str_remove_all(which_cbh,&quot;\\\\s&quot;) == &quot;&quot; , &quot;lowest&quot; , which_cbh ) which_cbh &lt;- tolower(which_cbh[1]) # check it cbh_l &lt;- c(&quot;max_lad&quot;, &quot;highest&quot;, &quot;lowest&quot;) if(!which_cbh %in% cbh_l){ stop(paste0( &quot;`which_cbh` must be one of:&quot; , &quot;\\n&quot; , paste(cbh_l, collapse = &quot;, &quot;) )) } ################################## # ensure that norm las data exists ################################## nlas_msg &lt;- paste0( &quot;`norm_las` must contain a directory with nomalized las files, the path of a .laz|.las file&quot; , &quot;\\n, -or- an object of class `LAS`. Please update the `norm_las` parameter.&quot; ) if(is.na(norm_las)){stop(nlas_msg)} if(inherits(norm_las, &quot;character&quot;)){ if(!stringr::str_ends(norm_las, &quot;.*\\\\.(laz|las)$&quot;)){ # try to read directory for las files fls &lt;- list.files(normalizePath(norm_las), pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = TRUE) # stop it if no files if(length(fls)&lt;1){stop(nlas_msg)} # read it nlas_ctg &lt;- lidR::readLAScatalog(fls) # turn of lidR progress lidR::opt_progress(nlas_ctg) &lt;- F }else if(stringr::str_ends(norm_las, &quot;.*\\\\.(laz|las)$&quot;)){ # read it nlas_ctg &lt;- lidR::readLAScatalog(norm_las) # turn of lidR progress lidR::opt_progress(nlas_ctg) &lt;- F }else{ stop(nlas_msg) } }else if(inherits(norm_las, &quot;LAS&quot;)){ nlas_ctg &lt;- norm_las }else{ stop(nlas_msg) } ################################## # ensure that treeID data exists ################################## f &lt;- trees_poly %&gt;% names() if(length(f)==0){f &lt;- &quot;&quot;} if( max(grepl(&quot;treeID&quot;, f))==0 ){ stop(paste0( &quot;`trees_poly` data must contain `treeID` column to estimate missing CBH values.&quot; , &quot;\\nProvide the `treeID` as a unique identifier of individual trees.&quot; )) }else{ # check for duplicate treeID if( nrow(trees_poly) != length(unique(trees_poly$treeID)) ){ stop(&quot;Duplicates found in the treeID column. Please remove duplicates and try again.&quot;) } # ensure that treeID is numeric # generate a treeID index because it needs to be numeric for LadderFuelsR trees_poly &lt;- trees_poly %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate( treeID_backup = treeID , treeID = dplyr::row_number() ) %&gt;% dplyr::relocate(treeID) } ################################## # ensure spatial polygon data ################################## sf_msg &lt;- paste0( &quot;`trees_poly` data must be an object of class `sf` with only POLYGON type.&quot; , &quot;\\nProvide an `sf` object and see `sf::st_geometry_type()`.&quot; ) if(!inherits(trees_poly, &quot;sf&quot;)){stop(sf_msg)} if( min(sf::st_is(trees_poly, type = c(&quot;POLYGON&quot;, &quot;MULTIPOLYGON&quot;))) == 0 ){stop(sf_msg)} ################################## # ensure the las and sf are same projection ################################## # get crs crs_las &lt;- sf::st_crs(nlas_ctg) crs_poly &lt;- sf::st_crs(trees_poly) # test equal epsg if( is.na(crs_las$epsg) | is.na(crs_poly$epsg) | crs_las$epsg != crs_poly$epsg ){ stop(&quot;The `trees_poly` and `norm_las` data have differing CRS projections. Please see `sf::st_crs()` and ensure compatibility.&quot;) } #################################################################### # map over ladderfuelsr_cbh function #################################################################### cbh_df &lt;- trees_poly %&gt;% dplyr::slice_sample(prop = min(as.numeric(tree_sample_prop), 1, na.rm = T)) %&gt;% dplyr::pull(treeID) %&gt;% purrr::map(\\(x) call_ladderfuelsr_cbh( id = x , poly_df = trees_poly , nlas = nlas_ctg , my_min_vhp_n = min_vhp_n , my_voxel_grain_size_m = voxel_grain_size_m , my_dist_btwn_bins_m = dist_btwn_bins_m , my_min_fuel_layer_ht_m = min_fuel_layer_ht_m , my_lad_pct_gap = lad_pct_gap , my_lad_pct_base = lad_pct_base , my_num_jump_steps = num_jump_steps , my_min_lad_pct = min_lad_pct , my_frst_layer_min_ht_m = frst_layer_min_ht_m )) %&gt;% dplyr::bind_rows() %&gt;% # get rid of treeID dplyr::mutate( treeID = treeID_backup ) %&gt;% dplyr::select(-treeID_backup) %&gt;% dplyr::relocate(treeID) %&gt;% sf::st_drop_geometry() # pick a cbh if(which_cbh == &quot;max_lad&quot;){ cbh_df &lt;- cbh_df %&gt;% dplyr::mutate( tree_cbh_m = cbh_maxlad_height_m , is_training_cbh = !is.na(cbh_maxlad_height_m) ) }else if(which_cbh == &quot;highest&quot;){ cbh_df &lt;- cbh_df %&gt;% dplyr::mutate( tree_cbh_m = cbh_max_height_m , is_training_cbh = !is.na(cbh_max_height_m) ) }else{ cbh_df &lt;- cbh_df %&gt;% dplyr::mutate( tree_cbh_m = cbh_last_height_m , is_training_cbh = !is.na(cbh_last_height_m) ) } # get rid of treeID trees_poly &lt;- trees_poly %&gt;% dplyr::mutate(treeID = treeID_backup) %&gt;% dplyr::select(-treeID_backup) %&gt;% dplyr::relocate(treeID) # ensure that there are enough data to estimate n_cbh &lt;- cbh_df %&gt;% dplyr::filter(is_training_cbh==T) %&gt;% nrow() # ensure that tree height data exists f &lt;- trees_poly %&gt;% names() if(length(f)==0){f &lt;- &quot;&quot;} ############################################# # check for estimate missing ############################################# if( estimate_missing_cbh==T &amp; n_cbh &gt; 10 &amp; max(grepl(&quot;tree_height_m&quot;, f))==1 ){ # add x,y to data mod_df &lt;- trees_poly %&gt;% dplyr::left_join( cbh_df %&gt;% dplyr::select(treeID, tree_cbh_m, is_training_cbh) , by = &quot;treeID&quot; ) %&gt;% dplyr::mutate(is_training_cbh = dplyr::coalesce(is_training_cbh, F)) %&gt;% dplyr::select(treeID, tree_height_m, tree_cbh_m, is_training_cbh) %&gt;% sf::st_centroid() %&gt;% dplyr::mutate( tree_xxx = sf::st_coordinates(.)[,1] , tree_yyy = sf::st_coordinates(.)[,2] , crown_area_zzz = sf::st_area(.) , tree_height_m = as.numeric(tree_height_m) , tree_cbh_m = as.numeric(tree_cbh_m) ) %&gt;% sf::st_drop_geometry() # training versus predict data training_df &lt;- mod_df %&gt;% dplyr::filter(is_training_cbh==T) %&gt;% dplyr::select(-is_training_cbh) predict_df &lt;- mod_df %&gt;% dplyr::filter(is_training_cbh==F) %&gt;% dplyr::select(-is_training_cbh) ### tuning RF model # If we are interested with just starting out and tuning the mtry parameter # we can use randomForest::tuneRF for a quick and easy tuning assessment. # tuneRf will start at a value of mtry that you supply and increase by a # certain step factor until the OOB error stops improving be a specified amount. # quiet this quiet_tuneRF &lt;- purrr::quietly(randomForest::tuneRF) # run it rf_tune_temp &lt;- quiet_tuneRF( # randomForest::tuneRF( y = training_df$tree_cbh_m , x = training_df %&gt;% dplyr::select(-c(treeID,tree_cbh_m)) , stepFactor = 0.5 , ntreeTry = 200 , mtryStart = 0.5 , improve = 0.01 , plot = F , trace = F ) # just get the result rf_tune_temp &lt;- rf_tune_temp$result # Extract the optimal mtry value optimal_mtry &lt;- rf_tune_temp %&gt;% dplyr::as_tibble() %&gt;% dplyr::filter(OOBError==min(OOBError)) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::pull(mtry) # ensure that the mtry value is not greater than the number of predictors optimal_mtry &lt;- min( optimal_mtry , ncol( training_df %&gt;% dplyr::select(-c(treeID,tree_cbh_m)) ) ) ### Run a randomForest model to predict DBH using various crown predictors cbh_mod &lt;- randomForest::randomForest( y = training_df$tree_cbh_m , x = training_df %&gt;% dplyr::select(-c(treeID,tree_cbh_m)) , mtry = optimal_mtry , na.action = na.omit ) # # model # cbh_mod &lt;- stats::lm( # formula = tree_cbh_m ~ tree_xxx + tree_yyy + tree_xxx:tree_yyy + tree_height_m + crown_area_zzz # , data = training_df # ) # predict missing predicted_cbh_temp &lt;- predict( cbh_mod , predict_df %&gt;% dplyr::select(-c(treeID,tree_cbh_m)) ) %&gt;% dplyr::as_tibble() %&gt;% dplyr::pull(1) ## combine predicted data with training data for full data set trees_poly &lt;- trees_poly %&gt;% # join with training data estimates dplyr::left_join( cbh_df %&gt;% dplyr::filter(is_training_cbh==T) %&gt;% dplyr::select(treeID, tree_cbh_m, is_training_cbh) , by = &quot;treeID&quot; ) %&gt;% dplyr::mutate(is_training_cbh = dplyr::coalesce(is_training_cbh, F)) %&gt;% # join with predicted data estimates dplyr::left_join( predict_df %&gt;% dplyr::mutate( predicted_cbh = predicted_cbh_temp ) %&gt;% dplyr::select(treeID, predicted_cbh) , by = dplyr::join_by(&quot;treeID&quot;) ) %&gt;% # clean up data dplyr::mutate( tree_cbh_m = dplyr::coalesce(tree_cbh_m, predicted_cbh) ) %&gt;% dplyr::select(-predicted_cbh) ## prevent the CBH from being &gt; the tree height # find the 95th percentile of height-cbh ratio max_ratio &lt;- cbh_df %&gt;% dplyr::filter( is_training_cbh==T &amp; tree_cbh_m &lt; tree_height_m ) %&gt;% dplyr::mutate(ratio = tree_cbh_m/tree_height_m) %&gt;% dplyr::pull(ratio) %&gt;% stats::quantile(probs = 0.95) # update values trees_poly &lt;- trees_poly %&gt;% dplyr::mutate( # update training data where tree_cbh_m &gt; tree_height_m is_training_cbh = dplyr::case_when( is_training_cbh==T &amp; tree_cbh_m &gt;= tree_height_m ~ FALSE , T ~ is_training_cbh ) # update tree_cbh_m , tree_cbh_m = dplyr::case_when( is_training_cbh==F &amp; tree_cbh_m/tree_height_m &gt; max_ratio ~ max_ratio*tree_height_m , T ~ tree_cbh_m ) ) }else if(estimate_missing_cbh==T){ if(max(grepl(&quot;tree_height_m&quot;, f))==0){ message(paste0( &quot;`trees_poly` data must contain `tree_height_m` column to estimate CBH.&quot; , &quot;\\nSetting `estimate_missing_cbh=TRUE` requires this data.&quot; , &quot;\\nReturning CBH values extracted from cloud only.&quot; )) }else{ message(paste0( &quot;Insufficient data available to estimate missing CBH values.&quot; , &quot;\\nReturning CBH values extracted from cloud only.&quot; )) } ## combine predicted data with training data for full data set trees_poly &lt;- trees_poly %&gt;% # join with training data estimates dplyr::left_join( cbh_df %&gt;% dplyr::filter(is_training_cbh==T) %&gt;% dplyr::select(treeID, tree_cbh_m, is_training_cbh) , by = &quot;treeID&quot; ) %&gt;% dplyr::mutate(is_training_cbh = dplyr::coalesce(is_training_cbh, F)) }else{ ## combine predicted data with training data for full data set trees_poly &lt;- trees_poly %&gt;% # join with training data estimates dplyr::left_join( cbh_df %&gt;% dplyr::filter(is_training_cbh==T) %&gt;% dplyr::select(treeID, tree_cbh_m, is_training_cbh) , by = &quot;treeID&quot; ) %&gt;% dplyr::mutate(is_training_cbh = dplyr::coalesce(is_training_cbh, F)) } # return return(trees_poly) # return(list( # trees_poly = trees_poly # , cbh_mod = cbh_mod # )) } 3.4 Test CBH process - lidar Test it and set the parameters based on recommendations from the literature (alternatively, we could keep the default parameter settings) With respect to the the voxel_grain_size_m parameter (see grain.size in leafR::lad.voxels()): In general, the LAD and LAI estimates tended to stabilize with an increasing grain size and increasing ALS pulse density. At small grain sizes of 1 m, 2 m, and 5 m, absolute LAD profiles became stable at respective pulse densities of 15, 15, and 10 pulses per m2…the lower accuracy particularly of the LAD profile estimation at a coarse grain size or at low pulse densities may be unacceptable for some applications, particularly in models and methods that rely on the fine scale vertical and horizontal heterogeneity of the canopy structure to make ecological inferences. Examples include the estimation of timber stock or demographic structure or light interception and absorption…For these applications our results suggest that pulse densities of 20 pulses per m2 or greater and grain sizes between 2 and 5 m, which maximize accuracy and stability, should be utilized. (de Almeida et al., 2019, p. 9-10) …however the documentation of leafR::lad.voxels() recommends “1 meter for lad profiles” Regarding the min_fuel_layer_ht_m parameter (see min_height in LadderFuelsR::get_gaps_fbhs()): The LAD strata estimated from both ALS and ground lidar were limited to pulse returns above one meter from the ground. This avoids ground-return interference in the ALS data and is also imposed by the ground lidar sensor height. (de Almeida et al., 2019, p. 6) Finally, for the frst_layer_min_ht_m parameter (see hdepth1_height in LadderFuelsR::get_cbh_metrics()): In the case of maximum LAD (%), the output also gives the CBH from the second fuel layer when the first one has the maximum LAD (%) but its depth is smaller than the value indicated in the parameter “hdepth1_height” (default 2 m). (Viedma et al. 2024, p. 8) and from the package: If the first fuel layer has the maximum LAD and its depth is greater than the indicated value, then this fuel layer is considered as the CBH of the tree. On the contrary, if its depth is &lt;= the value, the CBH with maximum LAD will be the second fuel layer, although it has not the maximum LAD. We’ll leave all of the other values at their default trees_cbh_ans &lt;- cloud2trees::trees_cbh( trees_poly = cloud2trees_ans$crowns_sf , norm_las = norm_las_dir # pull this from create_project_structure.R , tree_sample_prop = .5 , estimate_missing_cbh = T , which_cbh = &quot;lowest&quot; , min_vhp_n = 4 # = 2.5m with min_fuel_layer_ht_m=1 and dist_btwn_bins_m = 0.5 , min_fuel_layer_ht_m = 1 # default = 1.5 , dist_btwn_bins_m = 0.5 # default = 1 , num_jump_steps = 0.5 # default = 1 , frst_layer_min_ht_m = 0.5 # default = 2.5 ) what? trees_cbh_ans %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 22 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ tree_x &lt;dbl&gt; 453532.6, 453544.6, 453542.6, 453547.4, 4535… ## $ tree_y &lt;dbl&gt; 4458595, 4458595, 4458594, 4458593, 4458592,… ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ geometry &lt;GEOMETRY [m]&gt; POLYGON ((453532.5 4458595,..., POL… ## $ fia_est_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_lower &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_upper &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_data &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_ft2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; 2.036268, 2.500000, 4.500000, 2.740810, 4.03… ## $ is_training_cbh &lt;lgl&gt; FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, FALSE… let’s view the height versus CBH relationship by training data trees_cbh_ans %&gt;% ggplot(aes(x = tree_height_m, y = tree_cbh_m, color = is_training_cbh)) + geom_point(size = 3, alpha = 0.8) + harrypotter::scale_color_hp_d(&quot;ronweasley&quot;, direction = -1) + scale_y_continuous(breaks = scales::breaks_extended(12)) + scale_x_continuous(breaks = scales::breaks_extended(12)) + labs(y = &quot;CBH (m)&quot;, x = &quot;Height (m)&quot;, color = &quot;is training data&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) check out the CBH spatially trees_cbh_ans %&gt;% ggplot(aes(color = is_training_cbh, fill = tree_cbh_m)) + geom_sf(lwd = 0.8) + harrypotter::scale_color_hp_d(&quot;ronweasley&quot;, direction = -1) + harrypotter::scale_fill_hp(&quot;always&quot;) + labs(fill = &quot;CBH (m)&quot;, color = &quot;is training data&quot;) + theme_light() + theme(legend.position = &quot;top&quot;, axis.text = element_blank()) + guides( color = guide_legend(order = 1, override.aes = list(lwd = 3, fill = NA)) ) 3.4.1 Comparison to LadderFuelsR defaults We just calculated the estimates of CBH using custom parameter values for the LadderFuelsR process. Let’s compare these custom values to values obtained if we just use the defaults from the LadderFuelsR package. # compare to default values from LadderFuelsR trees_cbh_ans2 &lt;- cloud2trees::trees_cbh( trees_poly = cloud2trees_ans$crowns_sf , norm_las = norm_las_dir , tree_sample_prop = .5 , estimate_missing_cbh = T , which_cbh = &quot;lowest&quot; # we can leave all other parameters at defaults ) # join to initial data trees_cbh_ans &lt;- trees_cbh_ans %&gt;% dplyr::left_join( trees_cbh_ans2 %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( treeID,is_training_cbh,tree_cbh_m ) %&gt;% dplyr::rename( def_is_training_cbh = is_training_cbh , def_tree_cbh_m = tree_cbh_m ) , by = &quot;treeID&quot; ) %&gt;% dplyr::mutate( pct_diff_cbh = (tree_cbh_m-def_tree_cbh_m)/def_tree_cbh_m ) what does the distribution of the percent difference look like (negative values = custom CBH &lt; default CBH and vice versa)? trees_cbh_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(tidyselect::ends_with(&quot;_cbh_m&quot;), pct_diff_cbh) %&gt;% summary() ## tree_cbh_m def_tree_cbh_m pct_diff_cbh ## Min. :1.500 Min. :1.975 Min. :-0.528903 ## 1st Qu.:3.359 1st Qu.:3.158 1st Qu.:-0.090155 ## Median :3.500 Median :3.298 Median : 0.003917 ## Mean :3.589 Mean :3.341 Mean : 0.091898 ## 3rd Qu.:3.782 3rd Qu.:3.564 3rd Qu.: 0.150446 ## Max. :9.500 Max. :5.500 Max. : 2.800000 so maybe the CBH estimates are sensitive to the parameterization of the LadderFuelsR process… trees_cbh_ans %&gt;% dplyr::mutate( cbh_bin = ggplot2::cut_width(pct_diff_cbh, width = 0.1, center = 0.05) , is_ltz = pct_diff_cbh&lt;=0 ) %&gt;% dplyr::count(cbh_bin, is_ltz) %&gt;% ggplot(aes( x = cbh_bin, y = n, fill = is_ltz )) + geom_col(width = 0.7) + harrypotter::scale_fill_hp_d(&quot;slytherin&quot;, begin = 0.2, end = 0.8) + labs(y = &quot;# Trees&quot;, x = &quot;CBH % diff&quot;, fill = &quot;custom CBH &lt; default&quot;) + theme_light() + theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1)) look at how the CBH estimates changed trees_cbh_ans %&gt;% dplyr::mutate( is_ltz = pct_diff_cbh&lt;=0 ) %&gt;% ggplot(aes( x = def_tree_cbh_m, y = tree_cbh_m, color = is_ltz )) + ggplot2::geom_abline() + geom_point(size = 2, alpha = 0.8) + harrypotter::scale_color_hp_d(&quot;slytherin&quot;, begin = 0.2, end = 0.8) + scale_y_continuous(limits = c(0,NA), breaks = scales::breaks_extended(12)) + scale_x_continuous(limits = c(0,NA), breaks = scales::breaks_extended(12)) + labs(y = &quot;custom CBH (m)&quot;, x = &quot;default CBH (m)&quot;, color = &quot;custom CBH &lt; default&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) one more way to look at how the CBH estimates changed dta_temp &lt;- trees_cbh_ans %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate( is_ltz = pct_diff_cbh&lt;=0 ) %&gt;% dplyr::select(treeID, is_ltz, tidyselect::ends_with(&quot;_cbh_m&quot;)) %&gt;% tidyr::pivot_longer( cols = tidyselect::ends_with(&quot;_cbh_m&quot;) , names_to = &quot;cbh_type&quot; , values_to = &quot;cbh&quot; , values_drop_na = F ) %&gt;% dplyr::mutate( cbh_type = dplyr::case_when( cbh_type == &quot;def_tree_cbh_m&quot; ~ &quot;default CBH&quot; , T ~ &quot;custom CBH&quot; ) %&gt;% factor() %&gt;% forcats::fct_rev() ) # plot ggplot( data = dta_temp , mapping = aes(x = cbh_type, y = cbh, color = is_ltz, group = treeID) ) + ggplot2::geom_line(data = dta_temp %&gt;% dplyr::filter(is_ltz == F), lwd = 1) + # ggplot2::geom_point(data = dta_temp %&gt;% dplyr::filter(is_ltz == F)) + ggplot2::geom_line(data = dta_temp %&gt;% dplyr::filter(is_ltz == T), lwd = 1.1, alpha = 0.8) + # ggplot2::geom_point(data = dta_temp %&gt;% dplyr::filter(is_ltz == T), alpha = 0.6) + harrypotter::scale_color_hp_d(&quot;slytherin&quot;, begin = 0.2, end = 0.8) + scale_y_continuous(limits = c(0,NA), breaks = scales::breaks_extended(12)) + labs(y = &quot;CBH (m)&quot;, x = &quot;&quot;, color = &quot;custom CBH &lt; default&quot;) + theme_light() + theme(legend.position = &quot;none&quot;) In selecting parameter levels, Let’s err on the side of a lower CBH for fuel modelling: 1) to be conservative with how “high” we say the CBH is; 2) since it looks like the minimum CBH extracted from lidar data via the LadderFuelsR process is ~1.5 m; 3) and since lower density lidar gets very few returns closer to the ground level due to canopy occlusion. for completeness, let’s view the height versus CBH relationship by training data using the default parameter values trees_cbh_ans %&gt;% ggplot(aes(x = tree_height_m, y = def_tree_cbh_m, color = def_is_training_cbh)) + geom_point(size = 3, alpha = 0.8) + harrypotter::scale_color_hp_d(&quot;ronweasley&quot;, direction = -1) + scale_y_continuous(breaks = scales::breaks_extended(12)) + scale_x_continuous(breaks = scales::breaks_extended(12)) + labs(y = &quot;CBH (m)&quot;, x = &quot;Height (m)&quot;, color = &quot;is training data&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) 3.4.2 test CBH based on parameterization of LadderFuelsR let’s build a test for different levels of the min_fuel_layer_ht_m and dist_btwn_bins_m parameters we’ll increase the sample proportion of data to attempt to extract a CBH from the point cloud for this exercise (tree_sample_prop = 0.5 in trees_cbh()) for this exercise. we’ll also hold the minimum number of vertical height profile records constant (min_vhp_n = 2 in trees_cbh()). we’ll also put in a timer to see how long this generally takes. # build a data frame of potential values dta_temp &lt;- tidyr::crossing( min_fuel_layer_ht_m = seq(0, 2.5, by = 0.5) # default = 1.5 , dist_btwn_bins_m = seq(0.5, 2.5, by = 0.5) # default = 1 ) # # something in LadderFuelsR is making the program crash if: # # 1) dist_btwn_bins_m - min_fuel_layer_ht_m &gt;= 1.5 # # 2) min_fuel_layer_ht_m = 1 &amp; dist_btwn_bins_m = 1 # # 2) min_fuel_layer_ht_m = 1 &amp; dist_btwn_bins_m = 2 # # 2) min_fuel_layer_ht_m = 1.5 &amp; dist_btwn_bins_m = 2 # dplyr::filter( # dist_btwn_bins_m - min_fuel_layer_ht_m &lt; 1.5 # &amp; (min_fuel_layer_ht_m != 1 &amp; dist_btwn_bins_m != 1) # &amp; (min_fuel_layer_ht_m != 1 &amp; dist_btwn_bins_m != 2) # ) # tester function test_cbh_fn &lt;- function(i, my_min_vhp_n = 4, my_tree_sample_prop = 1) { # parameters my_min_fuel_layer_ht_m &lt;- dta_temp %&gt;% dplyr::filter(dplyr::row_number()==i) %&gt;% dplyr::pull(min_fuel_layer_ht_m) my_dist_btwn_bins_m &lt;- dta_temp %&gt;% dplyr::filter(dplyr::row_number()==i) %&gt;% dplyr::pull(dist_btwn_bins_m) # run it safe_trees_cbh &lt;- purrr::safely(cloud2trees::trees_cbh) st &lt;- Sys.time() trees_cbh_ans &lt;- safe_trees_cbh( trees_poly = cloud2trees_ans$crowns_sf , norm_las = norm_las_dir , tree_sample_prop = my_tree_sample_prop , estimate_missing_cbh = T , min_vhp_n = my_min_vhp_n , which_cbh = &quot;lowest&quot; # we can leave all other parameters at defaults , min_fuel_layer_ht_m = my_min_fuel_layer_ht_m # default = 1.5 , dist_btwn_bins_m = my_dist_btwn_bins_m # default = 1 ) end &lt;- Sys.time() if(!is.null(trees_cbh_ans$result)){ message(paste( &quot;my_min_fuel_layer_ht_m=&quot; , my_min_fuel_layer_ht_m , &quot;; my_dist_btwn_bins_m=&quot; , my_dist_btwn_bins_m )) # return return( trees_cbh_ans$result %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(treeID, tree_height_m, tidyselect::contains(&quot;cbh&quot;)) %&gt;% dplyr::mutate( min_fuel_layer_ht_m = my_min_fuel_layer_ht_m , dist_btwn_bins_m = my_dist_btwn_bins_m , timer_secs = difftime(end, st, units = &quot;secs&quot;) %&gt;% as.numeric() ) ) }else{ message(paste( &quot;ERROR: my_min_fuel_layer_ht_m=&quot; , my_min_fuel_layer_ht_m , &quot;; my_dist_btwn_bins_m=&quot; , my_dist_btwn_bins_m # , &quot;\\n&quot; # , trees_cbh_ans$error # , &quot;\\n&quot; )) message() return(NULL) } } # run it test_cbh_dta &lt;- 1:nrow(dta_temp) %&gt;% purrr::map(\\(x) test_cbh_fn(x, my_min_vhp_n = 4, my_tree_sample_prop = 0.5)) %&gt;% dplyr::bind_rows() which combinations caused errors? Update: in the cloud2trees package I have included error handling so that the function does not return the errors that happen in the LadderfulesR package. Additionally, if no trees return CBH based on the parameters passed to the LadderfulesR package, I attempt update the parameters to settings that have previously been successful for most data sets to get a successful result in the trees_cbh() call. # which combinations caused errors? dta_temp %&gt;% dplyr::anti_join( test_cbh_dta , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% kableExtra::kbl(caption = &quot;lidar: these combintations resulted in ERROR!&quot;) %&gt;% kableExtra::kable_styling() Table 3.1: lidar: these combintations resulted in ERROR! min_fuel_layer_ht_m dist_btwn_bins_m which combinations resulted in success? # which combinations caused success? dta_temp %&gt;% dplyr::inner_join( test_cbh_dta %&gt;% dplyr::distinct(min_fuel_layer_ht_m, dist_btwn_bins_m) , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% kableExtra::kbl(caption = &quot;lidar: these combintations resulted in SUCCESS!&quot;) %&gt;% kableExtra::kable_styling() Table 3.2: lidar: these combintations resulted in SUCCESS! min_fuel_layer_ht_m dist_btwn_bins_m 0.0 0.5 0.0 1.0 0.0 1.5 0.0 2.0 0.0 2.5 0.5 0.5 0.5 1.0 0.5 1.5 0.5 2.0 0.5 2.5 1.0 0.5 1.0 1.0 1.0 1.5 1.0 2.0 1.0 2.5 1.5 0.5 1.5 1.0 1.5 1.5 1.5 2.0 1.5 2.5 2.0 0.5 2.0 1.0 2.0 1.5 2.0 2.0 2.0 2.5 2.5 0.5 2.5 1.0 2.5 1.5 2.5 2.0 2.5 2.5 is there a pattern?? ERROR if : min_fuel_layer_ht_m == dist_btwn_bins_m (except 0.5,1.5,2.5)?? ERROR if : dist_btwn_bins_m - min_fuel_layer_ht_m &gt;= 1.5 perhaps the pattern is driven by the interaction with another parameter that we did’t adjust anyway….. what does the success data look like? test_cbh_dta %&gt;% dplyr::glimpse() ## Rows: 3,210 ## Columns: 7 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.6&quot;, &quot;3… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, 6.352,… ## $ tree_cbh_m &lt;dbl&gt; 1.317595, 2.324658, 3.000000, 1.773479, 2.045024, … ## $ is_training_cbh &lt;lgl&gt; FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, FALS… ## $ min_fuel_layer_ht_m &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ dist_btwn_bins_m &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, … ## $ timer_secs &lt;dbl&gt; 16.6013, 16.6013, 16.6013, 16.6013, 16.6013, 16.60… sick, how about by data set? test_cbh_dta %&gt;% dplyr::count(min_fuel_layer_ht_m, dist_btwn_bins_m) %&gt;% kableExtra::kbl(caption = &quot;look at our test data combintation successes&quot;) %&gt;% kableExtra::kable_styling() Table 3.3: look at our test data combintation successes min_fuel_layer_ht_m dist_btwn_bins_m n 0.0 0.5 107 0.0 1.0 107 0.0 1.5 107 0.0 2.0 107 0.0 2.5 107 0.5 0.5 107 0.5 1.0 107 0.5 1.5 107 0.5 2.0 107 0.5 2.5 107 1.0 0.5 107 1.0 1.0 107 1.0 1.5 107 1.0 2.0 107 1.0 2.5 107 1.5 0.5 107 1.5 1.0 107 1.5 1.5 107 1.5 2.0 107 1.5 2.5 107 2.0 0.5 107 2.0 1.0 107 2.0 1.5 107 2.0 2.0 107 2.0 2.5 107 2.5 0.5 107 2.5 1.0 107 2.5 1.5 107 2.5 2.0 107 2.5 2.5 107 let’s check those CBH values test_cbh_dta %&gt;% dplyr::mutate( is_default = min_fuel_layer_ht_m == 1.5 &amp; dist_btwn_bins_m == 1 , minHT_step = forcats::fct_cross( factor(min_fuel_layer_ht_m), factor(dist_btwn_bins_m) , keep_empty = F ) %&gt;% forcats::fct_reorder( .x = tree_cbh_m , .fun = median ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot(aes(y = minHT_step, x = tree_cbh_m, fill = is_default)) + geom_boxplot(width = 0.7, outliers = F) + harrypotter::scale_fill_hp_d(&quot;dracomalfoy&quot;, begin = 0.8, end = 0.2) + scale_x_continuous(breaks = scales::breaks_extended(12)) + labs(y = &quot;min_fuel_layer_ht_m : dist_btwn_bins_m&quot;, x = &quot;CBH (m)&quot;, fill = &quot;is the default&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) very interesting. it seems that the default settings result in variable CBH estimates that are generally lower than other parameter settings tested. Setting min_fuel_layer_ht_m = 1 and dist_btwn_bins_m = 0.5 results in CBH estimates that are lower (what we are aiming for) than the default settings and similarly variable to the default setting. Increasing the min_fuel_layer_ht_m to values &gt;= 2 does indeed result in increase CBH estimates that are also more consistent (potentially a desirable result) which may be due to the limited number of taller trees in this particular test data. let’s proceed by using these settings: min_fuel_layer_ht_m = 1 and dist_btwn_bins_m = 0.5 we need to perform a study measuring the accuracy of the CBH estimated from the point cloud versus field validation data to properly determine what parameter settings to use in the LadderFuelsR process let’s check out the timer on a per tree basis secs_per_tree &lt;- test_cbh_dta %&gt;% dplyr::count(min_fuel_layer_ht_m, dist_btwn_bins_m, timer_secs) %&gt;% dplyr::mutate( secs_per_tree = timer_secs/n ) %&gt;% dplyr::pull(secs_per_tree) secs_per_tree %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1257 0.1489 0.1553 0.1545 0.1597 0.1690 that’s not too shabby but let’s remember that this is a lower density point cloud. the estimate is that for every 1,000 trees the CBH extraction from the point cloud would take 2.6 minutes. how does that sound? this is also based on the point density of this test data: lidR::readLAScatalog(norm_las_dir) ## class : LAScatalog (v1.3 format 1) ## extent : 453532.6, 453572.6, 4458556, 4458596 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1599.8 m² ## points : 20.4 thousand points ## density : 12.7 points/m² ## density : 7.9 pulses/m² ## num. files : 1 3.5 Test CBH process - UAS In the analysis above we tested extracting CBH from lidar point cloud data. Let’s test the process for UAS data 3.5.1 cloud2trees that UAS data extract trees from the UAS data using cloud2trees to create some example tree-level point cloud data to test the LadderFuelsR process if(F){ cloud2trees_ans &lt;- cloud2trees::cloud2trees( input_las_dir = &quot;../data/uas&quot; , output_dir = &quot;../data/uas&quot; , estimate_tree_dbh = F , keep_intrmdt = T ) norm_las_dir &lt;- &quot;../data/uas/point_cloud_processing_temp/02_normalize/&quot; }else{ cloud2trees_ans &lt;- list( crowns_sf = sf::st_read(&quot;../data/uas/point_cloud_processing_delivery/final_detected_crowns.gpkg&quot;, quiet=T) , treetops_sf = sf::st_read(&quot;../data/uas/point_cloud_processing_delivery/final_detected_tree_tops.gpkg&quot;, quiet=T) ) norm_las_dir &lt;- &quot;../data/uas/point_cloud_processing_temp/02_normalize/&quot; } look at that point density lidR::readLAScatalog( list.files(&quot;../data/uas&quot;, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = TRUE)[1] ) ## class : LAScatalog (v1.2 format 3) ## extent : 490067.8, 490329.8, 4330744, 4330951 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 54091.95 m² ## points : 14.31 million points ## density : 264.6 points/m² ## num. files : 1 how many trees did we get? cloud2trees_ans$crowns_sf %&gt;% nrow() ## [1] 1626 we’ll reduce our sample to estimate cbh from 3.5.2 Extract CBH example here, we’ll use the parameter settings in the LadderFuelsR process that we found worked the best for lidar point cloud data and we’ll decrease the trees_cbh_ans &lt;- cloud2trees::trees_cbh( trees_poly = cloud2trees_ans$crowns_sf , norm_las = norm_las_dir # pull this from create_project_structure.R , tree_sample_prop = .1 , estimate_missing_cbh = T , which_cbh = &quot;lowest&quot; , min_vhp_n = 4 # = 2.5m with min_fuel_layer_ht_m=1 and dist_btwn_bins_m = 0.5 , min_fuel_layer_ht_m = 1 # default = 1.5 , dist_btwn_bins_m = 0.5 # default = 1 ) what? trees_cbh_ans %&gt;% dplyr::glimpse() ## Rows: 1,626 ## Columns: 22 ## $ treeID &lt;chr&gt; &quot;1_490176.4_4330945.1&quot;, &quot;2_490177.6_4330944.… ## $ tree_height_m &lt;dbl&gt; 6.780, 3.685, 4.972, 18.424, 7.200, 3.069, 1… ## $ tree_x &lt;dbl&gt; 490176.4, 490177.6, 490235.9, 490117.1, 4901… ## $ tree_y &lt;dbl&gt; 4330945, 4330944, 4330944, 4330943, 4330943,… ## $ crown_area_m2 &lt;dbl&gt; 3.0000, 0.8750, 1.1250, 16.3125, 0.7500, 0.9… ## $ fia_est_dbh_cm &lt;dbl&gt; 11.316934, 6.064179, 8.071623, 42.559879, 12… ## $ fia_est_dbh_cm_lower &lt;dbl&gt; 6.514868, 3.477446, 4.650148, 24.469235, 6.9… ## $ fia_est_dbh_cm_upper &lt;dbl&gt; 17.299223, 9.144170, 12.312182, 65.605321, 1… ## $ dbh_cm &lt;dbl&gt; 11.316934, 6.064179, 8.071623, 42.559879, 12… ## $ is_training_data &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… ## $ dbh_m &lt;dbl&gt; 0.11316934, 0.06064179, 0.08071623, 0.425598… ## $ radius_m &lt;dbl&gt; 0.05658467, 0.03032089, 0.04035812, 0.212799… ## $ basal_area_m2 &lt;dbl&gt; 0.010058830, 0.002888244, 0.005116955, 0.142… ## $ basal_area_ft2 &lt;dbl&gt; 0.10827324, 0.03108906, 0.05507891, 1.531314… ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; 5.578810, 3.222765, 4.348328, 8.994933, 5.92… ## $ is_training_cbh &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… ## $ geom &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((490177 4330...,… let’s view the height versus CBH relationship by training data trees_cbh_ans %&gt;% ggplot(aes(x = tree_height_m, y = tree_cbh_m, color = is_training_cbh)) + geom_point(size = 3, alpha = 0.8) + harrypotter::scale_color_hp_d(&quot;ronweasley&quot;, direction = -1) + scale_y_continuous(breaks = scales::breaks_extended(12)) + scale_x_continuous(breaks = scales::breaks_extended(12)) + labs(y = &quot;CBH (m)&quot;, x = &quot;Height (m)&quot;, color = &quot;is training data&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) check out the CBH spatially trees_cbh_ans %&gt;% ggplot(aes(color = is_training_cbh, fill = tree_cbh_m)) + geom_sf(lwd = 0.8) + harrypotter::scale_color_hp_d(&quot;ronweasley&quot;, direction = -1) + harrypotter::scale_fill_hp(&quot;always&quot;) + labs(fill = &quot;CBH (m)&quot;, color = &quot;is training data&quot;) + theme_light() + theme(legend.position = &quot;top&quot;, axis.text = element_blank()) + guides( color = guide_legend(order = 1, override.aes = list(lwd = 3, fill = NA)) ) 3.5.3 test CBH based on parameterization of LadderFuelsR Above, we tested different parameterization settings for the lidar data. Let’s do the same for UAS data to test for different levels of the min_fuel_layer_ht_m and dist_btwn_bins_m parameters Notice here that we adjusted the min_vhp_n and tree_sample_prop in the trees_cbh() function compared to the lidar data test # run it test_cbh_dta_u &lt;- 1:nrow(dta_temp) %&gt;% purrr::map(\\(x) test_cbh_fn(x, my_min_vhp_n = 4, my_tree_sample_prop = 0.08)) %&gt;% dplyr::bind_rows() which combinations caused errors? Update: in the cloud2trees package I have included error handling so that the function does not return the errors that happen in the LadderfulesR package. Additionally, if no trees return CBH based on the parameters passed to the LadderfulesR package, I attempt update the parameters to settings that have previously been successful for most data sets to get a successful result in the trees_cbh() call. # which combinations caused errors? dta_temp %&gt;% dplyr::anti_join( test_cbh_dta_u , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% kableExtra::kbl(caption = &quot;uas: these combintations resulted in ERROR!&quot;) %&gt;% kableExtra::kable_styling() Table 3.4: uas: these combintations resulted in ERROR! min_fuel_layer_ht_m dist_btwn_bins_m which combinations resulted in success? # which combinations caused success? dta_temp %&gt;% dplyr::inner_join( test_cbh_dta_u %&gt;% dplyr::distinct(min_fuel_layer_ht_m, dist_btwn_bins_m) , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% kableExtra::kbl(caption = &quot;uas: these combintations resulted in SUCCESS!&quot;) %&gt;% kableExtra::kable_styling() Table 3.5: uas: these combintations resulted in SUCCESS! min_fuel_layer_ht_m dist_btwn_bins_m 0.0 0.5 0.0 1.0 0.0 1.5 0.0 2.0 0.0 2.5 0.5 0.5 0.5 1.0 0.5 1.5 0.5 2.0 0.5 2.5 1.0 0.5 1.0 1.0 1.0 1.5 1.0 2.0 1.0 2.5 1.5 0.5 1.5 1.0 1.5 1.5 1.5 2.0 1.5 2.5 2.0 0.5 2.0 1.0 2.0 1.5 2.0 2.0 2.0 2.5 2.5 0.5 2.5 1.0 2.5 1.5 2.5 2.0 2.5 2.5 which combinations caused errors IN BOTH LIDAR AND UAS DATA? # which combinations caused errors? # UAS ERRORS dta_temp %&gt;% dplyr::anti_join( test_cbh_dta_u , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% dplyr::inner_join( # lidar ERRORS dta_temp %&gt;% dplyr::anti_join( test_cbh_dta , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) , by = dplyr::join_by(min_fuel_layer_ht_m, dist_btwn_bins_m) ) %&gt;% kableExtra::kbl(caption = &quot;lidar AND uas: these combintations resulted in ERROR!&quot;) %&gt;% kableExtra::kable_styling() Table 3.6: lidar AND uas: these combintations resulted in ERROR! min_fuel_layer_ht_m dist_btwn_bins_m is there a pattern?? ERROR if : min_fuel_layer_ht_m == dist_btwn_bins_m (except 0.5,1.5,2.5)?? ERROR if : dist_btwn_bins_m - min_fuel_layer_ht_m &gt;= 1.5 perhaps the pattern is driven by the interaction with another parameter that we did’t adjust anyway….. let’s check those CBH values test_cbh_dta_u %&gt;% dplyr::mutate( is_default = min_fuel_layer_ht_m == 1.5 &amp; dist_btwn_bins_m == 1 , minHT_step = forcats::fct_cross( factor(min_fuel_layer_ht_m), factor(dist_btwn_bins_m) , keep_empty = F ) %&gt;% forcats::fct_reorder( .x = tree_cbh_m , .fun = median ) %&gt;% forcats::fct_rev() ) %&gt;% ggplot(aes(y = minHT_step, x = tree_cbh_m, fill = is_default)) + geom_boxplot(width = 0.7, outliers = F) + harrypotter::scale_fill_hp_d(&quot;dracomalfoy&quot;, begin = 0.8, end = 0.2) + scale_x_continuous(breaks = scales::breaks_extended(12)) + labs(y = &quot;min_fuel_layer_ht_m : dist_btwn_bins_m&quot;, x = &quot;CBH (m)&quot;, fill = &quot;is the default&quot;) + theme_light() + theme(legend.position = &quot;top&quot;) is this interesting? we need to perform a study measuring the accuracy of the CBH estimated from the point cloud versus field validation data to properly determine what parameter settings to use in the LadderFuelsR process let’s check out the timer on a per tree basis secs_per_tree &lt;- test_cbh_dta_u %&gt;% dplyr::count(min_fuel_layer_ht_m, dist_btwn_bins_m, timer_secs) %&gt;% dplyr::mutate( secs_per_tree = timer_secs/n ) %&gt;% dplyr::pull(secs_per_tree) secs_per_tree %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.03099 0.03285 0.03459 0.03433 0.03567 0.03858 the estimate is that for every 1,000 trees the CBH extraction from the point cloud would take 0.6 minutes. how does that sound? "],["s03.html", "Section 4 Species Process 4.1 Example Lidar Data 4.2 USFS National Forest Type Group dataset 4.3 Forest Type to Tree List", " Section 4 Species Process In this section we’ll use the benchmark data made available in the NeonTreeEvaluation data set (Weinstein et al. 2021) to test a simple process for classifying the species of the trees extracted using lidar-based tree detection methods. The majority of research on classifying individual trees into different species categories using point cloud data from lidar or structure from motion data follows a similar process. This process generally involves segmenting individual trees and extracting key features from each tree using the point cloud, selecting the most relevant features, and training a machine learning model on a training dataset of trees with known species identities to classify tree species (Seidel et al. 2021; Meng et al. 2024). Such a process would require training data that may not be available in an easily accessible format over a broad extent (excepting FIA data, maybe?) which would be required for a general purpose process which we aim to define in the present research study. Instead, we will use a more simplistic process which uses the USFS Forest Type Groups of the Continental United States dataset Wilson (2023) available online here with a data overview here to attach the tree species group to individual trees detected from the point cloud data based on spatial location. At the time of this analysis the Wilson (2023) dataset was last updated on Oct 18, 2023 and depicts forest type groups for the Continental United States created from USFS Forest Inventory &amp; Analysis plot data collected from 2014-2018. This forest type groups dataset provides a broad classification of forest types at a 30-meter resolution and is preferable for our objective to the older, coarser (Ruefenacht et al. 2008) dataset available at https://data.fs.usda.gov/geodata/rastergateway/forest_type/. Here, we’ll outline the process to attach forest type group to the tree list based on the Forest Type Groups dataset. As a second option, we could utilize the TreeMap FIA data from Riley et al. (2021) to build a softmax regression (i.e. multinomial logistic regression) to predict the nominal variable tree species using the predictors tree height and location extracted from the point cloud data. This option roughly follows the process most represented in the existing literature as detailed above. Note that to predict the nominal variable tree species we could also use a random forest classifier as in Meng et al. (2024). The ultimate goal is to incorporate this process in the [cloud2trees]https://github.com/georgewoolsey/cloud2trees) package (Woolsey and Tinkham, 2024). First, load the standard libraries # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(ggnewscale) # ggnewscale library(rgl) # rgl plotting # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data library(cloud2trees) # tha cloud2trees library(NeonTreeEvaluation) # benchmark data # models library(brms) # bayesian modelling # utilities library(rvest) # web scraping 4.1 Example Lidar Data Let’s load an example lidar dataset from Weinstein et al. (2021) in their NeonTreeEvaluation package. We’ll use data from a NEON site that we know has conifers: RMNP (Rocky Mountain National Park) # let&#39;s see some field trees data NeonTreeEvaluation::field %&gt;% dplyr::filter(siteID == &quot;RMNP&quot;) %&gt;% dplyr::count(taxonID) %&gt;% dplyr::arrange(desc(n)) ## taxonID n ## 1 PICOL 773 ## 2 POTR5 292 ## 3 PIPOS 91 ## 4 PSME 89 ## 5 ABLAL 57 ## 6 PIEN 39 ## 7 PIFL2 34 let’s pick a site with the lowest proportion of POTR5 plots_temp &lt;- NeonTreeEvaluation::field %&gt;% dplyr::filter(siteID == &quot;RMNP&quot;) %&gt;% dplyr::group_by(plotID) %&gt;% dplyr::summarise( trees = dplyr::n() , conifers = sum(ifelse(taxonID==&quot;POTR5&quot;, 0, 1)) ) %&gt;% dplyr::mutate(pct_conifer = conifers/trees) %&gt;% dplyr::filter(trees&gt;20) %&gt;% dplyr::arrange(desc(pct_conifer), desc(trees)) plots_temp ## # A tibble: 20 × 4 ## plotID trees conifers pct_conifer ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 RMNP_042 111 111 1 ## 2 RMNP_043 104 104 1 ## 3 RMNP_047 59 59 1 ## 4 RMNP_008 50 50 1 ## 5 RMNP_048 50 50 1 ## 6 RMNP_001 41 41 1 ## 7 RMNP_006 39 39 1 ## 8 RMNP_014 36 36 1 ## 9 RMNP_012 35 35 1 ## 10 RMNP_003 30 30 1 ## 11 RMNP_018 29 29 1 ## 12 RMNP_005 24 24 1 ## 13 RMNP_002 21 21 1 ## 14 RMNP_041 131 128 0.977 ## 15 RMNP_004 27 26 0.963 ## 16 RMNP_049 36 34 0.944 ## 17 RMNP_007 30 24 0.8 ## 18 RMNP_044 111 68 0.613 ## 19 RMNP_045 229 57 0.249 ## 20 RMNP_046 73 13 0.178 look at the tree data for this plot NeonTreeEvaluation::field %&gt;% dplyr::filter(plotID == plots_temp[1,]$plotID) %&gt;% dplyr::count(taxonID, scientificName) ## taxonID scientificName ## 1 PICOL Pinus contorta Douglas ex Loudon var. latifolia Engelm. ex S. Watson ## n ## 1 111 get the lidar data # get the laz file path las_f_path_temp &lt;- paste0(system.file(package = &quot;NeonTreeEvaluation&quot;),&quot;/extdata/&quot;) %&gt;% list.files(recursive = T, pattern = &quot;.*\\\\.(laz|las)$&quot;, full.names = T) %&gt;% unique() %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(f_path = 1) %&gt;% dplyr::filter( stringr::str_detect(f_path, as.character(plots_temp[1,]$plotID)) ) %&gt;% .[1] %&gt;% dplyr::pull(f_path) # check the data lidR::readLAS(las_f_path_temp) ## class : LAS (v1.3 format 1) ## memory : 1.2 Mb ## extent : 453532.6, 453572.6, 4458556, 4458596 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 1653 m² ## points : 20.4 thousand points ## density : 12.35 points/m² ## density : 7.63 pulses/m² 4.1.1 cloud2trees that lidar data extract trees from the lidar data using cloud2trees we do not need to get DBH or CBH for this testing cloud2trees_ans &lt;- cloud2trees::cloud2trees( input_las_dir = las_f_path_temp , output_dir = tempdir() , estimate_tree_dbh = F , estimate_tree_cbh = F ) let’s see what we got cloud2trees_ans$treetops_sf %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 20 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ fia_est_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_lower &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_upper &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_data &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_ft2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_cbh &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ geometry &lt;POINT [m]&gt; POINT (453532.6 4458595), POINT (45354… where is this? # where? cloud2trees_ans$treetops_sf %&gt;% mapview::mapview(layer.name = &quot;trees&quot;) zoom out if you can’t see anything 4.2 USFS National Forest Type Group dataset Download the USFS National Forest Type Group dataset (Wilson 2023) available online here with a data overview here to attach the tree species group to individual trees detected from the point cloud data based on spatial location. At the time of this analysis the Wilson (2023) dataset was last updated on Oct 18, 2023 and depicts forest type groups for the Continental United States created from USFS Forest Inventory &amp; Analysis plot data collected from 2014-2018. This forest type groups dataset provides a broad classification of forest types at a 30-meter resolution to attach the tree species group to individual trees detected from the point cloud data based on spatial location. Here, we’ll outline the process to attach forest type group to the tree list based on the Forest Type Groups dataset. 4.2.1 Get the data define a function to download the data !!!The download function get_foresttype_raw() below works great…however, there is a hard limitation on the image api service with respect to maximum download limits. Attempting to get the entire extent of the data results in a downscaling from 30x30 m resolution to 808x808m resolution. Attempting to download the extent in chunks gets us closer to the native resolution (~50-100 m) but requires that the service returns the data without error for ~300-900 chunks; this process is ripe for error. As such, I resorted to utilizing the image service within ArcGIS Pro and used the following steps: connect to the image service via the “Open in ArcGIS Desktop” at the data source to get around the image service data limits, aggregate the raster to 90x90 m resolution in chunks open the Aggregate tool (Spatial Analyst tools) in the “Environments” tab change the extent to process in chunks chunk 1 in the “Environments” tab change the Extent “X and Y Extent” (t,l,r,b): 6868893.686445,-14469331.213417,-10383464.5467503,2480613.686445 in the “Parameters” tab set the “Cell factor” to 3 with “Aggregation technique” to maximum (to prefer any data to no data which is coded as 0), everything else is default run the tool (this took 71 mins across 6 parallel instances for 1 chunk) export the raster layer as a .tif repeat for chunk 2 in the “Environments” tab change the Extent “X and Y Extent” (t,l,r,b): 6868893.686445,-10383464.5467503,-7114771.213417,2480613.686445 Use the “Mosaic to New Raster” tool to combine the chunks using the maximum “Mosaic Operator” with a “Pixel Type” of 16-bit unsigned and 1 for “Number of Bands” export the raster layer as a .tif upload to Zenodo we’ll then define a download process to get our aggregated (90x90 m) forest type raster from Zenodo Even though this process is inefficient and manual (i.e. painful), it is preferable to using the the USFS Forest Type Groups of the Continental United States dataset (Ruefenacht et al. 2008) which is older, coarser in resolution (250x250 m), and uses a custom projection system that does not have a well-known EPSG available in the terra and sf packages. Endure the pain once, the grass may be greener on the other side. 4.2.1.1 Get raw data Not used but works (see discussion above). This function pulls the data directly from the image server. # this is for: # Wilson, B. T. (2021). # Available online at: https://di-usfsdata.img.arcgis.com/arcgis/rest/services/CONUS_forest_type_group_2018_masked_202105122120120/ImageServer # with a data overview at: https://www.arcgis.com/home/item.html?id=10760c83b9e44923bd3c18efdaa7319d get_foresttype_raw &lt;- function(savedir=NULL,force=F){ #Store users timeout options timeout_option_backup &lt;- getOption(&quot;timeout&quot;) options(timeout = max(3600, getOption(&quot;timeout&quot;))) if(is.null(savedir)){ # create dir dir.create(paste0(system.file(package = &quot;cloud2trees&quot;),&quot;/extdata&quot;), showWarnings = FALSE) # names dirname &lt;- paste0(system.file(package = &quot;cloud2trees&quot;),&quot;/extdata/foresttype&quot;) destination &lt;- file.path(dirname,&quot;foresttype.tif&quot;) }else{ dirname &lt;- file.path(savedir,&quot;foresttype&quot;) destination &lt;- file.path(dirname,&quot;foresttype.tif&quot;) } # create dir dir.create(dirname, showWarnings = FALSE) #check if already exists. f &lt;- tolower(list.files(dirname)) if(length(f)==0){f &lt;- &quot;&quot;} if( max(grepl(&quot;foresttype.tif&quot;, f))==1 ){ if(!force){ warning(paste(&quot;Data has already been downloaded to&quot;,dirname,&quot;, use force=T to overwrite&quot;)) return(NULL) } } # url # # math to set the size parameter # map_ext &lt;- c(-1.4469E7,2480613,-7114771,6868893) # (w &lt;- map_ext[3]-map_ext[1]) # (h &lt;- map_ext[4]-map_ext[2]) # c(w,h) %&gt;% `*`(.001137) %&gt;% round() # this returns the w,h to enter for size # exporting the entire image at a resolution better than 808x808 is not possible with the image server data limits # let&#39;s try chunking up the area, downloading tiles, then mosaicing to get a better resolution # math to set the size parameter map_ext &lt;- c(-1.4469E7,2480613,-7114771,6868893) (w &lt;- map_ext[3]-map_ext[1]) (h &lt;- map_ext[4]-map_ext[2]) # this returns the w,h to enter for size parameter # c(w,h) %&gt;% `*`(.001137) %&gt;% round() %&gt;% paste(collapse = &quot;,&quot;) # this returns the w,h to enter for size..best size_temp &lt;- c(w,h) %&gt;% `*`(.0007) %&gt;% round() %&gt;% paste(collapse = &quot;%2C&quot;) # paste(collapse = &quot;,&quot;) # chunk this # x combinations x_l &lt;- dplyr::tibble( xmin = seq(from = map_ext[1], to = map_ext[3], length.out = 15) ) %&gt;% dplyr::mutate(xmax = dplyr::lead(xmin, n = 1)) %&gt;% dplyr::filter(!is.na(xmax)) # y combinations y_l &lt;- dplyr::tibble( ymin = seq(from = map_ext[2], to = map_ext[4], length.out = 15) ) %&gt;% dplyr::mutate(ymax = dplyr::lead(ymin, n = 1)) %&gt;% dplyr::filter(!is.na(ymax)) # combine chunk_df &lt;- tidyr::crossing(x_l,y_l) %&gt;% dplyr::mutate( w = xmax - xmin , h = ymax - ymin ) # chunk_df %&gt;% dplyr::glimpse() # chunk_df %&gt;% # dplyr::mutate(n = dplyr::row_number()) %&gt;% # ggplot() + # geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = as.factor(n)), color = &quot;black&quot;) + # theme(legend.position = &quot;none&quot;) # function to build the api string and download dl_ans &lt;- 1:nrow(chunk_df) %&gt;% purrr::map(function(x){ # get the bounding box string bb_temp &lt;- chunk_df %&gt;% dplyr::select(xmin,ymin,xmax,ymax) %&gt;% dplyr::filter(dplyr::row_number() == x) %&gt;% c() %&gt;% unlist() %&gt;% paste(collapse = &quot;%2C&quot;) # paste(collapse = &quot;,&quot;) # buld url eval_url &lt;- paste0( &quot;https://di-usfsdata.img.arcgis.com/arcgis/rest/services/CONUS_forest_type_group_2018_masked_202105122120120/ImageServer/exportImage?bbox=&quot; , bb_temp # &quot;-1.4469E7%2C2480613%2C-7114771%2C6868893&quot; , &quot;&amp;bboxSR=&amp;size=&quot; , size_temp # &quot;8362%2C4989&quot; , &quot;&amp;imageSR=&amp;time=&amp;format=tiff&amp;pixelType=U16&amp;noData=&amp;noDataInterpretation=esriNoDataMatchAny&amp;interpolation=RSP_BilinearInterpolation&amp;compression=None&amp;compressionQuality=&amp;bandIds=&amp;sliceId=&amp;mosaicRule=&amp;renderingRule=&amp;adjustAspectRatio=true&amp;validateExtent=false&amp;lercVersion=1&amp;compressionTolerance=&amp;f=html&quot; ) # now we have to parse the url return because this server creates a unique token for each request html &lt;- rvest::read_html(x = eval_url) # get parent element chrs &lt;- html %&gt;% rvest::html_elements(&quot;a&quot;) # unnest children elements iii &lt;- chrs %&gt;% rvest::html_text2() %&gt;% purrr::detect_index(function(x) tolower(x) == &quot;download image&quot;) # download url dl_url &lt;- chrs[iii] %&gt;% html_attr(&quot;href&quot;) # get it chunk_dest &lt;- file.path(dirname, paste0(&quot;chunk_&quot;,x,&quot;.tif&quot;)) message(paste(&quot;Downloading file to&quot;,chunk_dest)) download.file(dl_url, chunk_dest, mode = &quot;wb&quot;) }) options(timeout = timeout_option_backup) return(dl_ans) } 4.2.1.2 Get cleaned data This function downloads the cleaned data from the Zenodo archive # this is for: [Ruefenacht et al. 2008](https://doi.org/10.14358/PERS.74.11.1379)) # The Forest Type Groups dataset provides a broad classification of forest types at a 250-meter resolution # and is available at: https://data.fs.usda.gov/geodata/rastergateway/forest_type/ # ...select the &quot;Conus Forest Type&quot; get_foresttype &lt;- function(savedir=NULL,force=F){ #Store users timeout options timeout_option_backup &lt;- getOption(&quot;timeout&quot;) options(timeout = max(3600, getOption(&quot;timeout&quot;))) if(is.null(savedir)){ # create dir dir.create(paste0(system.file(package = &quot;cloud2trees&quot;),&quot;/extdata&quot;), showWarnings = FALSE) # names destination &lt;- paste0(system.file(package = &quot;cloud2trees&quot;),&quot;/extdata/foresttype.zip&quot;) dirname &lt;- paste0(system.file(package = &quot;cloud2trees&quot;),&quot;/extdata/foresttype&quot;) }else{ destination &lt;- file.path(savedir,&quot;foresttype.zip&quot;) dirname &lt;- file.path(savedir,&quot;foresttype&quot;) } # create dir dir.create(dirname, showWarnings = FALSE) #check if already exists. f_dir &lt;- file.path(dirname(destination),&quot;foresttype/&quot;) # f_dir &lt;- paste0(system.file(&quot;extdata&quot;, &quot;foresttype/&quot;, package = &quot;cloud2trees&quot;)) f &lt;- toupper(list.files(f_dir)) if(length(f)==0){f &lt;- &quot;&quot;} if( max(grepl(&quot;TREEMAP2016.TIF&quot;, f))==1 &amp; max(grepl(&quot;TREEMAP2016_TREE_TABLE.CSV&quot;, f))==1 ){ if(!force){ warning(paste(&quot;Data has already been downloaded to&quot;,dirname,&quot;, use force=T to overwrite&quot;)) return(NULL) } } # get data eval_url &lt;- &quot;https://s3-us-west-2.amazonaws.com/fs.usda.rds/RDS-2021-0074/RDS-2021-0074_Data.zip&quot; message(paste(&quot;Downloading file to&quot;,destination)) download.file(eval_url, destination, mode = &quot;wb&quot;) unzip_download(destination) options(timeout = timeout_option_backup) } ## unzip function unzip_download &lt;- function(destination){ #location of unzip base_dir &lt;- dirname(destination) #get file names unzip_folder &lt;- unzip(destination, list = TRUE)$Name[1] unzipped_folder &lt;- file.path(base_dir,unzip_folder) unzip(destination,exdir=base_dir) final_name &lt;- file.path(base_dir,&quot;foresttype/&quot;) #Force delete of any previous folder unlink(final_name,recursive = T) file.rename(unzipped_folder,final_name) #Remove zipped files unlink(destination) } call the function to download the data # define dl dir savedir_temp &lt;- &quot;../data/&quot; # what dirs do we have already? list.dirs(savedir_temp, recursive = F) # get the data get_foresttype(savedir = savedir_temp) ## get_foresttype_raw(savedir = savedir_temp) # if want to test the raw image extraction # now what dirs? list.dirs(savedir_temp, recursive = F) # are there files in the foresttype dir? list.files(file.path(savedir_temp, &quot;foresttype&quot;)) 4.2.2 Check the raster let’s check this data foresttype &lt;- # terra::rast(&quot;c:/Users/georg/Downloads/conus_forest-type/conus_foresttype.img&quot;) # terra::rast(&quot;../data/foresttype/foresttype.tif&quot;) terra::rast(&quot;E:\\\\lidar_phys_fire_mods\\\\data\\\\foresttype.tif&quot;) # what? foresttype ## class : SpatRaster ## dimensions : 48759, 81718, 1 (nrow, ncol, nlyr) ## resolution : 90, 90 (x, y) ## extent : -14469331, -7114711, 2480614, 6868924 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / Pseudo-Mercator (EPSG:3857) ## source : foresttype.tif ## name : foresttype ## min value : 0 ## max value : 999 # layers? terra::names(foresttype) ## [1] &quot;foresttype&quot; # resolution terra::res(foresttype) ## [1] 90 90 # crs? terra::crs(foresttype) ## [1] &quot;PROJCRS[\\&quot;WGS 84 / Pseudo-Mercator\\&quot;,\\n BASEGEOGCRS[\\&quot;WGS 84\\&quot;,\\n DATUM[\\&quot;World Geodetic System 1984\\&quot;,\\n ELLIPSOID[\\&quot;WGS 84\\&quot;,6378137,298.257223563,\\n LENGTHUNIT[\\&quot;metre\\&quot;,1]]],\\n PRIMEM[\\&quot;Greenwich\\&quot;,0,\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433]],\\n ID[\\&quot;EPSG\\&quot;,4326]],\\n CONVERSION[\\&quot;unnamed\\&quot;,\\n METHOD[\\&quot;Popular Visualisation Pseudo Mercator\\&quot;,\\n ID[\\&quot;EPSG\\&quot;,1024]],\\n PARAMETER[\\&quot;Latitude of natural origin\\&quot;,0,\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433],\\n ID[\\&quot;EPSG\\&quot;,8801]],\\n PARAMETER[\\&quot;Longitude of natural origin\\&quot;,0,\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433],\\n ID[\\&quot;EPSG\\&quot;,8802]],\\n PARAMETER[\\&quot;False easting\\&quot;,0,\\n LENGTHUNIT[\\&quot;metre\\&quot;,1],\\n ID[\\&quot;EPSG\\&quot;,8806]],\\n PARAMETER[\\&quot;False northing\\&quot;,0,\\n LENGTHUNIT[\\&quot;metre\\&quot;,1],\\n ID[\\&quot;EPSG\\&quot;,8807]]],\\n CS[Cartesian,2],\\n AXIS[\\&quot;easting\\&quot;,east,\\n ORDER[1],\\n LENGTHUNIT[\\&quot;metre\\&quot;,1]],\\n AXIS[\\&quot;northing\\&quot;,north,\\n ORDER[2],\\n LENGTHUNIT[\\&quot;metre\\&quot;,1]],\\n ID[\\&quot;EPSG\\&quot;,3857]]&quot; what does this cover? # the projection is not carried over when going from spatextent to vector crs_temp &lt;- terra::crs(foresttype, describe = T) epsg_temp &lt;- paste(crs_temp$authority[1], crs_temp$code[1], sep = &quot;:&quot;) # where is this? terra::ext(foresttype) %&gt;% terra::vect() %&gt;% sf::st_as_sf() %&gt;% sf::st_set_crs(epsg_temp) %&gt;% mapview::mapview() quick map terra::plot(foresttype) let’s check the values terra::freq(foresttype) %&gt;% dplyr::arrange(desc(count)) %&gt;% dplyr::slice_head(n = 12) ## layer value count ## 1 1 0 1016698844 ## 2 1 500 182777000 ## 3 1 800 53970418 ## 4 1 180 53178290 ## 5 1 160 41136189 ## 6 1 200 37352480 ## 7 1 900 36640662 ## 8 1 600 34110206 ## 9 1 260 33204632 ## 10 1 220 27870805 ## 11 1 970 24823216 ## 12 1 280 17843824 4.2.3 Forest type group data let’s create a lookup table of these forest type groups using the data table from Woudenberg et al. (2010) Appendix D foresttype_lookup &lt;- c( 100, &quot;White / red / jack pine group&quot;, 101, &quot;Jack pine&quot;, 102, &quot;Red pine&quot;, 103, &quot;Eastern white pine&quot;, 104, &quot;Eastern white pine / eastern hemlock&quot;, 105, &quot;Eastern hemlock&quot;, 120, &quot;Spruce / fir group&quot;, 121, &quot;Balsam fir&quot;, 122, &quot;White spruce&quot;, 123, &quot;Red spruce&quot;, 124, &quot;Red spruce / balsam fir&quot;, 125, &quot;Black spruce&quot;, 126, &quot;Tamarack&quot;, 127, &quot;Northern white-cedar&quot;, 128, &quot;Fraser fir&quot;, 129, &quot;Red spruce / Fraser fir&quot;, 140, &quot;Longleaf / slash pine group&quot;, 141, &quot;Longleaf pine&quot;, 142, &quot;Slash pine&quot;, 150, &quot;Tropical pine group&quot;, 151, &quot;Tropical pines&quot;, 160, &quot;Loblolly / shortleaf pine group&quot;, 161, &quot;Loblolly pine&quot;, 162, &quot;Shortleaf pine&quot;, 163, &quot;Virginia pine&quot;, 164, &quot;Sand pine&quot;, 165, &quot;Table mountain pine&quot;, 166, &quot;Pond pine&quot;, 167, &quot;Pitch pine&quot;, 168, &quot;Spruce pine&quot;, 170, &quot;Other eastern softwoods group&quot;, 171, &quot;Eastern redcedar&quot;, 172, &quot;Florida softwoods&quot;, 180, &quot;Pinyon / juniper group&quot;, 182, &quot;Rocky Mountain juniper&quot;, 184, &quot;Juniper woodland&quot;, 185, &quot;Pinyon / juniper woodland&quot;, 200, &quot;Douglas-fir group&quot;, 201, &quot;Douglas-fir&quot;, 202, &quot;Port-Orford-cedar&quot;, 203, &quot;Bigcone Douglas-fir &quot;, 220, &quot;Ponderosa pine group&quot;, 221, &quot;Ponderosa pine&quot;, 222, &quot;Incense-cedar&quot;, 224, &quot;Sugar pine&quot;, 225, &quot;Jeffrey pine&quot;, 226, &quot;Coulter pine&quot;, 240, &quot;Western white pine group&quot;, 241, &quot;Western white pine&quot;, 260, &quot;Fir / spruce / mountain hemlock group&quot;, 261, &quot;White fir&quot;, 262, &quot;Red fir&quot;, 263, &quot;Noble fir&quot;, 264, &quot;Pacific silver fir&quot;, 265, &quot;Engelmann spruce&quot;, 266, &quot;Engelmann spruce / subalpine fir&quot;, 267, &quot;Grand fir&quot;, 268, &quot;Subalpine fir&quot;, 269, &quot;Blue spruce&quot;, 270, &quot;Mountain hemlock&quot;, 271, &quot;Alaska-yellow-cedar&quot;, 280, &quot;Lodgepole pine group&quot;, 281, &quot;Lodgepole pine&quot;, 300, &quot;Hemlock / Sitka spruce group&quot;, 301, &quot;Western hemlock&quot;, 304, &quot;Western redcedar&quot;, 305, &quot;Sitka spruce&quot;, 320, &quot;Western larch group&quot;, 321, &quot;Western larch&quot;, 340, &quot;Redwood group&quot;, 341, &quot;Redwood&quot;, 342, &quot;Giant sequoia&quot;, 360, &quot;Other western softwoods group&quot;, 361, &quot;Knobcone pine&quot;, 362, &quot;Southwestern white pine&quot;, 363, &quot;Bishop pine&quot;, 364, &quot;Monterey pine&quot;, 365, &quot;Foxtail pine / bristlecone pine&quot;, 366, &quot;Limber pine&quot;, 367, &quot;Whitebark pine&quot;, 368, &quot;Miscellaneous western softwoods&quot;, 369, &quot;Western juniper&quot;, 370, &quot;California mixed conifer group&quot;, 371, &quot;California mixed conifer&quot;, 380, &quot;Exotic softwoods group&quot;, 381, &quot;Scotch pine&quot;, 383, &quot;Other exotic softwoods&quot;, 384, &quot;Norway spruce&quot;, 385, &quot;Introduced larch&quot;, 390, &quot;Other softwoods group&quot;, 391, &quot;Other softwoods&quot;, 400, &quot;Oak / pine group&quot;, 401, &quot;Eastern white pine / northern red oak / white ash&quot;, 402, &quot;Eastern redcedar / hardwood&quot;, 403, &quot;Longleaf pine / oak&quot;, 404, &quot;Shortleaf pine / oak&quot;, 405, &quot;Virginia pine / southern red oak&quot;, 406, &quot;Loblolly pine / hardwood&quot;, 407, &quot;Slash pine / hardwood&quot;, 409, &quot;Other pine / hardwood&quot;, 500, &quot;Oak / hickory group&quot;, 501, &quot;Post oak / blackjack oak&quot;, 502, &quot;Chestnut oak&quot;, 503, &quot;White oak / red oak / hickory&quot;, 504, &quot;White oak&quot;, 505, &quot;Northern red oak&quot;, 506, &quot;Yellow-poplar / white oak / northern red oak&quot;, 507, &quot;Sassafras / persimmon&quot;, 508, &quot;Sweetgum / yellow-poplar&quot;, 509, &quot;Bur oak&quot;, 510, &quot;Scarlet oak&quot;, 511, &quot;Yellow-poplar&quot;, 512, &quot;Black walnut&quot;, 513, &quot;Black locust&quot;, 514, &quot;Southern scrub oak&quot;, 515, &quot;Chestnut oak / black oak / scarlet oak&quot;, 516, &quot;Cherry / white ash / yellow-poplar&quot;, 517, &quot;Elm / ash / black locust&quot;, 519, &quot;Red maple / oak&quot;, 520, &quot;Mixed upland hardwoods&quot;, 600, &quot;Oak / gum / cypress group&quot;, 601, &quot;Swamp chestnut oak / cherrybark oak&quot;, 602, &quot;Sweetgum / Nuttall oak / willow oak&quot;, 605, &quot;Overcup oak / water hickory&quot;, 606, &quot;Atlantic white-cedar&quot;, 607, &quot;Baldcypress / water tupelo&quot;, 608, &quot;Sweetbay / swamp tupelo / red maple&quot;, 609, &quot;Baldcypress / pondcypress&quot;, 700, &quot;Elm / ash / cottonwood group&quot;, 701, &quot;Black ash / American elm / red maple&quot;, 702, &quot;River birch / sycamore&quot;, 703, &quot;Cottonwood&quot;, 704, &quot;Willow&quot;, 705, &quot;Sycamore / pecan / American elm&quot;, 706, &quot;Sugarberry / hackberry / elm / green ash&quot;, 707, &quot;Silver maple / American elm&quot;, 708, &quot;Red maple / lowland&quot;, 709, &quot;Cottonwood / willow&quot;, 722, &quot;Oregon ash&quot;, 800, &quot;Maple / beech / birch group&quot;, 801, &quot;Sugar maple / beech / yellow birch&quot;, 802, &quot;Black cherry&quot;, 805, &quot;Hard maple / basswood&quot;, 809, &quot;Red maple / upland&quot;, 900, &quot;Aspen / birch group&quot;, 901, &quot;Aspen&quot;, 902, &quot;Paper birch&quot;, 903, &quot;Gray birch&quot;, 904, &quot;Balsam poplar&quot;, 905, &quot;Pin cherry&quot;, 910, &quot;Alder / maple group&quot;, 911, &quot;Red alder&quot;, 912, &quot;Bigleaf maple&quot;, 920, &quot;Western oak group&quot;, 921, &quot;Gray pine&quot;, 922, &quot;California black oak&quot;, 923, &quot;Oregon white oak&quot;, 924, &quot;Blue oak&quot;, 931, &quot;Coast live oak&quot;, 933, &quot;Canyon live oak&quot;, 934, &quot;Interior live oak&quot;, 935, &quot;California white oak (valley oak)&quot;, 940, &quot;Tanoak / laurel group&quot;, 941, &quot;Tanoak&quot;, 942, &quot;California laurel&quot;, 943, &quot;Giant chinkapin&quot;, 960, &quot;Other hardwoods group&quot;, 961, &quot;Pacific madrone&quot;, 962, &quot;Other hardwoods&quot;, 970, &quot;Woodland hardwoods group&quot;, 971, &quot;Deciduous oak woodland&quot;, 972, &quot;Evergreen oak woodland&quot;, 973, &quot;Mesquite woodland&quot;, 974, &quot;Cercocarpus (mountain brush) woodland&quot;, 975, &quot;Intermountain maple woodland&quot;, 976, &quot;Miscellaneous woodland hardwoods&quot;, 980, &quot;Tropical hardwoods group&quot;, 982, &quot;Mangrove&quot;, 983, &quot;Palms&quot;, 988, &quot;Cloud forest&quot;, 989, &quot;Other tropical hardwoods&quot;, 990, &quot;Exotic hardwoods group&quot;, 991, &quot;Paulownia&quot;, 992, &quot;Melaleuca&quot;, 993, &quot;Eucalyptus&quot;, 995, &quot;Other exotic hardwoods&quot;, 999, &quot;Nonstocked&quot;, ## this list below is from: 101, &quot;Jack pine&quot;, 102, &quot;Red pine&quot;, 103, &quot;Eastern white pine&quot;, 104, &quot;Eastern White pine / Eastern hemlock&quot;, 105, &quot;Eastern hemlock&quot;, 121, &quot;Balsam fir&quot;, 122, &quot;White spruce&quot;, 123, &quot;Red spruce&quot;, 124, &quot;Red spruce / balsam fir&quot;, 125, &quot;Black spruce&quot;, 126, &quot;Tamarack&quot;, 127, &quot;Northern white-cedar&quot;, 141, &quot;Longleaf pine&quot;, 142, &quot;Slash pine&quot;, 161, &quot;Loblolly pine&quot;, 162, &quot;Shortleaf pine&quot;, 163, &quot;Virginia pine&quot;, 164, &quot;Sand pine&quot;, 165, &quot;Table-mountain pine&quot;, 166, &quot;Pond pine&quot;, 167, &quot;Pitch pine&quot;, 168, &quot;Spruce pine&quot;, 181, &quot;Eastern redcedar&quot;, 182, &quot;Rocky Mountain juniper&quot;, 183, &quot;Western juniper&quot;, 184, &quot;Juniper woodland&quot;, 185, &quot;Pinyon juniper woodland&quot;, 201, &quot;Douglas-fir&quot;, 202, &quot;Port-Orford-cedar&quot;, 221, &quot;Ponderosa pine&quot;, 222, &quot;Incense cedar&quot;, 223, &quot;Jeffrey pine / Coulter pine / bigcone Douglas-fir&quot;, 224, &quot;Sugar pine&quot;, 241, &quot;Western white pine&quot;, 261, &quot;White fir&quot;, 262, &quot;Red fir&quot;, 263, &quot;Noble fir&quot;, 264, &quot;Pacific silver fir&quot;, 265, &quot;Engelmann spruce&quot;, 266, &quot;Engelmann spruce / subalpine fir&quot;, 267, &quot;Grand fir&quot;, 268, &quot;Subalpine fir&quot;, 269, &quot;Blue spruce&quot;, 270, &quot;Mountain hemlock&quot;, 271, &quot;Alaska-yellow-cedar&quot;, 281, &quot;Lodgepole pine&quot;, 301, &quot;Western hemlock&quot;, 304, &quot;Western redcedar&quot;, 305, &quot;Sitka spruce&quot;, 321, &quot;Western larch&quot;, 341, &quot;Redwood&quot;, 342, &quot;Giant sequoia&quot;, 361, &quot;Knobcone pine&quot;, 362, &quot;Southwest white pine&quot;, 363, &quot;Bishop pine&quot;, 364, &quot;Monterey pine&quot;, 365, &quot;Foxtail pine / bristlecone pine&quot;, 366, &quot;Limber pine&quot;, 367, &quot;Whitebark pine&quot;, 368, &quot;Misc. western softwoods&quot;, 371, &quot;California mixed conifer&quot;, 381, &quot;Scotch pine&quot;, 382, &quot;Australian pine&quot;, 383, &quot;Other exotic softwoods&quot;, 384, &quot;Norway Spruce&quot;, 385, &quot;Introduced larch&quot;, 401, &quot;Eastern white pine / N. red oak / white ash&quot;, 402, &quot;Eastern redcedar / hardwood&quot;, 403, &quot;Longleaf pine / oak&quot;, 404, &quot;Shortleaf pine / oak&quot;, 405, &quot;Virginia pine / southern red oak&quot;, 406, &quot;Loblolly pine / hardwood&quot;, 407, &quot;Slash pine / hardwood&quot;, 409, &quot;Other pine / hardwood&quot;, 501, &quot;Post oak / blackjack oak&quot;, 502, &quot;Chestnut oak&quot;, 503, &quot;White oak / red oak / hickory&quot;, 504, &quot;White oak&quot;, 505, &quot;Northern red oak&quot;, 506, &quot;Yellow-poplar / white oak / N. red oak&quot;, 507, &quot;Sassafras / persimmon&quot;, 508, &quot;Sweetgum / yellow-poplar&quot;, 509, &quot;Bur oak&quot;, 510, &quot;Scarlet oak&quot;, 511, &quot;Yellow-poplar&quot;, 512, &quot;Black walnut&quot;, 513, &quot;Black locust&quot;, 514, &quot;Southern scrub oak&quot;, 515, &quot;Chestnut oak / black oak / scarlet oak&quot;, 519, &quot;Red maple / oak&quot;, 520, &quot;Mixed upland hardwoods&quot;, 601, &quot;Swamp chestnut oak / cherrybark oak&quot;, 602, &quot;Sweetgum / Nuttall oak / willow oak&quot;, 605, &quot;Overcup oak / water hickory&quot;, 606, &quot;Atlantic white-cedar&quot;, 607, &quot;Baldcypress / water tupelo&quot;, 608, &quot;Sweetbay / swamp tupelo / red maple&quot;, 701, &quot;Black ash / American elm / red maple&quot;, 702, &quot;River birch / sycamore&quot;, 703, &quot;Cottonwood&quot;, 704, &quot;Willow&quot;, 705, &quot;Sycamore / pecan / American elm&quot;, 706, &quot;Sugarberry / hackberry / elm / green ash&quot;, 707, &quot;Silver maple / American elm&quot;, 708, &quot;Red maple / lowland&quot;, 709, &quot;Cottonwood / willow&quot;, 722, &quot;Oregon ash&quot;, 801, &quot;Sugar maple / beech / yellow birch&quot;, 802, &quot;Black cherry&quot;, 803, &quot;Cherry / ash / yellow-poplar&quot;, 805, &quot;Hard maple / basswood&quot;, 807, &quot;Elm / ash / locust&quot;, 809, &quot;Red maple / upland&quot;, 901, &quot;Aspen&quot;, 902, &quot;Paper birch&quot;, 904, &quot;Balsam poplar&quot;, 911, &quot;Red alder&quot;, 912, &quot;Bigleaf maple&quot;, 921, &quot;Gray pine&quot;, 922, &quot;California black oak&quot;, 923, &quot;Oregon white oak&quot;, 924, &quot;Blue oak&quot;, 925, &quot;Deciduous oak woodland&quot;, 926, &quot;Evergreen oak woodland&quot;, 931, &quot;Coast live oak&quot;, 932, &quot;Canyon live oak / interior live oak&quot;, 941, &quot;Tanoak&quot;, 942, &quot;Califonia laurel&quot;, 943, &quot;Giant chinkapin&quot;, 951, &quot;Pacific madrone&quot;, 952, &quot;Mesquite Woodland&quot;, 953, &quot;Cercocarpus woodland&quot;, 954, &quot;Intermountain maple woodland&quot;, 955, &quot;Misc. western hardwood woodlands&quot;, 981, &quot;Sabal palm&quot;, 982, &quot;Mangrove&quot;, 989, &quot;Other tropical&quot;, 991, &quot;Paulownia&quot;, 992, &quot;Melaluca&quot;, 993, &quot;Eucalyptus&quot;, 995, &quot;Other exotic hardwoods&quot; ) %&gt;% matrix(ncol = 2, byrow = T) %&gt;% dplyr::as_tibble() %&gt;% dplyr::rename(forest_type_code = 1, forest_type = 2) %&gt;% dplyr::mutate(forest_type = stringr::str_squish(forest_type)) %&gt;% dplyr::group_by(forest_type_code) %&gt;% dplyr::filter(dplyr::row_number()==1) %&gt;% dplyr::ungroup() # huh? foresttype_lookup %&gt;% dplyr::glimpse() ## Rows: 202 ## Columns: 2 ## $ forest_type_code &lt;chr&gt; &quot;100&quot;, &quot;101&quot;, &quot;102&quot;, &quot;103&quot;, &quot;104&quot;, &quot;105&quot;, &quot;120&quot;, &quot;121… ## $ forest_type &lt;chr&gt; &quot;White / red / jack pine group&quot;, &quot;Jack pine&quot;, &quot;Red pi… let’s create a column for the “forest type group” which is included in this data as any type code that is a multiple of 10 starting at 100…but remember we need to exclude the “999” which is “Nonstocked” foresttype_lookup &lt;- foresttype_lookup %&gt;% # define forest_type_group_code as the 10&#39;s value dplyr::mutate( forest_type_group_code = forest_type_code %&gt;% stringr::str_sub(end = -2) %&gt;% # cuts off the last digit from a number as a string paste0(&quot;0&quot;) , forest_type_group = dplyr::case_when( forest_type_group_code == forest_type_code ~ forest_type , T ~ NA ) ) %&gt;% dplyr::arrange(as.numeric(forest_type_code)) %&gt;% dplyr::group_by(forest_type_group_code) %&gt;% dplyr::mutate( forest_type_group = dplyr::first(forest_type_group, na_rm = T) , hardwood_softwood = dplyr::case_when( as.numeric(forest_type_group_code) &gt; 370 ~ &quot;Hardwood&quot; , as.numeric(forest_type_group_code) &lt;= 370 ~ &quot;Softwood&quot; , T ~ &quot;Error&quot; ) ) %&gt;% dplyr::ungroup() %&gt;% # some type groups are missing...lump them into other dplyr::mutate( forest_type_group_code = dplyr::case_when( is.na(forest_type_group) &amp; as.numeric(forest_type_code) &gt; 370 ~ &quot;960&quot; , is.na(forest_type_group) &amp; as.numeric(forest_type_code) &lt;= 370 ~ &quot;390&quot; , T ~ forest_type_group_code ) , forest_type_group = dplyr::case_when( is.na(forest_type_group) &amp; as.numeric(forest_type_code) &gt; 370 ~ &quot;Other hardwoods group&quot; , is.na(forest_type_group) &amp; as.numeric(forest_type_code) &lt;= 370 ~ &quot;Other softwoods group&quot; , T ~ forest_type_group ) ) %&gt;% # just drop the non-stocked dplyr::filter(forest_type_code != &quot;999&quot; &amp; tolower(forest_type) != &quot;nonstocked&quot;) # huh? foresttype_lookup %&gt;% dplyr::glimpse() ## Rows: 201 ## Columns: 5 ## $ forest_type_code &lt;chr&gt; &quot;100&quot;, &quot;101&quot;, &quot;102&quot;, &quot;103&quot;, &quot;104&quot;, &quot;105&quot;, &quot;120&quot;… ## $ forest_type &lt;chr&gt; &quot;White / red / jack pine group&quot;, &quot;Jack pine&quot;, &quot;… ## $ forest_type_group_code &lt;chr&gt; &quot;100&quot;, &quot;100&quot;, &quot;100&quot;, &quot;100&quot;, &quot;100&quot;, &quot;100&quot;, &quot;120&quot;… ## $ forest_type_group &lt;chr&gt; &quot;White / red / jack pine group&quot;, &quot;White / red /… ## $ hardwood_softwood &lt;chr&gt; &quot;Softwood&quot;, &quot;Softwood&quot;, &quot;Softwood&quot;, &quot;Softwood&quot;,… export this for upload to Zenodo foresttype_lookup %&gt;% write.csv( file = file.path(savedir_temp, &quot;foresttype_lookup.csv&quot;) , append = F , row.names = F ) 4.2.4 Forest type group example let’s look at the Forest Type Groups raster for our example area and use our fancy lookup data to make use of the forest type group codes in the raster # aoi box_temp &lt;- cloud2trees_ans$crowns_sf %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(200) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) # crop it and merge with the forest type group data aoi_temp &lt;- foresttype %&gt;% terra::crop(box_temp) %&gt;% terra::mask(box_temp) %&gt;% as.data.frame(xy = T) %&gt;% dplyr::rename(forest_type_code=3) %&gt;% dplyr::mutate(forest_type_code = as.character(forest_type_code)) %&gt;% dplyr::left_join(foresttype_lookup, by = &quot;forest_type_code&quot;) # huh aoi_temp %&gt;% dplyr::glimpse() ## Rows: 36 ## Columns: 7 ## $ x &lt;dbl&gt; -11749576, -11749486, -11749396, -11749306, -11… ## $ y &lt;dbl&gt; 4906429, 4906429, 4906429, 4906429, 4906429, 49… ## $ forest_type_code &lt;chr&gt; &quot;280&quot;, &quot;280&quot;, &quot;900&quot;, &quot;0&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, … ## $ forest_type &lt;chr&gt; &quot;Lodgepole pine group&quot;, &quot;Lodgepole pine group&quot;,… ## $ forest_type_group_code &lt;chr&gt; &quot;280&quot;, &quot;280&quot;, &quot;900&quot;, NA, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;… ## $ forest_type_group &lt;chr&gt; &quot;Lodgepole pine group&quot;, &quot;Lodgepole pine group&quot;,… ## $ hardwood_softwood &lt;chr&gt; &quot;Softwood&quot;, &quot;Softwood&quot;, &quot;Hardwood&quot;, NA, &quot;Hardwo… let’s plot the Forest Type Groups raster for our example area # plot it ggplot() + geom_tile( data = aoi_temp , mapping = aes(x=x, y=y, fill=forest_type_group) , color = NA , alpha = 0.7 ) + geom_sf( data = cloud2trees_ans$crowns_sf %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) %&gt;% sf::st_as_sf() , fill = NA , color = &quot;navy&quot; , lwd = 1 ) + labs(fill = &quot;forest\\ntype group&quot;, subtitle = &quot;extent of lidar detected trees shown in blue&quot;) + harrypotter::scale_fill_hp_d(&quot;lunalovegood&quot;, na.value = &quot;black&quot;) + theme_void() this looks like the forest type we expected based on RMNP example data also, note that there are raster cells that do not have a forest type. if a lidar-detected tree falls within one of these “no forest type” cells, we’ll have to figure out how to fill in the forest type. perhaps we can use the majority based on the other trees that overlap cells with a forest type? but what if none of our trees overlap with an actual forest type? we’ll have to figure out how to find the nearest cell with a forest type. 4.3 Forest Type to Tree List Now that we have all the data, let’s define a process to attach the forest type group data to a lidar-derived tree list. Remember, there are raster cells that do not have a forest type. If a lidar-detected tree falls within one of these “no forest type” cells, we’ll have to figure out how to fill in the forest type. Perhaps we can use the majority based on the other trees that overlap cells with a forest type? But what if none of our trees overlap with an actual forest type? We’ll have to figure out how to find the nearest cell with a forest type. 4.3.1 Example with original forest type our input data is a tree list with location data cloud2trees_ans$treetops_sf %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 20 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ fia_est_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_lower &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_upper &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_data &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_ft2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_cbh &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ geometry &lt;POINT [m]&gt; POINT (453532.6 4458595), POINT (45354… we want to attach the forest type group data to the tree list foresttype ## class : SpatRaster ## dimensions : 48759, 81718, 1 (nrow, ncol, nlyr) ## resolution : 90, 90 (x, y) ## extent : -14469331, -7114711, 2480614, 6868924 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / Pseudo-Mercator (EPSG:3857) ## source : foresttype.tif ## name : foresttype ## min value : 0 ## max value : 999 this is easy with terra::extract() tree_ftype_temp &lt;- terra::extract( x = foresttype , y = cloud2trees_ans$treetops_sf %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) # don&#39;t forget to reproject ) # huh? tree_ftype_temp %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 2 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, … ## $ foresttype &lt;int&gt; 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 900, 280,… now let’s join it back with our data and check it treetops_sf_new &lt;- cloud2trees_ans$treetops_sf %&gt;% dplyr::mutate( forest_type_code = tree_ftype_temp$foresttype %&gt;% as.character() ) %&gt;% dplyr::left_join(foresttype_lookup, by = &quot;forest_type_code&quot;) # huh? treetops_sf_new %&gt;% dplyr::glimpse() ## Rows: 107 ## Columns: 25 ## $ treeID &lt;chr&gt; &quot;1_453532.6_4458594.6&quot;, &quot;2_453544.6_4458594.… ## $ tree_height_m &lt;dbl&gt; 3.185, 12.866, 11.826, 4.287, 8.980, 7.009, … ## $ crown_area_m2 &lt;dbl&gt; 0.8750, 10.0000, 11.0625, 0.5625, 5.1875, 1.… ## $ fia_est_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_lower &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ fia_est_dbh_cm_upper &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_data &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ dbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ radius_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_m2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ basal_area_ft2 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_extracted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ ptcld_predicted_dbh_cm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ tree_cbh_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ is_training_cbh &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_trees_per_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_relative_tree_height &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ comp_dist_to_nearest_m &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ geometry &lt;POINT [m]&gt; POINT (453532.6 4458595), POINT (45354… ## $ forest_type_code &lt;chr&gt; &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;9… ## $ forest_type &lt;chr&gt; &quot;Aspen / birch group&quot;, &quot;Aspen / birch group&quot;… ## $ forest_type_group_code &lt;chr&gt; &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;900&quot;, &quot;9… ## $ forest_type_group &lt;chr&gt; &quot;Aspen / birch group&quot;, &quot;Aspen / birch group&quot;… ## $ hardwood_softwood &lt;chr&gt; &quot;Hardwood&quot;, &quot;Hardwood&quot;, &quot;Hardwood&quot;, &quot;Hardwoo… check it on the map # plot it ggplot() + geom_tile( data = aoi_temp , mapping = aes(x=x, y=y, fill=forest_type_group) , color = NA , alpha = 0.7 ) + geom_sf( data = treetops_sf_new %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) %&gt;% # don&#39;t forget to reproject sf::st_as_sf() , mapping = aes(color = forest_type_group) , show.legend = F ) + labs(fill = &quot;forest\\ntype group&quot;, subtitle = &quot;lidar-detected tree points with forest type group&quot;) + harrypotter::scale_fill_hp_d(&quot;lunalovegood&quot;, na.value = &quot;black&quot;) + harrypotter::scale_color_hp_d(&quot;lunalovegood&quot;, na.value = &quot;black&quot;) + theme_void() looks good! 4.3.2 Fill missing forest type example now we need to figure out what to do if the tree data overlaps with raster cells with no forest type group I originally tried to create a raster dataset with full coverage of forest type groups and just fill non-forest cells with the value from the nearest forest type. this “full coverage” data set could then be the master data we upload/download from Zenodo (since we’re already using custom data) and apply the terra::extract() function. This option is not going to work because 1) there are too many blank cells to fill (~80% of the original raster); 2) we want to give a feasible answer and if there is a great distance between the tree data and the nearest forest type then the answer could be misleading (we’ll just return no answer, but what is a “great distance”?) The process we’ll use to fill NA cell values is: * create a bounding box around the tree point data * expand the extent by the greater of double the bounding box or 1 km + outside of this would be a “great distance” to interpolate forest type * crop the forest type raster to the bounding box extent * fill in NA raster cell values using nearest neighbor interpolation * return the forest type group attached to the tree using terra::extract() first, get the bounding box of the tree data and double the extent # get extent of data bbox_temp &lt;- cloud2trees_ans$treetops_sf %&gt;% sf::st_bbox() # find largest side buffer_temp &lt;- max( bbox_temp[&quot;xmax&quot;]-bbox_temp[&quot;xmin&quot;] , bbox_temp[&quot;ymax&quot;]-bbox_temp[&quot;ymin&quot;] ) %&gt;% max(1000) # apply the buffer ext_temp &lt;- bbox_temp %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(buffer_temp, endCapStyle = &quot;SQUARE&quot;) %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) mask the raster to this extent foresttype_temp &lt;- foresttype %&gt;% terra::crop(ext_temp) %&gt;% # crop it first to make if faster terra::mask(ext_temp) mark all non-forest cells as “NA” in the cropped raster # rcl = two column matrix (&quot;is&quot;, &quot;becomes&quot;) can be useful for classifying integer # values. In that case, the arguments right and include.lowest are ignored. # unique type codes type_code_temp &lt;- foresttype_lookup %&gt;% dplyr::pull(forest_type_code) %&gt;% as.numeric() %&gt;% unique() # matrix rcl_temp &lt;- c(type_code_temp, type_code_temp) %&gt;% matrix(ncol=2, byrow=F) # update raster to mark all non-forest cells as NA foresttype_temp &lt;- foresttype_temp %&gt;% terra::classify( rcl = rcl_temp , others = NA ) do we have NA cells? # na cells terra::global(foresttype_temp, fun = &quot;isNA&quot;) ## isNA ## foresttype 194 here’s what that looks like p1_temp &lt;- # plot it ggplot() + geom_tile( data = foresttype_temp %&gt;% as.data.frame(xy = T) %&gt;% dplyr::rename(forest_type_code=3) %&gt;% dplyr::mutate(forest_type_code = as.character(forest_type_code)) %&gt;% dplyr::left_join(foresttype_lookup, by = &quot;forest_type_code&quot;) , mapping = aes(x=x, y=y, fill=forest_type_group) , color = NA , alpha = 0.7 ) + geom_sf( data = bbox_temp %&gt;% sf::st_as_sfc() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) %&gt;% sf::st_as_sf() , mapping = aes(color = &quot;trees extent&quot;) , fill = NA ) + geom_sf( data = ext_temp %&gt;% sf::st_as_sf() , mapping = aes(color = &quot;buffered extent&quot;) , fill = NA ) + labs(fill = &quot;forest\\ntype group&quot;, color = &quot;&quot;, subtitle = &quot;original&quot;) + harrypotter::scale_fill_hp_d(&quot;lunalovegood&quot;, na.value = &quot;white&quot;) + scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) + theme_void() p1_temp in this example we don’t happen to have an NA cells that overlap with our tree data, but that’s ok as we are just demonstrating the process lets’s make a quick function to fill the NA raster cells using nearest neighbor interpolation fill_rast_na &lt;- function(rast, interp = F){ # get points with data p_temp &lt;- terra::as.points(rast) # sets the search radius to the max r_temp &lt;- max( terra::nrow(foresttype_temp)*terra::res(foresttype_temp)[1] , terra::ncol(foresttype_temp)*terra::res(foresttype_temp)[2] ) # nearest neighbor interpolate rast_fill &lt;- terra::interpNear( x = rast , y = p_temp , field = names(p_temp)[1] , radius = r_temp , interpolate = interp # if F, keeps the estimate as &quot;categorical&quot; # (e.g. doesn&#39;t interpolate between ftype 700 and 900 to get 800, just picks 700 or 900) ) return(rast_fill) } # fill_rast_na(r_temp) %&gt;% terra::plot() let’s take the fill_rast_na() for a spin with our forest type raster…it might take a while with so many empty cells foresttype_temp &lt;- fill_rast_na(foresttype_temp) …just kidding, but if we were to use the entire extent of the US that might be true with the updated data plot p2_temp &lt;- # plot it ggplot() + geom_tile( data = foresttype_temp %&gt;% as.data.frame(xy = T) %&gt;% dplyr::rename(forest_type_code=3) %&gt;% dplyr::mutate(forest_type_code = as.character(forest_type_code)) %&gt;% dplyr::left_join(foresttype_lookup, by = &quot;forest_type_code&quot;) , mapping = aes(x=x, y=y, fill=forest_type_group) , color = NA , alpha = 0.7 ) + geom_sf( data = bbox_temp %&gt;% sf::st_as_sfc() %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) %&gt;% sf::st_as_sf() , mapping = aes(color = &quot;trees extent&quot;) , fill = NA ) + geom_sf( data = ext_temp %&gt;% sf::st_as_sf() , mapping = aes(color = &quot;buffered extent&quot;) , fill = NA ) + labs(fill = &quot;forest\\ntype group&quot;, color = &quot;&quot;, subtitle = &quot;NA&#39;s filled&quot;) + harrypotter::scale_fill_hp_d(&quot;lunalovegood&quot;, na.value = &quot;white&quot;) + scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) + theme_void() p2_temp compare old vs new (p1_temp + theme(legend.position = &quot;none&quot;)) + p2_temp that we filled raster cells outside of the buffered extent doesn’t matter since those cells won’t be used for anything now we apply the terra::extract() function to attach forest type to our original tree list tree_ftype_temp &lt;- terra::extract( x = foresttype_temp , y = cloud2trees_ans$treetops_sf %&gt;% terra::vect() %&gt;% terra::project(terra::crs(foresttype)) # don&#39;t forget to reproject ) # now let&#39;s join it back with our data and check it cloud2trees_ans$treetops_sf %&gt;% dplyr::mutate( forest_type_code = tree_ftype_temp$foresttype %&gt;% as.character() ) %&gt;% dplyr::left_join(foresttype_lookup, by = &quot;forest_type_code&quot;) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(forest_type_group) ## # A tibble: 2 × 2 ## forest_type_group n ## &lt;chr&gt; &lt;int&gt; ## 1 Aspen / birch group 11 ## 2 Lodgepole pine group 96 4.3.3 Fill missing forest type function let’s define a function to put all of those steps together so that we can add it to cloud2trees # do it then "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
